2025-10-15 02:29:28,844:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 02:29:28,844:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 02:29:28,844:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 02:29:28,844:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 03:00:48,817:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 03:00:48,817:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 03:00:48,817:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 03:00:48,825:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 03:05:29,386:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 03:05:29,386:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 03:05:29,386:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 03:05:29,386:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 03:10:46,143:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 03:10:46,143:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 03:10:46,143:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 03:10:46,143:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 03:10:49,071:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\flaml\__init__.py:20: UserWarning: flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.
  warnings.warn("flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.")

2025-10-15 03:14:44,079:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 03:14:44,079:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 03:14:44,079:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 03:14:44,079:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 03:15:51,457:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 03:15:51,457:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 03:15:51,457:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 03:15:51,457:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 03:33:17,691:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 03:33:17,691:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 03:33:17,691:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 03:33:17,699:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 03:34:23,200:INFO:PyCaret ClassificationExperiment
2025-10-15 03:34:23,200:INFO:Logging name: CharityML_PyCaret_AutoML
2025-10-15 03:34:23,200:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-15 03:34:23,200:INFO:version 3.3.2
2025-10-15 03:34:23,200:INFO:Initializing setup()
2025-10-15 03:34:23,205:INFO:self.USI: 9903
2025-10-15 03:34:23,208:INFO:self._variable_keys: {'X', 'seed', 'log_plots_param', 'pipeline', 'USI', 'fold_shuffle_param', 'X_train', 'target_param', 'y_test', 'fold_groups_param', 'exp_name_log', '_available_plots', '_ml_usecase', 'fix_imbalance', 'exp_id', 'n_jobs_param', 'gpu_n_jobs_param', 'memory', 'X_test', 'fold_generator', 'y', 'gpu_param', 'data', 'is_multiclass', 'y_train', 'logging_param', 'idx', 'html_param'}
2025-10-15 03:34:23,208:INFO:Checking environment
2025-10-15 03:34:23,210:INFO:python_version: 3.10.0
2025-10-15 03:34:23,211:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-10-15 03:34:23,212:INFO:machine: AMD64
2025-10-15 03:34:23,212:INFO:platform: Windows-10-10.0.19045-SP0
2025-10-15 03:34:23,230:INFO:Memory: svmem(total=8465043456, available=1464467456, percent=82.7, used=7000576000, free=1464467456)
2025-10-15 03:34:23,231:INFO:Physical Core: 2
2025-10-15 03:34:23,231:INFO:Logical Core: 4
2025-10-15 03:34:23,231:INFO:Checking libraries
2025-10-15 03:34:23,232:INFO:System:
2025-10-15 03:34:23,232:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-10-15 03:34:23,232:INFO:executable: c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\Scripts\python.exe
2025-10-15 03:34:23,232:INFO:   machine: Windows-10-10.0.19045-SP0
2025-10-15 03:34:23,233:INFO:PyCaret required dependencies:
2025-10-15 03:34:23,260:INFO:                 pip: 25.2
2025-10-15 03:34:23,260:INFO:          setuptools: 57.4.0
2025-10-15 03:34:23,260:INFO:             pycaret: 3.3.2
2025-10-15 03:34:23,260:INFO:             IPython: 8.37.0
2025-10-15 03:34:23,260:INFO:          ipywidgets: 8.1.7
2025-10-15 03:34:23,260:INFO:                tqdm: 4.67.1
2025-10-15 03:34:23,260:INFO:               numpy: 1.26.4
2025-10-15 03:34:23,260:INFO:              pandas: 2.0.3
2025-10-15 03:34:23,260:INFO:              jinja2: 3.1.6
2025-10-15 03:34:23,269:INFO:               scipy: 1.11.4
2025-10-15 03:34:23,270:INFO:              joblib: 1.3.2
2025-10-15 03:34:23,270:INFO:             sklearn: 1.4.2
2025-10-15 03:34:23,271:INFO:                pyod: 2.0.5
2025-10-15 03:34:23,278:INFO:            imblearn: 0.14.0
2025-10-15 03:34:23,280:INFO:   category_encoders: 2.7.0
2025-10-15 03:34:23,281:INFO:            lightgbm: 4.6.0
2025-10-15 03:34:23,291:INFO:               numba: 0.62.1
2025-10-15 03:34:23,292:INFO:            requests: 2.32.5
2025-10-15 03:34:23,292:INFO:          matplotlib: 3.7.5
2025-10-15 03:34:23,295:INFO:          scikitplot: 0.3.7
2025-10-15 03:34:23,295:INFO:         yellowbrick: 1.5
2025-10-15 03:34:23,296:INFO:              plotly: 6.3.1
2025-10-15 03:34:23,296:INFO:    plotly-resampler: Not installed
2025-10-15 03:34:23,296:INFO:             kaleido: 1.1.0
2025-10-15 03:34:23,297:INFO:           schemdraw: 0.15
2025-10-15 03:34:23,298:INFO:         statsmodels: 0.14.5
2025-10-15 03:34:23,299:INFO:              sktime: 0.26.0
2025-10-15 03:34:23,300:INFO:               tbats: 1.1.3
2025-10-15 03:34:23,300:INFO:            pmdarima: 2.0.4
2025-10-15 03:34:23,301:INFO:              psutil: 7.1.0
2025-10-15 03:34:23,303:INFO:          markupsafe: 3.0.3
2025-10-15 03:34:23,303:INFO:             pickle5: Not installed
2025-10-15 03:34:23,304:INFO:         cloudpickle: 3.1.1
2025-10-15 03:34:23,311:INFO:         deprecation: 2.1.0
2025-10-15 03:34:23,314:INFO:              xxhash: 3.6.0
2025-10-15 03:34:23,321:INFO:           wurlitzer: Not installed
2025-10-15 03:34:23,321:INFO:PyCaret optional dependencies:
2025-10-15 03:34:27,423:INFO:                shap: Not installed
2025-10-15 03:34:27,423:INFO:           interpret: Not installed
2025-10-15 03:34:27,423:INFO:                umap: Not installed
2025-10-15 03:34:27,423:INFO:     ydata_profiling: Not installed
2025-10-15 03:34:27,423:INFO:  explainerdashboard: Not installed
2025-10-15 03:34:27,423:INFO:             autoviz: Not installed
2025-10-15 03:34:27,423:INFO:           fairlearn: Not installed
2025-10-15 03:34:27,423:INFO:          deepchecks: Not installed
2025-10-15 03:34:27,423:INFO:             xgboost: 2.1.4
2025-10-15 03:34:27,423:INFO:            catboost: Not installed
2025-10-15 03:34:27,423:INFO:              kmodes: Not installed
2025-10-15 03:34:27,423:INFO:             mlxtend: Not installed
2025-10-15 03:34:27,423:INFO:       statsforecast: Not installed
2025-10-15 03:34:27,423:INFO:        tune_sklearn: Not installed
2025-10-15 03:34:27,423:INFO:                 ray: Not installed
2025-10-15 03:34:27,439:INFO:            hyperopt: Not installed
2025-10-15 03:34:27,439:INFO:              optuna: Not installed
2025-10-15 03:34:27,439:INFO:               skopt: Not installed
2025-10-15 03:34:27,439:INFO:              mlflow: 3.4.0
2025-10-15 03:34:27,439:INFO:              gradio: Not installed
2025-10-15 03:34:27,439:INFO:             fastapi: 0.119.0
2025-10-15 03:34:27,439:INFO:             uvicorn: 0.37.0
2025-10-15 03:34:27,439:INFO:              m2cgen: Not installed
2025-10-15 03:34:27,439:INFO:           evidently: Not installed
2025-10-15 03:34:27,439:INFO:               fugue: Not installed
2025-10-15 03:34:27,439:INFO:           streamlit: Not installed
2025-10-15 03:34:27,439:INFO:             prophet: Not installed
2025-10-15 03:34:27,439:INFO:None
2025-10-15 03:34:27,439:INFO:Set up data.
2025-10-15 03:35:06,411:INFO:PyCaret ClassificationExperiment
2025-10-15 03:35:06,411:INFO:Logging name: CharityML_PyCaret_AutoML
2025-10-15 03:35:06,419:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-15 03:35:06,419:INFO:version 3.3.2
2025-10-15 03:35:06,419:INFO:Initializing setup()
2025-10-15 03:35:06,419:INFO:self.USI: 7d10
2025-10-15 03:35:06,419:INFO:self._variable_keys: {'X', 'seed', 'log_plots_param', 'pipeline', 'USI', 'fold_shuffle_param', 'X_train', 'target_param', 'y_test', 'fold_groups_param', 'exp_name_log', '_available_plots', '_ml_usecase', 'fix_imbalance', 'exp_id', 'n_jobs_param', 'gpu_n_jobs_param', 'memory', 'X_test', 'fold_generator', 'y', 'gpu_param', 'data', 'is_multiclass', 'y_train', 'logging_param', 'idx', 'html_param'}
2025-10-15 03:35:06,419:INFO:Checking environment
2025-10-15 03:35:06,419:INFO:python_version: 3.10.0
2025-10-15 03:35:06,419:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-10-15 03:35:06,419:INFO:machine: AMD64
2025-10-15 03:35:06,419:INFO:platform: Windows-10-10.0.19045-SP0
2025-10-15 03:35:06,419:INFO:Memory: svmem(total=8465043456, available=1387884544, percent=83.6, used=7077158912, free=1387884544)
2025-10-15 03:35:06,419:INFO:Physical Core: 2
2025-10-15 03:35:06,419:INFO:Logical Core: 4
2025-10-15 03:35:06,419:INFO:Checking libraries
2025-10-15 03:35:06,419:INFO:System:
2025-10-15 03:35:06,419:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-10-15 03:35:06,419:INFO:executable: c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\Scripts\python.exe
2025-10-15 03:35:06,419:INFO:   machine: Windows-10-10.0.19045-SP0
2025-10-15 03:35:06,419:INFO:PyCaret required dependencies:
2025-10-15 03:35:06,419:INFO:                 pip: 25.2
2025-10-15 03:35:06,419:INFO:          setuptools: 57.4.0
2025-10-15 03:35:06,419:INFO:             pycaret: 3.3.2
2025-10-15 03:35:06,419:INFO:             IPython: 8.37.0
2025-10-15 03:35:06,419:INFO:          ipywidgets: 8.1.7
2025-10-15 03:35:06,419:INFO:                tqdm: 4.67.1
2025-10-15 03:35:06,419:INFO:               numpy: 1.26.4
2025-10-15 03:35:06,419:INFO:              pandas: 2.0.3
2025-10-15 03:35:06,419:INFO:              jinja2: 3.1.6
2025-10-15 03:35:06,419:INFO:               scipy: 1.11.4
2025-10-15 03:35:06,419:INFO:              joblib: 1.3.2
2025-10-15 03:35:06,419:INFO:             sklearn: 1.4.2
2025-10-15 03:35:06,419:INFO:                pyod: 2.0.5
2025-10-15 03:35:06,419:INFO:            imblearn: 0.14.0
2025-10-15 03:35:06,419:INFO:   category_encoders: 2.7.0
2025-10-15 03:35:06,419:INFO:            lightgbm: 4.6.0
2025-10-15 03:35:06,419:INFO:               numba: 0.62.1
2025-10-15 03:35:06,419:INFO:            requests: 2.32.5
2025-10-15 03:35:06,419:INFO:          matplotlib: 3.7.5
2025-10-15 03:35:06,419:INFO:          scikitplot: 0.3.7
2025-10-15 03:35:06,419:INFO:         yellowbrick: 1.5
2025-10-15 03:35:06,419:INFO:              plotly: 6.3.1
2025-10-15 03:35:06,419:INFO:    plotly-resampler: Not installed
2025-10-15 03:35:06,419:INFO:             kaleido: 1.1.0
2025-10-15 03:35:06,419:INFO:           schemdraw: 0.15
2025-10-15 03:35:06,419:INFO:         statsmodels: 0.14.5
2025-10-15 03:35:06,419:INFO:              sktime: 0.26.0
2025-10-15 03:35:06,419:INFO:               tbats: 1.1.3
2025-10-15 03:35:06,419:INFO:            pmdarima: 2.0.4
2025-10-15 03:35:06,419:INFO:              psutil: 7.1.0
2025-10-15 03:35:06,419:INFO:          markupsafe: 3.0.3
2025-10-15 03:35:06,419:INFO:             pickle5: Not installed
2025-10-15 03:35:06,419:INFO:         cloudpickle: 3.1.1
2025-10-15 03:35:06,419:INFO:         deprecation: 2.1.0
2025-10-15 03:35:06,419:INFO:              xxhash: 3.6.0
2025-10-15 03:35:06,419:INFO:           wurlitzer: Not installed
2025-10-15 03:35:06,419:INFO:PyCaret optional dependencies:
2025-10-15 03:35:06,419:INFO:                shap: Not installed
2025-10-15 03:35:06,419:INFO:           interpret: Not installed
2025-10-15 03:35:06,419:INFO:                umap: Not installed
2025-10-15 03:35:06,419:INFO:     ydata_profiling: Not installed
2025-10-15 03:35:06,419:INFO:  explainerdashboard: Not installed
2025-10-15 03:35:06,419:INFO:             autoviz: Not installed
2025-10-15 03:35:06,419:INFO:           fairlearn: Not installed
2025-10-15 03:35:06,419:INFO:          deepchecks: Not installed
2025-10-15 03:35:06,419:INFO:             xgboost: 2.1.4
2025-10-15 03:35:06,419:INFO:            catboost: Not installed
2025-10-15 03:35:06,419:INFO:              kmodes: Not installed
2025-10-15 03:35:06,419:INFO:             mlxtend: Not installed
2025-10-15 03:35:06,419:INFO:       statsforecast: Not installed
2025-10-15 03:35:06,419:INFO:        tune_sklearn: Not installed
2025-10-15 03:35:06,419:INFO:                 ray: Not installed
2025-10-15 03:35:06,419:INFO:            hyperopt: Not installed
2025-10-15 03:35:06,419:INFO:              optuna: Not installed
2025-10-15 03:35:06,429:INFO:               skopt: Not installed
2025-10-15 03:35:06,429:INFO:              mlflow: 3.4.0
2025-10-15 03:35:06,429:INFO:              gradio: Not installed
2025-10-15 03:35:06,429:INFO:             fastapi: 0.119.0
2025-10-15 03:35:06,429:INFO:             uvicorn: 0.37.0
2025-10-15 03:35:06,429:INFO:              m2cgen: Not installed
2025-10-15 03:35:06,429:INFO:           evidently: Not installed
2025-10-15 03:35:06,429:INFO:               fugue: Not installed
2025-10-15 03:35:06,429:INFO:           streamlit: Not installed
2025-10-15 03:35:06,429:INFO:             prophet: Not installed
2025-10-15 03:35:06,429:INFO:None
2025-10-15 03:35:06,429:INFO:Set up data.
2025-10-15 03:35:06,685:INFO:Set up folding strategy.
2025-10-15 03:35:06,685:INFO:Set up train/test split.
2025-10-15 03:35:06,940:INFO:Set up index.
2025-10-15 03:35:06,960:INFO:Assigning column types.
2025-10-15 03:35:07,293:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-15 03:35:07,376:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-15 03:35:07,384:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-15 03:35:07,477:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:35:07,487:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:35:07,618:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-15 03:35:07,618:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-15 03:35:07,771:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:35:07,802:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:35:07,802:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-15 03:35:08,015:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-15 03:35:08,091:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:35:08,096:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:35:08,180:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-15 03:35:08,238:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:35:08,253:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:35:08,253:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-15 03:35:08,396:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:35:08,418:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:35:08,596:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:35:08,612:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:35:08,612:INFO:Preparing preprocessing pipeline...
2025-10-15 03:35:08,680:INFO:Set up simple imputation.
2025-10-15 03:35:08,680:INFO:Set up removing multicollinearity.
2025-10-15 03:35:08,680:INFO:Set up imbalanced handling.
2025-10-15 03:35:08,680:INFO:Set up feature selection.
2025-10-15 03:35:08,860:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:35:08,860:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:35:09,333:INFO:Set up column name cleaning.
2025-10-15 03:37:19,467:INFO:PyCaret ClassificationExperiment
2025-10-15 03:37:19,467:INFO:Logging name: CharityML_PyCaret_AutoML
2025-10-15 03:37:19,468:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-15 03:37:19,468:INFO:version 3.3.2
2025-10-15 03:37:19,468:INFO:Initializing setup()
2025-10-15 03:37:19,468:INFO:self.USI: e616
2025-10-15 03:37:19,468:INFO:self._variable_keys: {'X', 'seed', 'log_plots_param', 'pipeline', 'USI', 'fold_shuffle_param', 'X_train', 'target_param', 'y_test', 'fold_groups_param', 'exp_name_log', '_available_plots', '_ml_usecase', 'fix_imbalance', 'exp_id', 'n_jobs_param', 'gpu_n_jobs_param', 'memory', 'X_test', 'fold_generator', 'y', 'gpu_param', 'data', 'is_multiclass', 'y_train', 'logging_param', 'idx', 'html_param'}
2025-10-15 03:37:19,468:INFO:Checking environment
2025-10-15 03:37:19,468:INFO:python_version: 3.10.0
2025-10-15 03:37:19,469:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-10-15 03:37:19,469:INFO:machine: AMD64
2025-10-15 03:37:19,469:INFO:platform: Windows-10-10.0.19045-SP0
2025-10-15 03:37:19,472:INFO:Memory: svmem(total=8465043456, available=1157734400, percent=86.3, used=7307309056, free=1157734400)
2025-10-15 03:37:19,472:INFO:Physical Core: 2
2025-10-15 03:37:19,472:INFO:Logical Core: 4
2025-10-15 03:37:19,472:INFO:Checking libraries
2025-10-15 03:37:19,472:INFO:System:
2025-10-15 03:37:19,472:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-10-15 03:37:19,472:INFO:executable: c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\Scripts\python.exe
2025-10-15 03:37:19,472:INFO:   machine: Windows-10-10.0.19045-SP0
2025-10-15 03:37:19,472:INFO:PyCaret required dependencies:
2025-10-15 03:37:19,472:INFO:                 pip: 25.2
2025-10-15 03:37:19,472:INFO:          setuptools: 57.4.0
2025-10-15 03:37:19,472:INFO:             pycaret: 3.3.2
2025-10-15 03:37:19,472:INFO:             IPython: 8.37.0
2025-10-15 03:37:19,472:INFO:          ipywidgets: 8.1.7
2025-10-15 03:37:19,472:INFO:                tqdm: 4.67.1
2025-10-15 03:37:19,472:INFO:               numpy: 1.26.4
2025-10-15 03:37:19,472:INFO:              pandas: 2.0.3
2025-10-15 03:37:19,472:INFO:              jinja2: 3.1.6
2025-10-15 03:37:19,472:INFO:               scipy: 1.11.4
2025-10-15 03:37:19,472:INFO:              joblib: 1.3.2
2025-10-15 03:37:19,472:INFO:             sklearn: 1.4.2
2025-10-15 03:37:19,472:INFO:                pyod: 2.0.5
2025-10-15 03:37:19,472:INFO:            imblearn: 0.14.0
2025-10-15 03:37:19,472:INFO:   category_encoders: 2.7.0
2025-10-15 03:37:19,472:INFO:            lightgbm: 4.6.0
2025-10-15 03:37:19,472:INFO:               numba: 0.62.1
2025-10-15 03:37:19,472:INFO:            requests: 2.32.5
2025-10-15 03:37:19,472:INFO:          matplotlib: 3.7.5
2025-10-15 03:37:19,472:INFO:          scikitplot: 0.3.7
2025-10-15 03:37:19,472:INFO:         yellowbrick: 1.5
2025-10-15 03:37:19,472:INFO:              plotly: 6.3.1
2025-10-15 03:37:19,472:INFO:    plotly-resampler: Not installed
2025-10-15 03:37:19,472:INFO:             kaleido: 1.1.0
2025-10-15 03:37:19,472:INFO:           schemdraw: 0.15
2025-10-15 03:37:19,472:INFO:         statsmodels: 0.14.5
2025-10-15 03:37:19,472:INFO:              sktime: 0.26.0
2025-10-15 03:37:19,472:INFO:               tbats: 1.1.3
2025-10-15 03:37:19,472:INFO:            pmdarima: 2.0.4
2025-10-15 03:37:19,480:INFO:              psutil: 7.1.0
2025-10-15 03:37:19,480:INFO:          markupsafe: 3.0.3
2025-10-15 03:37:19,480:INFO:             pickle5: Not installed
2025-10-15 03:37:19,480:INFO:         cloudpickle: 3.1.1
2025-10-15 03:37:19,480:INFO:         deprecation: 2.1.0
2025-10-15 03:37:19,480:INFO:              xxhash: 3.6.0
2025-10-15 03:37:19,480:INFO:           wurlitzer: Not installed
2025-10-15 03:37:19,480:INFO:PyCaret optional dependencies:
2025-10-15 03:37:19,480:INFO:                shap: Not installed
2025-10-15 03:37:19,480:INFO:           interpret: Not installed
2025-10-15 03:37:19,480:INFO:                umap: Not installed
2025-10-15 03:37:19,480:INFO:     ydata_profiling: Not installed
2025-10-15 03:37:19,480:INFO:  explainerdashboard: Not installed
2025-10-15 03:37:19,480:INFO:             autoviz: Not installed
2025-10-15 03:37:19,480:INFO:           fairlearn: Not installed
2025-10-15 03:37:19,480:INFO:          deepchecks: Not installed
2025-10-15 03:37:19,480:INFO:             xgboost: 2.1.4
2025-10-15 03:37:19,480:INFO:            catboost: Not installed
2025-10-15 03:37:19,480:INFO:              kmodes: Not installed
2025-10-15 03:37:19,480:INFO:             mlxtend: Not installed
2025-10-15 03:37:19,480:INFO:       statsforecast: Not installed
2025-10-15 03:37:19,480:INFO:        tune_sklearn: Not installed
2025-10-15 03:37:19,482:INFO:                 ray: Not installed
2025-10-15 03:37:19,482:INFO:            hyperopt: Not installed
2025-10-15 03:37:19,482:INFO:              optuna: Not installed
2025-10-15 03:37:19,482:INFO:               skopt: Not installed
2025-10-15 03:37:19,482:INFO:              mlflow: 3.4.0
2025-10-15 03:37:19,482:INFO:              gradio: Not installed
2025-10-15 03:37:19,482:INFO:             fastapi: 0.119.0
2025-10-15 03:37:19,482:INFO:             uvicorn: 0.37.0
2025-10-15 03:37:19,482:INFO:              m2cgen: Not installed
2025-10-15 03:37:19,482:INFO:           evidently: Not installed
2025-10-15 03:37:19,482:INFO:               fugue: Not installed
2025-10-15 03:37:19,482:INFO:           streamlit: Not installed
2025-10-15 03:37:19,482:INFO:             prophet: Not installed
2025-10-15 03:37:19,482:INFO:None
2025-10-15 03:37:19,482:INFO:Set up data.
2025-10-15 03:41:56,103:INFO:PyCaret ClassificationExperiment
2025-10-15 03:41:56,103:INFO:Logging name: CharityML_PyCaret_AutoML
2025-10-15 03:41:56,103:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-15 03:41:56,103:INFO:version 3.3.2
2025-10-15 03:41:56,103:INFO:Initializing setup()
2025-10-15 03:41:56,103:INFO:self.USI: 0c72
2025-10-15 03:41:56,103:INFO:self._variable_keys: {'X', 'seed', 'log_plots_param', 'pipeline', 'USI', 'fold_shuffle_param', 'X_train', 'target_param', 'y_test', 'fold_groups_param', 'exp_name_log', '_available_plots', '_ml_usecase', 'fix_imbalance', 'exp_id', 'n_jobs_param', 'gpu_n_jobs_param', 'memory', 'X_test', 'fold_generator', 'y', 'gpu_param', 'data', 'is_multiclass', 'y_train', 'logging_param', 'idx', 'html_param'}
2025-10-15 03:41:56,103:INFO:Checking environment
2025-10-15 03:41:56,103:INFO:python_version: 3.10.0
2025-10-15 03:41:56,103:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-10-15 03:41:56,103:INFO:machine: AMD64
2025-10-15 03:41:56,103:INFO:platform: Windows-10-10.0.19045-SP0
2025-10-15 03:41:56,103:INFO:Memory: svmem(total=8465043456, available=1507217408, percent=82.2, used=6957826048, free=1507217408)
2025-10-15 03:41:56,103:INFO:Physical Core: 2
2025-10-15 03:41:56,103:INFO:Logical Core: 4
2025-10-15 03:41:56,103:INFO:Checking libraries
2025-10-15 03:41:56,103:INFO:System:
2025-10-15 03:41:56,103:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-10-15 03:41:56,103:INFO:executable: c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\Scripts\python.exe
2025-10-15 03:41:56,103:INFO:   machine: Windows-10-10.0.19045-SP0
2025-10-15 03:41:56,103:INFO:PyCaret required dependencies:
2025-10-15 03:41:56,103:INFO:                 pip: 25.2
2025-10-15 03:41:56,103:INFO:          setuptools: 57.4.0
2025-10-15 03:41:56,103:INFO:             pycaret: 3.3.2
2025-10-15 03:41:56,103:INFO:             IPython: 8.37.0
2025-10-15 03:41:56,103:INFO:          ipywidgets: 8.1.7
2025-10-15 03:41:56,103:INFO:                tqdm: 4.67.1
2025-10-15 03:41:56,103:INFO:               numpy: 1.26.4
2025-10-15 03:41:56,103:INFO:              pandas: 2.0.3
2025-10-15 03:41:56,103:INFO:              jinja2: 3.1.6
2025-10-15 03:41:56,103:INFO:               scipy: 1.11.4
2025-10-15 03:41:56,111:INFO:              joblib: 1.3.2
2025-10-15 03:41:56,111:INFO:             sklearn: 1.4.2
2025-10-15 03:41:56,111:INFO:                pyod: 2.0.5
2025-10-15 03:41:56,111:INFO:            imblearn: 0.14.0
2025-10-15 03:41:56,111:INFO:   category_encoders: 2.7.0
2025-10-15 03:41:56,111:INFO:            lightgbm: 4.6.0
2025-10-15 03:41:56,111:INFO:               numba: 0.62.1
2025-10-15 03:41:56,111:INFO:            requests: 2.32.5
2025-10-15 03:41:56,111:INFO:          matplotlib: 3.7.5
2025-10-15 03:41:56,111:INFO:          scikitplot: 0.3.7
2025-10-15 03:41:56,111:INFO:         yellowbrick: 1.5
2025-10-15 03:41:56,111:INFO:              plotly: 6.3.1
2025-10-15 03:41:56,111:INFO:    plotly-resampler: Not installed
2025-10-15 03:41:56,111:INFO:             kaleido: 1.1.0
2025-10-15 03:41:56,111:INFO:           schemdraw: 0.15
2025-10-15 03:41:56,111:INFO:         statsmodels: 0.14.5
2025-10-15 03:41:56,111:INFO:              sktime: 0.26.0
2025-10-15 03:41:56,111:INFO:               tbats: 1.1.3
2025-10-15 03:41:56,111:INFO:            pmdarima: 2.0.4
2025-10-15 03:41:56,111:INFO:              psutil: 7.1.0
2025-10-15 03:41:56,111:INFO:          markupsafe: 3.0.3
2025-10-15 03:41:56,111:INFO:             pickle5: Not installed
2025-10-15 03:41:56,111:INFO:         cloudpickle: 3.1.1
2025-10-15 03:41:56,111:INFO:         deprecation: 2.1.0
2025-10-15 03:41:56,111:INFO:              xxhash: 3.6.0
2025-10-15 03:41:56,111:INFO:           wurlitzer: Not installed
2025-10-15 03:41:56,111:INFO:PyCaret optional dependencies:
2025-10-15 03:41:56,111:INFO:                shap: Not installed
2025-10-15 03:41:56,111:INFO:           interpret: Not installed
2025-10-15 03:41:56,111:INFO:                umap: Not installed
2025-10-15 03:41:56,111:INFO:     ydata_profiling: Not installed
2025-10-15 03:41:56,113:INFO:  explainerdashboard: Not installed
2025-10-15 03:41:56,113:INFO:             autoviz: Not installed
2025-10-15 03:41:56,113:INFO:           fairlearn: Not installed
2025-10-15 03:41:56,113:INFO:          deepchecks: Not installed
2025-10-15 03:41:56,113:INFO:             xgboost: 2.1.4
2025-10-15 03:41:56,113:INFO:            catboost: Not installed
2025-10-15 03:41:56,113:INFO:              kmodes: Not installed
2025-10-15 03:41:56,113:INFO:             mlxtend: Not installed
2025-10-15 03:41:56,113:INFO:       statsforecast: Not installed
2025-10-15 03:41:56,113:INFO:        tune_sklearn: Not installed
2025-10-15 03:41:56,113:INFO:                 ray: Not installed
2025-10-15 03:41:56,113:INFO:            hyperopt: Not installed
2025-10-15 03:41:56,113:INFO:              optuna: Not installed
2025-10-15 03:41:56,113:INFO:               skopt: Not installed
2025-10-15 03:41:56,113:INFO:              mlflow: 3.4.0
2025-10-15 03:41:56,113:INFO:              gradio: Not installed
2025-10-15 03:41:56,113:INFO:             fastapi: 0.119.0
2025-10-15 03:41:56,113:INFO:             uvicorn: 0.37.0
2025-10-15 03:41:56,113:INFO:              m2cgen: Not installed
2025-10-15 03:41:56,113:INFO:           evidently: Not installed
2025-10-15 03:41:56,113:INFO:               fugue: Not installed
2025-10-15 03:41:56,113:INFO:           streamlit: Not installed
2025-10-15 03:41:56,113:INFO:             prophet: Not installed
2025-10-15 03:41:56,113:INFO:None
2025-10-15 03:41:56,113:INFO:Set up data.
2025-10-15 03:41:56,543:INFO:Set up folding strategy.
2025-10-15 03:41:56,543:INFO:Set up train/test split.
2025-10-15 03:41:56,867:INFO:Set up index.
2025-10-15 03:41:56,877:INFO:Assigning column types.
2025-10-15 03:41:57,266:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-15 03:41:57,939:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-15 03:41:57,939:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-15 03:41:58,075:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:41:58,102:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:41:58,671:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-15 03:41:58,671:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-15 03:41:58,793:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:41:58,809:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:41:58,810:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-15 03:41:59,038:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-15 03:41:59,160:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:41:59,170:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:41:59,437:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-15 03:41:59,586:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:41:59,596:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:41:59,596:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-15 03:41:59,930:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:41:59,940:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:42:00,224:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:42:00,234:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:42:00,242:INFO:Preparing preprocessing pipeline...
2025-10-15 03:42:00,316:INFO:Set up simple imputation.
2025-10-15 03:42:00,316:INFO:Set up removing multicollinearity.
2025-10-15 03:42:00,316:INFO:Set up imbalanced handling.
2025-10-15 03:42:00,316:INFO:Set up feature selection.
2025-10-15 03:42:00,575:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:42:00,580:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:42:00,792:INFO:Set up column name cleaning.
2025-10-15 03:44:38,494:INFO:PyCaret ClassificationExperiment
2025-10-15 03:44:38,495:INFO:Logging name: CharityML_PyCaret_AutoML
2025-10-15 03:44:38,495:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-15 03:44:38,495:INFO:version 3.3.2
2025-10-15 03:44:38,495:INFO:Initializing setup()
2025-10-15 03:44:38,495:INFO:self.USI: fb46
2025-10-15 03:44:38,495:INFO:self._variable_keys: {'X', 'seed', 'log_plots_param', 'pipeline', 'USI', 'fold_shuffle_param', 'X_train', 'target_param', 'y_test', 'fold_groups_param', 'exp_name_log', '_available_plots', '_ml_usecase', 'fix_imbalance', 'exp_id', 'n_jobs_param', 'gpu_n_jobs_param', 'memory', 'X_test', 'fold_generator', 'y', 'gpu_param', 'data', 'is_multiclass', 'y_train', 'logging_param', 'idx', 'html_param'}
2025-10-15 03:44:38,495:INFO:Checking environment
2025-10-15 03:44:38,495:INFO:python_version: 3.10.0
2025-10-15 03:44:38,495:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-10-15 03:44:38,496:INFO:machine: AMD64
2025-10-15 03:44:38,496:INFO:platform: Windows-10-10.0.19045-SP0
2025-10-15 03:44:38,499:INFO:Memory: svmem(total=8465043456, available=1271873536, percent=85.0, used=7193169920, free=1271873536)
2025-10-15 03:44:38,501:INFO:Physical Core: 2
2025-10-15 03:44:38,502:INFO:Logical Core: 4
2025-10-15 03:44:38,504:INFO:Checking libraries
2025-10-15 03:44:38,504:INFO:System:
2025-10-15 03:44:38,504:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-10-15 03:44:38,505:INFO:executable: c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\Scripts\python.exe
2025-10-15 03:44:38,505:INFO:   machine: Windows-10-10.0.19045-SP0
2025-10-15 03:44:38,505:INFO:PyCaret required dependencies:
2025-10-15 03:44:38,505:INFO:                 pip: 25.2
2025-10-15 03:44:38,506:INFO:          setuptools: 57.4.0
2025-10-15 03:44:38,506:INFO:             pycaret: 3.3.2
2025-10-15 03:44:38,506:INFO:             IPython: 8.37.0
2025-10-15 03:44:38,506:INFO:          ipywidgets: 8.1.7
2025-10-15 03:44:38,506:INFO:                tqdm: 4.67.1
2025-10-15 03:44:38,506:INFO:               numpy: 1.26.4
2025-10-15 03:44:38,507:INFO:              pandas: 2.0.3
2025-10-15 03:44:38,507:INFO:              jinja2: 3.1.6
2025-10-15 03:44:38,507:INFO:               scipy: 1.11.4
2025-10-15 03:44:38,507:INFO:              joblib: 1.3.2
2025-10-15 03:44:38,507:INFO:             sklearn: 1.4.2
2025-10-15 03:44:38,507:INFO:                pyod: 2.0.5
2025-10-15 03:44:38,507:INFO:            imblearn: 0.14.0
2025-10-15 03:44:38,508:INFO:   category_encoders: 2.7.0
2025-10-15 03:44:38,508:INFO:            lightgbm: 4.6.0
2025-10-15 03:44:38,508:INFO:               numba: 0.62.1
2025-10-15 03:44:38,508:INFO:            requests: 2.32.5
2025-10-15 03:44:38,508:INFO:          matplotlib: 3.7.5
2025-10-15 03:44:38,508:INFO:          scikitplot: 0.3.7
2025-10-15 03:44:38,508:INFO:         yellowbrick: 1.5
2025-10-15 03:44:38,508:INFO:              plotly: 6.3.1
2025-10-15 03:44:38,508:INFO:    plotly-resampler: Not installed
2025-10-15 03:44:38,508:INFO:             kaleido: 1.1.0
2025-10-15 03:44:38,509:INFO:           schemdraw: 0.15
2025-10-15 03:44:38,509:INFO:         statsmodels: 0.14.5
2025-10-15 03:44:38,509:INFO:              sktime: 0.26.0
2025-10-15 03:44:38,509:INFO:               tbats: 1.1.3
2025-10-15 03:44:38,509:INFO:            pmdarima: 2.0.4
2025-10-15 03:44:38,509:INFO:              psutil: 7.1.0
2025-10-15 03:44:38,509:INFO:          markupsafe: 3.0.3
2025-10-15 03:44:38,509:INFO:             pickle5: Not installed
2025-10-15 03:44:38,509:INFO:         cloudpickle: 3.1.1
2025-10-15 03:44:38,509:INFO:         deprecation: 2.1.0
2025-10-15 03:44:38,509:INFO:              xxhash: 3.6.0
2025-10-15 03:44:38,510:INFO:           wurlitzer: Not installed
2025-10-15 03:44:38,510:INFO:PyCaret optional dependencies:
2025-10-15 03:44:38,510:INFO:                shap: Not installed
2025-10-15 03:44:38,510:INFO:           interpret: Not installed
2025-10-15 03:44:38,510:INFO:                umap: Not installed
2025-10-15 03:44:38,510:INFO:     ydata_profiling: Not installed
2025-10-15 03:44:38,510:INFO:  explainerdashboard: Not installed
2025-10-15 03:44:38,510:INFO:             autoviz: Not installed
2025-10-15 03:44:38,549:INFO:           fairlearn: Not installed
2025-10-15 03:44:38,549:INFO:          deepchecks: Not installed
2025-10-15 03:44:38,549:INFO:             xgboost: 2.1.4
2025-10-15 03:44:38,549:INFO:            catboost: Not installed
2025-10-15 03:44:38,549:INFO:              kmodes: Not installed
2025-10-15 03:44:38,549:INFO:             mlxtend: Not installed
2025-10-15 03:44:38,549:INFO:       statsforecast: Not installed
2025-10-15 03:44:38,549:INFO:        tune_sklearn: Not installed
2025-10-15 03:44:38,549:INFO:                 ray: Not installed
2025-10-15 03:44:38,550:INFO:            hyperopt: Not installed
2025-10-15 03:44:38,550:INFO:              optuna: Not installed
2025-10-15 03:44:38,550:INFO:               skopt: Not installed
2025-10-15 03:44:38,550:INFO:              mlflow: 3.4.0
2025-10-15 03:44:38,550:INFO:              gradio: Not installed
2025-10-15 03:44:38,550:INFO:             fastapi: 0.119.0
2025-10-15 03:44:38,550:INFO:             uvicorn: 0.37.0
2025-10-15 03:44:38,550:INFO:              m2cgen: Not installed
2025-10-15 03:44:38,550:INFO:           evidently: Not installed
2025-10-15 03:44:38,550:INFO:               fugue: Not installed
2025-10-15 03:44:38,551:INFO:           streamlit: Not installed
2025-10-15 03:44:38,551:INFO:             prophet: Not installed
2025-10-15 03:44:38,551:INFO:None
2025-10-15 03:44:38,551:INFO:Set up data.
2025-10-15 03:44:38,929:INFO:Set up folding strategy.
2025-10-15 03:44:38,929:INFO:Set up train/test split.
2025-10-15 03:44:39,265:INFO:Set up index.
2025-10-15 03:44:39,275:INFO:Assigning column types.
2025-10-15 03:44:39,589:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-15 03:44:39,793:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-15 03:44:39,793:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-15 03:44:39,935:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:44:39,945:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:44:40,026:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-15 03:44:40,034:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-15 03:44:40,084:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:44:40,086:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:44:40,086:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-15 03:44:40,188:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-15 03:44:40,241:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:44:40,246:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:44:40,319:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-15 03:44:40,370:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:44:40,378:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:44:40,378:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-15 03:44:40,533:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:44:40,543:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:44:40,685:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:44:40,685:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:44:40,733:INFO:Set up column name cleaning.
2025-10-15 03:44:40,979:INFO:Finished creating preprocessing pipeline.
2025-10-15 03:44:40,979:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Khaled\AppData\Local\Temp\joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-15 03:44:40,979:INFO:Creating final display dataframe.
2025-10-15 03:44:43,153:INFO:Setup _display_container:                    Description         Value
0                   Session id            42
1                       Target        donate
2                  Target type        Binary
3          Original data shape  (45222, 104)
4       Transformed data shape  (45222, 104)
5  Transformed train set shape  (31655, 104)
6   Transformed test set shape  (13567, 104)
7             Numeric features           103
2025-10-15 03:44:43,591:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:44:43,611:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:44:44,039:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:44:44,047:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:44:44,057:INFO:Logging experiment in loggers
2025-10-15 03:46:10,643:INFO:PyCaret ClassificationExperiment
2025-10-15 03:46:10,643:INFO:Logging name: CharityML_PyCaret_AutoML
2025-10-15 03:46:10,643:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-15 03:46:10,643:INFO:version 3.3.2
2025-10-15 03:46:10,643:INFO:Initializing setup()
2025-10-15 03:46:10,643:INFO:self.USI: 2a9f
2025-10-15 03:46:10,643:INFO:self._variable_keys: {'X', 'seed', 'log_plots_param', 'pipeline', 'USI', 'fold_shuffle_param', 'X_train', 'target_param', 'y_test', 'fold_groups_param', 'exp_name_log', '_available_plots', '_ml_usecase', 'fix_imbalance', 'exp_id', 'n_jobs_param', 'gpu_n_jobs_param', 'memory', 'X_test', 'fold_generator', 'y', 'gpu_param', 'data', 'is_multiclass', 'y_train', 'logging_param', 'idx', 'html_param'}
2025-10-15 03:46:10,643:INFO:Checking environment
2025-10-15 03:46:10,643:INFO:python_version: 3.10.0
2025-10-15 03:46:10,643:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-10-15 03:46:10,643:INFO:machine: AMD64
2025-10-15 03:46:10,643:INFO:platform: Windows-10-10.0.19045-SP0
2025-10-15 03:46:10,643:INFO:Memory: svmem(total=8465043456, available=1500819456, percent=82.3, used=6964224000, free=1500819456)
2025-10-15 03:46:10,643:INFO:Physical Core: 2
2025-10-15 03:46:10,643:INFO:Logical Core: 4
2025-10-15 03:46:10,643:INFO:Checking libraries
2025-10-15 03:46:10,643:INFO:System:
2025-10-15 03:46:10,652:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-10-15 03:46:10,653:INFO:executable: c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\Scripts\python.exe
2025-10-15 03:46:10,653:INFO:   machine: Windows-10-10.0.19045-SP0
2025-10-15 03:46:10,654:INFO:PyCaret required dependencies:
2025-10-15 03:46:10,654:INFO:                 pip: 25.2
2025-10-15 03:46:10,654:INFO:          setuptools: 57.4.0
2025-10-15 03:46:10,655:INFO:             pycaret: 3.3.2
2025-10-15 03:46:10,655:INFO:             IPython: 8.37.0
2025-10-15 03:46:10,655:INFO:          ipywidgets: 8.1.7
2025-10-15 03:46:10,655:INFO:                tqdm: 4.67.1
2025-10-15 03:46:10,655:INFO:               numpy: 1.26.4
2025-10-15 03:46:10,655:INFO:              pandas: 2.0.3
2025-10-15 03:46:10,655:INFO:              jinja2: 3.1.6
2025-10-15 03:46:10,655:INFO:               scipy: 1.11.4
2025-10-15 03:46:10,655:INFO:              joblib: 1.3.2
2025-10-15 03:46:10,655:INFO:             sklearn: 1.4.2
2025-10-15 03:46:10,655:INFO:                pyod: 2.0.5
2025-10-15 03:46:10,655:INFO:            imblearn: 0.14.0
2025-10-15 03:46:10,655:INFO:   category_encoders: 2.7.0
2025-10-15 03:46:10,655:INFO:            lightgbm: 4.6.0
2025-10-15 03:46:10,655:INFO:               numba: 0.62.1
2025-10-15 03:46:10,656:INFO:            requests: 2.32.5
2025-10-15 03:46:10,656:INFO:          matplotlib: 3.7.5
2025-10-15 03:46:10,656:INFO:          scikitplot: 0.3.7
2025-10-15 03:46:10,656:INFO:         yellowbrick: 1.5
2025-10-15 03:46:10,656:INFO:              plotly: 6.3.1
2025-10-15 03:46:10,656:INFO:    plotly-resampler: Not installed
2025-10-15 03:46:10,656:INFO:             kaleido: 1.1.0
2025-10-15 03:46:10,656:INFO:           schemdraw: 0.15
2025-10-15 03:46:10,656:INFO:         statsmodels: 0.14.5
2025-10-15 03:46:10,656:INFO:              sktime: 0.26.0
2025-10-15 03:46:10,656:INFO:               tbats: 1.1.3
2025-10-15 03:46:10,657:INFO:            pmdarima: 2.0.4
2025-10-15 03:46:10,657:INFO:              psutil: 7.1.0
2025-10-15 03:46:10,657:INFO:          markupsafe: 3.0.3
2025-10-15 03:46:10,657:INFO:             pickle5: Not installed
2025-10-15 03:46:10,657:INFO:         cloudpickle: 3.1.1
2025-10-15 03:46:10,657:INFO:         deprecation: 2.1.0
2025-10-15 03:46:10,657:INFO:              xxhash: 3.6.0
2025-10-15 03:46:10,657:INFO:           wurlitzer: Not installed
2025-10-15 03:46:10,657:INFO:PyCaret optional dependencies:
2025-10-15 03:46:10,658:INFO:                shap: Not installed
2025-10-15 03:46:10,658:INFO:           interpret: Not installed
2025-10-15 03:46:10,658:INFO:                umap: Not installed
2025-10-15 03:46:10,658:INFO:     ydata_profiling: Not installed
2025-10-15 03:46:10,658:INFO:  explainerdashboard: Not installed
2025-10-15 03:46:10,658:INFO:             autoviz: Not installed
2025-10-15 03:46:10,658:INFO:           fairlearn: Not installed
2025-10-15 03:46:10,658:INFO:          deepchecks: Not installed
2025-10-15 03:46:10,658:INFO:             xgboost: 2.1.4
2025-10-15 03:46:10,659:INFO:            catboost: Not installed
2025-10-15 03:46:10,659:INFO:              kmodes: Not installed
2025-10-15 03:46:10,659:INFO:             mlxtend: Not installed
2025-10-15 03:46:10,659:INFO:       statsforecast: Not installed
2025-10-15 03:46:10,659:INFO:        tune_sklearn: Not installed
2025-10-15 03:46:10,659:INFO:                 ray: Not installed
2025-10-15 03:46:10,659:INFO:            hyperopt: Not installed
2025-10-15 03:46:10,659:INFO:              optuna: Not installed
2025-10-15 03:46:10,659:INFO:               skopt: Not installed
2025-10-15 03:46:10,659:INFO:              mlflow: 3.4.0
2025-10-15 03:46:10,661:INFO:              gradio: Not installed
2025-10-15 03:46:10,661:INFO:             fastapi: 0.119.0
2025-10-15 03:46:10,661:INFO:             uvicorn: 0.37.0
2025-10-15 03:46:10,661:INFO:              m2cgen: Not installed
2025-10-15 03:46:10,661:INFO:           evidently: Not installed
2025-10-15 03:46:10,661:INFO:               fugue: Not installed
2025-10-15 03:46:10,661:INFO:           streamlit: Not installed
2025-10-15 03:46:10,661:INFO:             prophet: Not installed
2025-10-15 03:46:10,661:INFO:None
2025-10-15 03:46:10,663:INFO:Set up data.
2025-10-15 03:46:11,140:INFO:Set up folding strategy.
2025-10-15 03:46:11,140:INFO:Set up train/test split.
2025-10-15 03:46:11,760:INFO:Set up index.
2025-10-15 03:46:11,770:INFO:Assigning column types.
2025-10-15 03:46:12,460:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-15 03:46:12,707:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-15 03:46:12,717:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-15 03:46:12,879:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:46:12,899:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:46:13,108:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-15 03:46:13,111:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-15 03:46:13,245:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:46:13,255:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:46:13,255:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-15 03:46:13,479:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-15 03:46:13,612:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:46:13,631:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:46:13,772:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-15 03:46:13,844:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:46:13,845:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:46:13,845:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-15 03:46:14,160:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:46:14,189:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:46:14,624:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:46:14,657:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:46:14,796:INFO:Set up column name cleaning.
2025-10-15 03:46:15,306:INFO:Finished creating preprocessing pipeline.
2025-10-15 03:46:15,314:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Khaled\AppData\Local\Temp\joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-15 03:46:15,314:INFO:Creating final display dataframe.
2025-10-15 03:46:17,468:INFO:Setup _display_container:                    Description         Value
0                   Session id            42
1                       Target        donate
2                  Target type        Binary
3          Original data shape  (45222, 104)
4       Transformed data shape  (45222, 104)
5  Transformed train set shape  (31655, 104)
6   Transformed test set shape  (13567, 104)
7             Numeric features           103
2025-10-15 03:46:17,873:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:46:17,884:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:46:18,275:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:46:18,280:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:46:18,280:INFO:setup() successfully completed in 7.65s...............
2025-10-15 03:46:18,291:INFO:Initializing compare_models()
2025-10-15 03:46:18,291:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A988865300>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001A988865300>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-10-15 03:46:18,291:INFO:Checking exceptions
2025-10-15 03:46:18,558:INFO:Preparing display monitor
2025-10-15 03:46:18,647:INFO:Initializing Logistic Regression
2025-10-15 03:46:18,647:INFO:Total runtime is 0.0 minutes
2025-10-15 03:46:18,689:INFO:SubProcess create_model() called ==================================
2025-10-15 03:46:18,689:INFO:Initializing create_model()
2025-10-15 03:46:18,690:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A988865300>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A9D306FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:46:18,690:INFO:Checking exceptions
2025-10-15 03:46:18,690:INFO:Importing libraries
2025-10-15 03:46:18,690:INFO:Copying training dataset
2025-10-15 03:46:19,272:INFO:Defining folds
2025-10-15 03:46:19,272:INFO:Declaring metric variables
2025-10-15 03:46:19,286:INFO:Importing untrained model
2025-10-15 03:46:19,294:INFO:Logistic Regression Imported successfully
2025-10-15 03:46:19,317:INFO:Starting cross validation
2025-10-15 03:46:19,325:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 03:46:46,962:INFO:Calculating mean and std
2025-10-15 03:46:46,969:INFO:Creating metrics dataframe
2025-10-15 03:46:46,985:INFO:Uploading results into container
2025-10-15 03:46:46,985:INFO:Uploading model into container now
2025-10-15 03:46:46,985:INFO:_master_model_container: 1
2025-10-15 03:46:46,985:INFO:_display_container: 2
2025-10-15 03:46:46,985:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-15 03:46:46,985:INFO:create_model() successfully completed......................................
2025-10-15 03:46:47,380:INFO:SubProcess create_model() end ==================================
2025-10-15 03:46:47,380:INFO:Creating metrics dataframe
2025-10-15 03:46:47,400:INFO:Initializing K Neighbors Classifier
2025-10-15 03:46:47,400:INFO:Total runtime is 0.4792288541793823 minutes
2025-10-15 03:46:47,419:INFO:SubProcess create_model() called ==================================
2025-10-15 03:46:47,419:INFO:Initializing create_model()
2025-10-15 03:46:47,421:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A988865300>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A9D306FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:46:47,421:INFO:Checking exceptions
2025-10-15 03:46:47,421:INFO:Importing libraries
2025-10-15 03:46:47,421:INFO:Copying training dataset
2025-10-15 03:46:48,001:INFO:Defining folds
2025-10-15 03:46:48,001:INFO:Declaring metric variables
2025-10-15 03:46:48,034:INFO:Importing untrained model
2025-10-15 03:46:48,054:INFO:K Neighbors Classifier Imported successfully
2025-10-15 03:46:48,080:INFO:Starting cross validation
2025-10-15 03:46:48,084:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 03:47:51,884:INFO:Calculating mean and std
2025-10-15 03:47:51,884:INFO:Creating metrics dataframe
2025-10-15 03:47:51,901:INFO:Uploading results into container
2025-10-15 03:47:51,906:INFO:Uploading model into container now
2025-10-15 03:47:51,908:INFO:_master_model_container: 2
2025-10-15 03:47:51,909:INFO:_display_container: 2
2025-10-15 03:47:51,910:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-15 03:47:51,911:INFO:create_model() successfully completed......................................
2025-10-15 03:47:52,199:INFO:SubProcess create_model() end ==================================
2025-10-15 03:47:52,199:INFO:Creating metrics dataframe
2025-10-15 03:47:52,229:INFO:Initializing Naive Bayes
2025-10-15 03:47:52,229:INFO:Total runtime is 1.5597044825553894 minutes
2025-10-15 03:47:52,239:INFO:SubProcess create_model() called ==================================
2025-10-15 03:47:52,239:INFO:Initializing create_model()
2025-10-15 03:47:52,239:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A988865300>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A9D306FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:47:52,239:INFO:Checking exceptions
2025-10-15 03:47:52,239:INFO:Importing libraries
2025-10-15 03:47:52,239:INFO:Copying training dataset
2025-10-15 03:47:53,157:INFO:Defining folds
2025-10-15 03:47:53,157:INFO:Declaring metric variables
2025-10-15 03:47:53,176:INFO:Importing untrained model
2025-10-15 03:47:53,193:INFO:Naive Bayes Imported successfully
2025-10-15 03:47:53,225:INFO:Starting cross validation
2025-10-15 03:47:53,227:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 03:47:55,005:INFO:Calculating mean and std
2025-10-15 03:47:55,005:INFO:Creating metrics dataframe
2025-10-15 03:47:55,017:INFO:Uploading results into container
2025-10-15 03:47:55,017:INFO:Uploading model into container now
2025-10-15 03:47:55,017:INFO:_master_model_container: 3
2025-10-15 03:47:55,017:INFO:_display_container: 2
2025-10-15 03:47:55,023:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-15 03:47:55,023:INFO:create_model() successfully completed......................................
2025-10-15 03:47:55,372:INFO:SubProcess create_model() end ==================================
2025-10-15 03:47:55,372:INFO:Creating metrics dataframe
2025-10-15 03:47:55,403:INFO:Initializing Decision Tree Classifier
2025-10-15 03:47:55,403:INFO:Total runtime is 1.6125979940096538 minutes
2025-10-15 03:47:55,421:INFO:SubProcess create_model() called ==================================
2025-10-15 03:47:55,421:INFO:Initializing create_model()
2025-10-15 03:47:55,423:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A988865300>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A9D306FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:47:55,423:INFO:Checking exceptions
2025-10-15 03:47:55,423:INFO:Importing libraries
2025-10-15 03:47:55,423:INFO:Copying training dataset
2025-10-15 03:47:55,860:INFO:Defining folds
2025-10-15 03:47:55,860:INFO:Declaring metric variables
2025-10-15 03:47:55,876:INFO:Importing untrained model
2025-10-15 03:47:55,893:INFO:Decision Tree Classifier Imported successfully
2025-10-15 03:47:55,917:INFO:Starting cross validation
2025-10-15 03:47:55,920:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 03:47:58,853:INFO:Calculating mean and std
2025-10-15 03:47:58,855:INFO:Creating metrics dataframe
2025-10-15 03:47:58,865:INFO:Uploading results into container
2025-10-15 03:47:58,868:INFO:Uploading model into container now
2025-10-15 03:47:58,868:INFO:_master_model_container: 4
2025-10-15 03:47:58,868:INFO:_display_container: 2
2025-10-15 03:47:58,868:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-10-15 03:47:58,868:INFO:create_model() successfully completed......................................
2025-10-15 03:47:59,051:INFO:SubProcess create_model() end ==================================
2025-10-15 03:47:59,051:INFO:Creating metrics dataframe
2025-10-15 03:47:59,072:INFO:Initializing SVM - Linear Kernel
2025-10-15 03:47:59,072:INFO:Total runtime is 1.6737544655799865 minutes
2025-10-15 03:47:59,079:INFO:SubProcess create_model() called ==================================
2025-10-15 03:47:59,079:INFO:Initializing create_model()
2025-10-15 03:47:59,079:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A988865300>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A9D306FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:47:59,079:INFO:Checking exceptions
2025-10-15 03:47:59,079:INFO:Importing libraries
2025-10-15 03:47:59,079:INFO:Copying training dataset
2025-10-15 03:47:59,353:INFO:Defining folds
2025-10-15 03:47:59,353:INFO:Declaring metric variables
2025-10-15 03:47:59,373:INFO:Importing untrained model
2025-10-15 03:47:59,385:INFO:SVM - Linear Kernel Imported successfully
2025-10-15 03:47:59,403:INFO:Starting cross validation
2025-10-15 03:47:59,405:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 03:48:02,684:INFO:Calculating mean and std
2025-10-15 03:48:02,695:INFO:Creating metrics dataframe
2025-10-15 03:48:02,704:INFO:Uploading results into container
2025-10-15 03:48:02,704:INFO:Uploading model into container now
2025-10-15 03:48:02,704:INFO:_master_model_container: 5
2025-10-15 03:48:02,704:INFO:_display_container: 2
2025-10-15 03:48:02,704:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-15 03:48:02,704:INFO:create_model() successfully completed......................................
2025-10-15 03:48:03,027:INFO:SubProcess create_model() end ==================================
2025-10-15 03:48:03,027:INFO:Creating metrics dataframe
2025-10-15 03:48:03,069:INFO:Initializing Ridge Classifier
2025-10-15 03:48:03,069:INFO:Total runtime is 1.7403794050216674 minutes
2025-10-15 03:48:03,086:INFO:SubProcess create_model() called ==================================
2025-10-15 03:48:03,086:INFO:Initializing create_model()
2025-10-15 03:48:03,086:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A988865300>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A9D306FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:48:03,087:INFO:Checking exceptions
2025-10-15 03:48:03,087:INFO:Importing libraries
2025-10-15 03:48:03,087:INFO:Copying training dataset
2025-10-15 03:48:03,680:INFO:Defining folds
2025-10-15 03:48:03,680:INFO:Declaring metric variables
2025-10-15 03:48:03,690:INFO:Importing untrained model
2025-10-15 03:48:03,705:INFO:Ridge Classifier Imported successfully
2025-10-15 03:48:03,729:INFO:Starting cross validation
2025-10-15 03:48:03,731:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 03:48:05,360:INFO:Calculating mean and std
2025-10-15 03:48:05,368:INFO:Creating metrics dataframe
2025-10-15 03:48:05,376:INFO:Uploading results into container
2025-10-15 03:48:05,383:INFO:Uploading model into container now
2025-10-15 03:48:05,384:INFO:_master_model_container: 6
2025-10-15 03:48:05,384:INFO:_display_container: 2
2025-10-15 03:48:05,384:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-15 03:48:05,384:INFO:create_model() successfully completed......................................
2025-10-15 03:48:05,659:INFO:SubProcess create_model() end ==================================
2025-10-15 03:48:05,659:INFO:Creating metrics dataframe
2025-10-15 03:48:05,669:INFO:Initializing Random Forest Classifier
2025-10-15 03:48:05,669:INFO:Total runtime is 1.783711032072703 minutes
2025-10-15 03:48:05,688:INFO:SubProcess create_model() called ==================================
2025-10-15 03:48:05,688:INFO:Initializing create_model()
2025-10-15 03:48:05,688:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A988865300>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A9D306FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:48:05,688:INFO:Checking exceptions
2025-10-15 03:48:05,688:INFO:Importing libraries
2025-10-15 03:48:05,688:INFO:Copying training dataset
2025-10-15 03:48:05,904:INFO:Defining folds
2025-10-15 03:48:05,904:INFO:Declaring metric variables
2025-10-15 03:48:05,916:INFO:Importing untrained model
2025-10-15 03:48:05,921:INFO:Random Forest Classifier Imported successfully
2025-10-15 03:48:05,934:INFO:Starting cross validation
2025-10-15 03:48:05,934:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 03:48:26,722:INFO:Calculating mean and std
2025-10-15 03:48:26,735:INFO:Creating metrics dataframe
2025-10-15 03:48:26,746:INFO:Uploading results into container
2025-10-15 03:48:26,746:INFO:Uploading model into container now
2025-10-15 03:48:26,746:INFO:_master_model_container: 7
2025-10-15 03:48:26,746:INFO:_display_container: 2
2025-10-15 03:48:26,746:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-10-15 03:48:26,746:INFO:create_model() successfully completed......................................
2025-10-15 03:48:27,019:INFO:SubProcess create_model() end ==================================
2025-10-15 03:48:27,019:INFO:Creating metrics dataframe
2025-10-15 03:48:27,049:INFO:Initializing Quadratic Discriminant Analysis
2025-10-15 03:48:27,049:INFO:Total runtime is 2.140041486422221 minutes
2025-10-15 03:48:27,059:INFO:SubProcess create_model() called ==================================
2025-10-15 03:48:27,059:INFO:Initializing create_model()
2025-10-15 03:48:27,059:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A988865300>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A9D306FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:48:27,059:INFO:Checking exceptions
2025-10-15 03:48:27,059:INFO:Importing libraries
2025-10-15 03:48:27,059:INFO:Copying training dataset
2025-10-15 03:48:27,327:INFO:Defining folds
2025-10-15 03:48:27,327:INFO:Declaring metric variables
2025-10-15 03:48:27,347:INFO:Importing untrained model
2025-10-15 03:48:27,360:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-15 03:48:27,383:INFO:Starting cross validation
2025-10-15 03:48:27,385:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 03:48:30,600:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-15 03:48:31,113:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-15 03:48:31,302:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-15 03:48:31,964:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-15 03:48:33,294:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-15 03:48:33,660:INFO:Calculating mean and std
2025-10-15 03:48:33,662:INFO:Creating metrics dataframe
2025-10-15 03:48:33,673:INFO:Uploading results into container
2025-10-15 03:48:33,677:INFO:Uploading model into container now
2025-10-15 03:48:33,682:INFO:_master_model_container: 8
2025-10-15 03:48:33,683:INFO:_display_container: 2
2025-10-15 03:48:33,683:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-15 03:48:33,683:INFO:create_model() successfully completed......................................
2025-10-15 03:48:33,935:INFO:SubProcess create_model() end ==================================
2025-10-15 03:48:33,935:INFO:Creating metrics dataframe
2025-10-15 03:48:33,968:INFO:Initializing Ada Boost Classifier
2025-10-15 03:48:33,968:INFO:Total runtime is 2.2553480982780454 minutes
2025-10-15 03:48:33,976:INFO:SubProcess create_model() called ==================================
2025-10-15 03:48:33,976:INFO:Initializing create_model()
2025-10-15 03:48:33,976:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A988865300>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A9D306FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:48:33,986:INFO:Checking exceptions
2025-10-15 03:48:33,986:INFO:Importing libraries
2025-10-15 03:48:33,986:INFO:Copying training dataset
2025-10-15 03:48:34,533:INFO:Defining folds
2025-10-15 03:48:34,533:INFO:Declaring metric variables
2025-10-15 03:48:34,580:INFO:Importing untrained model
2025-10-15 03:48:34,590:INFO:Ada Boost Classifier Imported successfully
2025-10-15 03:48:34,719:INFO:Starting cross validation
2025-10-15 03:48:34,728:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 03:48:35,510:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-15 03:48:35,911:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-15 03:48:36,184:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-15 03:48:36,901:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-15 03:49:01,203:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-15 03:49:13,293:INFO:Calculating mean and std
2025-10-15 03:49:13,362:INFO:Creating metrics dataframe
2025-10-15 03:49:13,391:INFO:Uploading results into container
2025-10-15 03:49:13,394:INFO:Uploading model into container now
2025-10-15 03:49:13,406:INFO:_master_model_container: 9
2025-10-15 03:49:13,406:INFO:_display_container: 2
2025-10-15 03:49:13,421:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-10-15 03:49:13,422:INFO:create_model() successfully completed......................................
2025-10-15 03:49:14,309:INFO:SubProcess create_model() end ==================================
2025-10-15 03:49:14,309:INFO:Creating metrics dataframe
2025-10-15 03:49:14,473:INFO:Initializing Gradient Boosting Classifier
2025-10-15 03:49:14,473:INFO:Total runtime is 2.93044163386027 minutes
2025-10-15 03:49:14,535:INFO:SubProcess create_model() called ==================================
2025-10-15 03:49:14,539:INFO:Initializing create_model()
2025-10-15 03:49:14,540:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A988865300>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A9D306FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:49:14,541:INFO:Checking exceptions
2025-10-15 03:49:14,541:INFO:Importing libraries
2025-10-15 03:49:14,542:INFO:Copying training dataset
2025-10-15 03:49:16,176:INFO:Defining folds
2025-10-15 03:49:16,176:INFO:Declaring metric variables
2025-10-15 03:49:16,300:INFO:Importing untrained model
2025-10-15 03:49:16,565:INFO:Gradient Boosting Classifier Imported successfully
2025-10-15 03:49:16,724:INFO:Starting cross validation
2025-10-15 03:49:16,738:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 03:49:55,878:INFO:Calculating mean and std
2025-10-15 03:49:55,878:INFO:Creating metrics dataframe
2025-10-15 03:49:55,886:INFO:Uploading results into container
2025-10-15 03:49:55,889:INFO:Uploading model into container now
2025-10-15 03:49:55,890:INFO:_master_model_container: 10
2025-10-15 03:49:55,891:INFO:_display_container: 2
2025-10-15 03:49:55,893:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-15 03:49:55,893:INFO:create_model() successfully completed......................................
2025-10-15 03:49:56,080:INFO:SubProcess create_model() end ==================================
2025-10-15 03:49:56,080:INFO:Creating metrics dataframe
2025-10-15 03:49:56,111:INFO:Initializing Linear Discriminant Analysis
2025-10-15 03:49:56,111:INFO:Total runtime is 3.6244129021962483 minutes
2025-10-15 03:49:56,127:INFO:SubProcess create_model() called ==================================
2025-10-15 03:49:56,127:INFO:Initializing create_model()
2025-10-15 03:49:56,127:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A988865300>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A9D306FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:49:56,127:INFO:Checking exceptions
2025-10-15 03:49:56,127:INFO:Importing libraries
2025-10-15 03:49:56,127:INFO:Copying training dataset
2025-10-15 03:49:56,346:INFO:Defining folds
2025-10-15 03:49:56,346:INFO:Declaring metric variables
2025-10-15 03:49:56,366:INFO:Importing untrained model
2025-10-15 03:49:56,380:INFO:Linear Discriminant Analysis Imported successfully
2025-10-15 03:49:56,413:INFO:Starting cross validation
2025-10-15 03:49:56,417:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 03:50:00,530:INFO:Calculating mean and std
2025-10-15 03:50:00,530:INFO:Creating metrics dataframe
2025-10-15 03:50:00,543:INFO:Uploading results into container
2025-10-15 03:50:00,543:INFO:Uploading model into container now
2025-10-15 03:50:00,543:INFO:_master_model_container: 11
2025-10-15 03:50:00,543:INFO:_display_container: 2
2025-10-15 03:50:00,543:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-15 03:50:00,543:INFO:create_model() successfully completed......................................
2025-10-15 03:50:00,854:INFO:SubProcess create_model() end ==================================
2025-10-15 03:50:00,854:INFO:Creating metrics dataframe
2025-10-15 03:50:00,890:INFO:Initializing Extra Trees Classifier
2025-10-15 03:50:00,891:INFO:Total runtime is 3.7040739258130393 minutes
2025-10-15 03:50:00,899:INFO:SubProcess create_model() called ==================================
2025-10-15 03:50:00,899:INFO:Initializing create_model()
2025-10-15 03:50:00,899:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A988865300>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A9D306FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:50:00,899:INFO:Checking exceptions
2025-10-15 03:50:00,899:INFO:Importing libraries
2025-10-15 03:50:00,899:INFO:Copying training dataset
2025-10-15 03:50:01,246:INFO:Defining folds
2025-10-15 03:50:01,246:INFO:Declaring metric variables
2025-10-15 03:50:01,264:INFO:Importing untrained model
2025-10-15 03:50:01,276:INFO:Extra Trees Classifier Imported successfully
2025-10-15 03:50:01,301:INFO:Starting cross validation
2025-10-15 03:50:01,311:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 03:50:51,168:INFO:Calculating mean and std
2025-10-15 03:50:51,184:INFO:Creating metrics dataframe
2025-10-15 03:50:51,208:INFO:Uploading results into container
2025-10-15 03:50:51,215:INFO:Uploading model into container now
2025-10-15 03:50:51,218:INFO:_master_model_container: 12
2025-10-15 03:50:51,218:INFO:_display_container: 2
2025-10-15 03:50:51,244:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-10-15 03:50:51,248:INFO:create_model() successfully completed......................................
2025-10-15 03:50:51,736:INFO:SubProcess create_model() end ==================================
2025-10-15 03:50:51,736:INFO:Creating metrics dataframe
2025-10-15 03:50:51,840:INFO:Initializing Extreme Gradient Boosting
2025-10-15 03:50:51,848:INFO:Total runtime is 4.553362953662872 minutes
2025-10-15 03:50:51,871:INFO:SubProcess create_model() called ==================================
2025-10-15 03:50:51,871:INFO:Initializing create_model()
2025-10-15 03:50:51,871:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A988865300>, estimator=xgboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A9D306FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:50:51,871:INFO:Checking exceptions
2025-10-15 03:50:51,871:INFO:Importing libraries
2025-10-15 03:50:51,871:INFO:Copying training dataset
2025-10-15 03:50:53,338:INFO:Defining folds
2025-10-15 03:50:53,338:INFO:Declaring metric variables
2025-10-15 03:50:53,404:INFO:Importing untrained model
2025-10-15 03:50:53,496:INFO:Extreme Gradient Boosting Imported successfully
2025-10-15 03:50:53,609:INFO:Starting cross validation
2025-10-15 03:50:53,635:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 03:51:27,324:INFO:Calculating mean and std
2025-10-15 03:51:27,326:INFO:Creating metrics dataframe
2025-10-15 03:51:27,333:INFO:Uploading results into container
2025-10-15 03:51:27,335:INFO:Uploading model into container now
2025-10-15 03:51:27,336:INFO:_master_model_container: 13
2025-10-15 03:51:27,336:INFO:_display_container: 2
2025-10-15 03:51:27,345:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-10-15 03:51:27,345:INFO:create_model() successfully completed......................................
2025-10-15 03:51:27,569:INFO:SubProcess create_model() end ==================================
2025-10-15 03:51:27,569:INFO:Creating metrics dataframe
2025-10-15 03:51:27,599:INFO:Initializing Light Gradient Boosting Machine
2025-10-15 03:51:27,599:INFO:Total runtime is 5.149211617310842 minutes
2025-10-15 03:51:27,615:INFO:SubProcess create_model() called ==================================
2025-10-15 03:51:27,615:INFO:Initializing create_model()
2025-10-15 03:51:27,615:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A988865300>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A9D306FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:51:27,615:INFO:Checking exceptions
2025-10-15 03:51:27,615:INFO:Importing libraries
2025-10-15 03:51:27,615:INFO:Copying training dataset
2025-10-15 03:51:27,974:INFO:Defining folds
2025-10-15 03:51:27,974:INFO:Declaring metric variables
2025-10-15 03:51:27,993:INFO:Importing untrained model
2025-10-15 03:51:28,034:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-15 03:51:28,053:INFO:Starting cross validation
2025-10-15 03:51:28,056:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 03:51:34,331:INFO:Calculating mean and std
2025-10-15 03:51:34,331:INFO:Creating metrics dataframe
2025-10-15 03:51:34,342:INFO:Uploading results into container
2025-10-15 03:51:34,342:INFO:Uploading model into container now
2025-10-15 03:51:34,342:INFO:_master_model_container: 14
2025-10-15 03:51:34,350:INFO:_display_container: 2
2025-10-15 03:51:34,350:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-15 03:51:34,352:INFO:create_model() successfully completed......................................
2025-10-15 03:51:34,595:INFO:SubProcess create_model() end ==================================
2025-10-15 03:51:34,595:INFO:Creating metrics dataframe
2025-10-15 03:51:34,628:INFO:Initializing Dummy Classifier
2025-10-15 03:51:34,629:INFO:Total runtime is 5.266365293661753 minutes
2025-10-15 03:51:34,634:INFO:SubProcess create_model() called ==================================
2025-10-15 03:51:34,636:INFO:Initializing create_model()
2025-10-15 03:51:34,636:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A988865300>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A9D306FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:51:34,636:INFO:Checking exceptions
2025-10-15 03:51:34,636:INFO:Importing libraries
2025-10-15 03:51:34,636:INFO:Copying training dataset
2025-10-15 03:51:34,968:INFO:Defining folds
2025-10-15 03:51:34,968:INFO:Declaring metric variables
2025-10-15 03:51:34,978:INFO:Importing untrained model
2025-10-15 03:51:34,992:INFO:Dummy Classifier Imported successfully
2025-10-15 03:51:35,010:INFO:Starting cross validation
2025-10-15 03:51:35,010:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 03:51:35,701:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-15 03:51:35,742:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-15 03:51:35,762:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-15 03:51:35,895:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-15 03:51:36,014:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-15 03:51:36,044:INFO:Calculating mean and std
2025-10-15 03:51:36,046:INFO:Creating metrics dataframe
2025-10-15 03:51:36,046:INFO:Uploading results into container
2025-10-15 03:51:36,046:INFO:Uploading model into container now
2025-10-15 03:51:36,057:INFO:_master_model_container: 15
2025-10-15 03:51:36,057:INFO:_display_container: 2
2025-10-15 03:51:36,057:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-10-15 03:51:36,057:INFO:create_model() successfully completed......................................
2025-10-15 03:51:36,506:INFO:SubProcess create_model() end ==================================
2025-10-15 03:51:36,507:INFO:Creating metrics dataframe
2025-10-15 03:51:36,581:INFO:Initializing create_model()
2025-10-15 03:51:36,581:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A988865300>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:51:36,581:INFO:Checking exceptions
2025-10-15 03:51:36,584:INFO:Importing libraries
2025-10-15 03:51:36,588:INFO:Copying training dataset
2025-10-15 03:51:36,992:INFO:Defining folds
2025-10-15 03:51:36,992:INFO:Declaring metric variables
2025-10-15 03:51:36,992:INFO:Importing untrained model
2025-10-15 03:51:36,992:INFO:Declaring custom model
2025-10-15 03:51:36,992:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-15 03:51:36,992:INFO:Cross validation set to False
2025-10-15 03:51:37,000:INFO:Fitting Model
2025-10-15 03:51:37,270:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 03:51:37,298:INFO:[LightGBM] [Info] Number of positive: 7846, number of negative: 23809
2025-10-15 03:51:37,341:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015531 seconds.
2025-10-15 03:51:37,341:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 03:51:37,341:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 03:51:37,341:INFO:[LightGBM] [Info] Total Bins 514
2025-10-15 03:51:37,341:INFO:[LightGBM] [Info] Number of data points in the train set: 31655, number of used features: 90
2025-10-15 03:51:37,341:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247860 -> initscore=-1.110060
2025-10-15 03:51:37,341:INFO:[LightGBM] [Info] Start training from score -1.110060
2025-10-15 03:51:38,642:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-15 03:51:38,642:INFO:create_model() successfully completed......................................
2025-10-15 03:51:38,915:INFO:Initializing create_model()
2025-10-15 03:51:38,916:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A988865300>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:51:38,917:INFO:Checking exceptions
2025-10-15 03:51:38,925:INFO:Importing libraries
2025-10-15 03:51:38,925:INFO:Copying training dataset
2025-10-15 03:51:39,240:INFO:Defining folds
2025-10-15 03:51:39,240:INFO:Declaring metric variables
2025-10-15 03:51:39,240:INFO:Importing untrained model
2025-10-15 03:51:39,240:INFO:Declaring custom model
2025-10-15 03:51:39,250:INFO:Extreme Gradient Boosting Imported successfully
2025-10-15 03:51:39,250:INFO:Cross validation set to False
2025-10-15 03:51:39,268:INFO:Fitting Model
2025-10-15 03:51:41,614:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-10-15 03:51:41,621:INFO:create_model() successfully completed......................................
2025-10-15 03:51:41,908:INFO:Initializing create_model()
2025-10-15 03:51:41,909:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A988865300>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:51:41,909:INFO:Checking exceptions
2025-10-15 03:51:41,914:INFO:Importing libraries
2025-10-15 03:51:41,914:INFO:Copying training dataset
2025-10-15 03:51:42,325:INFO:Defining folds
2025-10-15 03:51:42,326:INFO:Declaring metric variables
2025-10-15 03:51:42,326:INFO:Importing untrained model
2025-10-15 03:51:42,326:INFO:Declaring custom model
2025-10-15 03:51:42,329:INFO:Gradient Boosting Classifier Imported successfully
2025-10-15 03:51:42,331:INFO:Cross validation set to False
2025-10-15 03:51:42,331:INFO:Fitting Model
2025-10-15 03:52:36,089:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-15 03:52:36,100:INFO:create_model() successfully completed......................................
2025-10-15 03:52:38,068:INFO:Initializing create_model()
2025-10-15 03:52:38,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A988865300>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:52:38,076:INFO:Checking exceptions
2025-10-15 03:52:38,215:INFO:Importing libraries
2025-10-15 03:52:38,216:INFO:Copying training dataset
2025-10-15 03:52:39,642:INFO:Defining folds
2025-10-15 03:52:39,642:INFO:Declaring metric variables
2025-10-15 03:52:39,695:INFO:Importing untrained model
2025-10-15 03:52:39,703:INFO:Declaring custom model
2025-10-15 03:52:39,705:INFO:Ada Boost Classifier Imported successfully
2025-10-15 03:52:39,705:INFO:Cross validation set to False
2025-10-15 03:52:39,713:INFO:Fitting Model
2025-10-15 03:52:44,400:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-10-15 03:52:44,400:INFO:create_model() successfully completed......................................
2025-10-15 03:52:44,722:INFO:Initializing create_model()
2025-10-15 03:52:44,722:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A988865300>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:52:44,722:INFO:Checking exceptions
2025-10-15 03:52:44,730:INFO:Importing libraries
2025-10-15 03:52:44,730:INFO:Copying training dataset
2025-10-15 03:52:45,101:INFO:Defining folds
2025-10-15 03:52:45,101:INFO:Declaring metric variables
2025-10-15 03:52:45,101:INFO:Importing untrained model
2025-10-15 03:52:45,101:INFO:Declaring custom model
2025-10-15 03:52:45,101:INFO:Logistic Regression Imported successfully
2025-10-15 03:52:45,101:INFO:Cross validation set to False
2025-10-15 03:52:45,101:INFO:Fitting Model
2025-10-15 03:52:46,452:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-15 03:52:46,452:INFO:create_model() successfully completed......................................
2025-10-15 03:52:46,827:INFO:_master_model_container: 15
2025-10-15 03:52:46,828:INFO:_display_container: 2
2025-10-15 03:52:46,832:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)]
2025-10-15 03:52:46,832:INFO:compare_models() successfully completed......................................
2025-10-15 03:52:46,883:INFO:Initializing blend_models()
2025-10-15 03:52:46,884:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A988865300>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-15 03:52:46,884:INFO:Checking exceptions
2025-10-15 03:52:47,134:INFO:Importing libraries
2025-10-15 03:52:47,135:INFO:Copying training dataset
2025-10-15 03:52:47,147:INFO:Getting model names
2025-10-15 03:52:47,161:INFO:SubProcess create_model() called ==================================
2025-10-15 03:52:47,201:INFO:Initializing create_model()
2025-10-15 03:52:47,201:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A988865300>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                 random_state=42)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=42,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A9DC94E0E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:52:47,201:INFO:Checking exceptions
2025-10-15 03:52:47,201:INFO:Importing libraries
2025-10-15 03:52:47,201:INFO:Copying training dataset
2025-10-15 03:52:47,598:INFO:Defining folds
2025-10-15 03:52:47,598:INFO:Declaring metric variables
2025-10-15 03:52:47,616:INFO:Importing untrained model
2025-10-15 03:52:47,616:INFO:Declaring custom model
2025-10-15 03:52:47,628:INFO:Voting Classifier Imported successfully
2025-10-15 03:52:47,661:INFO:Starting cross validation
2025-10-15 03:52:47,663:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 03:52:48,598:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-15 03:52:49,197:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-15 03:52:49,678:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-15 03:52:50,624:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-15 03:53:20,574:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-15 03:54:26,076:INFO:Calculating mean and std
2025-10-15 03:54:26,076:INFO:Creating metrics dataframe
2025-10-15 03:54:26,117:INFO:Finalizing model
2025-10-15 03:55:47,895:INFO:PyCaret ClassificationExperiment
2025-10-15 03:55:47,896:INFO:Logging name: CharityML_PyCaret_AutoML
2025-10-15 03:55:47,897:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-15 03:55:47,898:INFO:version 3.3.2
2025-10-15 03:55:47,899:INFO:Initializing setup()
2025-10-15 03:55:47,900:INFO:self.USI: 20cb
2025-10-15 03:55:47,900:INFO:self._variable_keys: {'X', 'seed', 'log_plots_param', 'pipeline', 'USI', 'fold_shuffle_param', 'X_train', 'target_param', 'y_test', 'fold_groups_param', 'exp_name_log', '_available_plots', '_ml_usecase', 'fix_imbalance', 'exp_id', 'n_jobs_param', 'gpu_n_jobs_param', 'memory', 'X_test', 'fold_generator', 'y', 'gpu_param', 'data', 'is_multiclass', 'y_train', 'logging_param', 'idx', 'html_param'}
2025-10-15 03:55:47,901:INFO:Checking environment
2025-10-15 03:55:47,903:INFO:python_version: 3.10.0
2025-10-15 03:55:47,904:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-10-15 03:55:47,904:INFO:machine: AMD64
2025-10-15 03:55:47,905:INFO:platform: Windows-10-10.0.19045-SP0
2025-10-15 03:55:47,940:INFO:Memory: svmem(total=8465043456, available=1220960256, percent=85.6, used=7244083200, free=1220960256)
2025-10-15 03:55:47,941:INFO:Physical Core: 2
2025-10-15 03:55:47,941:INFO:Logical Core: 4
2025-10-15 03:55:47,943:INFO:Checking libraries
2025-10-15 03:55:47,944:INFO:System:
2025-10-15 03:55:47,944:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-10-15 03:55:47,947:INFO:executable: c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\Scripts\python.exe
2025-10-15 03:55:47,948:INFO:   machine: Windows-10-10.0.19045-SP0
2025-10-15 03:55:47,948:INFO:PyCaret required dependencies:
2025-10-15 03:55:47,951:INFO:                 pip: 25.2
2025-10-15 03:55:47,952:INFO:          setuptools: 57.4.0
2025-10-15 03:55:47,953:INFO:             pycaret: 3.3.2
2025-10-15 03:55:47,953:INFO:             IPython: 8.37.0
2025-10-15 03:55:47,955:INFO:          ipywidgets: 8.1.7
2025-10-15 03:55:47,956:INFO:                tqdm: 4.67.1
2025-10-15 03:55:47,957:INFO:               numpy: 1.26.4
2025-10-15 03:55:47,958:INFO:              pandas: 2.0.3
2025-10-15 03:55:47,959:INFO:              jinja2: 3.1.6
2025-10-15 03:55:47,959:INFO:               scipy: 1.11.4
2025-10-15 03:55:47,962:INFO:              joblib: 1.3.2
2025-10-15 03:55:47,963:INFO:             sklearn: 1.4.2
2025-10-15 03:55:47,963:INFO:                pyod: 2.0.5
2025-10-15 03:55:47,964:INFO:            imblearn: 0.14.0
2025-10-15 03:55:47,965:INFO:   category_encoders: 2.7.0
2025-10-15 03:55:47,965:INFO:            lightgbm: 4.6.0
2025-10-15 03:55:47,966:INFO:               numba: 0.62.1
2025-10-15 03:55:47,967:INFO:            requests: 2.32.5
2025-10-15 03:55:47,968:INFO:          matplotlib: 3.7.5
2025-10-15 03:55:47,969:INFO:          scikitplot: 0.3.7
2025-10-15 03:55:47,970:INFO:         yellowbrick: 1.5
2025-10-15 03:55:47,970:INFO:              plotly: 6.3.1
2025-10-15 03:55:47,971:INFO:    plotly-resampler: Not installed
2025-10-15 03:55:47,972:INFO:             kaleido: 1.1.0
2025-10-15 03:55:47,972:INFO:           schemdraw: 0.15
2025-10-15 03:55:47,973:INFO:         statsmodels: 0.14.5
2025-10-15 03:55:47,973:INFO:              sktime: 0.26.0
2025-10-15 03:55:47,974:INFO:               tbats: 1.1.3
2025-10-15 03:55:47,974:INFO:            pmdarima: 2.0.4
2025-10-15 03:55:48,032:INFO:              psutil: 7.1.0
2025-10-15 03:55:48,032:INFO:          markupsafe: 3.0.3
2025-10-15 03:55:48,034:INFO:             pickle5: Not installed
2025-10-15 03:55:48,035:INFO:         cloudpickle: 3.1.1
2025-10-15 03:55:48,036:INFO:         deprecation: 2.1.0
2025-10-15 03:55:48,037:INFO:              xxhash: 3.6.0
2025-10-15 03:55:48,037:INFO:           wurlitzer: Not installed
2025-10-15 03:55:48,039:INFO:PyCaret optional dependencies:
2025-10-15 03:55:48,041:INFO:                shap: Not installed
2025-10-15 03:55:48,042:INFO:           interpret: Not installed
2025-10-15 03:55:48,044:INFO:                umap: Not installed
2025-10-15 03:55:48,044:INFO:     ydata_profiling: Not installed
2025-10-15 03:55:48,045:INFO:  explainerdashboard: Not installed
2025-10-15 03:55:48,047:INFO:             autoviz: Not installed
2025-10-15 03:55:48,047:INFO:           fairlearn: Not installed
2025-10-15 03:55:48,048:INFO:          deepchecks: Not installed
2025-10-15 03:55:48,049:INFO:             xgboost: 2.1.4
2025-10-15 03:55:48,049:INFO:            catboost: Not installed
2025-10-15 03:55:48,050:INFO:              kmodes: Not installed
2025-10-15 03:55:48,050:INFO:             mlxtend: Not installed
2025-10-15 03:55:48,051:INFO:       statsforecast: Not installed
2025-10-15 03:55:48,052:INFO:        tune_sklearn: Not installed
2025-10-15 03:55:48,053:INFO:                 ray: Not installed
2025-10-15 03:55:48,053:INFO:            hyperopt: Not installed
2025-10-15 03:55:48,053:INFO:              optuna: Not installed
2025-10-15 03:55:48,055:INFO:               skopt: Not installed
2025-10-15 03:55:48,056:INFO:              mlflow: 3.4.0
2025-10-15 03:55:48,056:INFO:              gradio: Not installed
2025-10-15 03:55:48,057:INFO:             fastapi: 0.119.0
2025-10-15 03:55:48,058:INFO:             uvicorn: 0.37.0
2025-10-15 03:55:48,059:INFO:              m2cgen: Not installed
2025-10-15 03:55:48,059:INFO:           evidently: Not installed
2025-10-15 03:55:48,060:INFO:               fugue: Not installed
2025-10-15 03:55:48,061:INFO:           streamlit: Not installed
2025-10-15 03:55:48,061:INFO:             prophet: Not installed
2025-10-15 03:55:48,062:INFO:None
2025-10-15 03:55:48,062:INFO:Set up data.
2025-10-15 03:55:50,291:INFO:Set up folding strategy.
2025-10-15 03:55:50,292:INFO:Set up train/test split.
2025-10-15 03:55:53,823:INFO:Set up index.
2025-10-15 03:55:54,011:INFO:Assigning column types.
2025-10-15 03:55:58,329:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-15 03:56:00,332:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-15 03:56:00,394:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-15 03:56:02,080:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:56:02,257:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:56:03,679:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-15 03:56:03,689:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-15 03:56:04,108:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:56:04,128:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:56:04,128:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-15 03:56:04,505:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-15 03:56:04,730:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:56:04,748:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:56:05,399:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-15 03:56:05,813:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:56:05,854:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:56:05,854:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-15 03:56:06,739:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:56:06,760:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:56:07,261:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:56:07,282:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:56:07,342:INFO:Set up column name cleaning.
2025-10-15 03:56:07,707:INFO:Finished creating preprocessing pipeline.
2025-10-15 03:56:07,715:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Khaled\AppData\Local\Temp\joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-15 03:56:07,718:INFO:Creating final display dataframe.
2025-10-15 03:56:10,093:INFO:Setup _display_container:                    Description         Value
0                   Session id            42
1                       Target        donate
2                  Target type        Binary
3          Original data shape  (45222, 104)
4       Transformed data shape  (45222, 104)
5  Transformed train set shape  (31655, 104)
6   Transformed test set shape  (13567, 104)
7             Numeric features           103
2025-10-15 03:56:10,649:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:56:10,659:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:56:11,037:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 03:56:11,047:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 03:56:11,057:INFO:setup() successfully completed in 23.31s...............
2025-10-15 03:56:11,067:INFO:Initializing compare_models()
2025-10-15 03:56:11,067:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-10-15 03:56:11,067:INFO:Checking exceptions
2025-10-15 03:56:11,321:INFO:Preparing display monitor
2025-10-15 03:56:11,491:INFO:Initializing Logistic Regression
2025-10-15 03:56:11,491:INFO:Total runtime is 0.0 minutes
2025-10-15 03:56:11,502:INFO:SubProcess create_model() called ==================================
2025-10-15 03:56:11,502:INFO:Initializing create_model()
2025-10-15 03:56:11,504:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A983A9B5E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:56:11,504:INFO:Checking exceptions
2025-10-15 03:56:11,504:INFO:Importing libraries
2025-10-15 03:56:11,504:INFO:Copying training dataset
2025-10-15 03:56:12,091:INFO:Defining folds
2025-10-15 03:56:12,091:INFO:Declaring metric variables
2025-10-15 03:56:12,101:INFO:Importing untrained model
2025-10-15 03:56:12,111:INFO:Logistic Regression Imported successfully
2025-10-15 03:56:12,141:INFO:Starting cross validation
2025-10-15 03:56:12,141:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 03:56:39,986:INFO:Calculating mean and std
2025-10-15 03:56:39,986:INFO:Creating metrics dataframe
2025-10-15 03:56:39,996:INFO:Uploading results into container
2025-10-15 03:56:39,996:INFO:Uploading model into container now
2025-10-15 03:56:39,996:INFO:_master_model_container: 1
2025-10-15 03:56:39,996:INFO:_display_container: 2
2025-10-15 03:56:39,996:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-15 03:56:39,996:INFO:create_model() successfully completed......................................
2025-10-15 03:56:40,384:INFO:SubProcess create_model() end ==================================
2025-10-15 03:56:40,384:INFO:Creating metrics dataframe
2025-10-15 03:56:40,414:INFO:Initializing K Neighbors Classifier
2025-10-15 03:56:40,414:INFO:Total runtime is 0.4820413510004679 minutes
2025-10-15 03:56:40,454:INFO:SubProcess create_model() called ==================================
2025-10-15 03:56:40,454:INFO:Initializing create_model()
2025-10-15 03:56:40,454:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A983A9B5E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:56:40,454:INFO:Checking exceptions
2025-10-15 03:56:40,454:INFO:Importing libraries
2025-10-15 03:56:40,454:INFO:Copying training dataset
2025-10-15 03:56:40,932:INFO:Defining folds
2025-10-15 03:56:40,932:INFO:Declaring metric variables
2025-10-15 03:56:40,952:INFO:Importing untrained model
2025-10-15 03:56:40,962:INFO:K Neighbors Classifier Imported successfully
2025-10-15 03:56:40,990:INFO:Starting cross validation
2025-10-15 03:56:40,992:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 03:58:14,713:INFO:Calculating mean and std
2025-10-15 03:58:14,713:INFO:Creating metrics dataframe
2025-10-15 03:58:14,713:INFO:Uploading results into container
2025-10-15 03:58:14,713:INFO:Uploading model into container now
2025-10-15 03:58:14,713:INFO:_master_model_container: 2
2025-10-15 03:58:14,713:INFO:_display_container: 2
2025-10-15 03:58:14,713:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-15 03:58:14,713:INFO:create_model() successfully completed......................................
2025-10-15 03:58:14,927:INFO:SubProcess create_model() end ==================================
2025-10-15 03:58:14,927:INFO:Creating metrics dataframe
2025-10-15 03:58:14,976:INFO:Initializing Naive Bayes
2025-10-15 03:58:14,977:INFO:Total runtime is 2.0580960790316265 minutes
2025-10-15 03:58:14,983:INFO:SubProcess create_model() called ==================================
2025-10-15 03:58:14,984:INFO:Initializing create_model()
2025-10-15 03:58:14,984:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A983A9B5E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:58:14,984:INFO:Checking exceptions
2025-10-15 03:58:14,984:INFO:Importing libraries
2025-10-15 03:58:14,985:INFO:Copying training dataset
2025-10-15 03:58:15,351:INFO:Defining folds
2025-10-15 03:58:15,351:INFO:Declaring metric variables
2025-10-15 03:58:15,361:INFO:Importing untrained model
2025-10-15 03:58:15,371:INFO:Naive Bayes Imported successfully
2025-10-15 03:58:15,418:INFO:Starting cross validation
2025-10-15 03:58:15,424:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 03:58:17,607:INFO:Calculating mean and std
2025-10-15 03:58:17,621:INFO:Creating metrics dataframe
2025-10-15 03:58:17,629:INFO:Uploading results into container
2025-10-15 03:58:17,630:INFO:Uploading model into container now
2025-10-15 03:58:17,631:INFO:_master_model_container: 3
2025-10-15 03:58:17,631:INFO:_display_container: 2
2025-10-15 03:58:17,631:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-15 03:58:17,631:INFO:create_model() successfully completed......................................
2025-10-15 03:58:17,960:INFO:SubProcess create_model() end ==================================
2025-10-15 03:58:17,960:INFO:Creating metrics dataframe
2025-10-15 03:58:17,991:INFO:Initializing Decision Tree Classifier
2025-10-15 03:58:17,991:INFO:Total runtime is 2.1083196640014648 minutes
2025-10-15 03:58:18,001:INFO:SubProcess create_model() called ==================================
2025-10-15 03:58:18,001:INFO:Initializing create_model()
2025-10-15 03:58:18,001:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A983A9B5E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:58:18,001:INFO:Checking exceptions
2025-10-15 03:58:18,001:INFO:Importing libraries
2025-10-15 03:58:18,001:INFO:Copying training dataset
2025-10-15 03:58:18,529:INFO:Defining folds
2025-10-15 03:58:18,529:INFO:Declaring metric variables
2025-10-15 03:58:18,541:INFO:Importing untrained model
2025-10-15 03:58:18,552:INFO:Decision Tree Classifier Imported successfully
2025-10-15 03:58:18,582:INFO:Starting cross validation
2025-10-15 03:58:18,582:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 03:58:21,922:INFO:Calculating mean and std
2025-10-15 03:58:21,922:INFO:Creating metrics dataframe
2025-10-15 03:58:21,932:INFO:Uploading results into container
2025-10-15 03:58:21,934:INFO:Uploading model into container now
2025-10-15 03:58:21,935:INFO:_master_model_container: 4
2025-10-15 03:58:21,935:INFO:_display_container: 2
2025-10-15 03:58:21,936:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-10-15 03:58:21,936:INFO:create_model() successfully completed......................................
2025-10-15 03:58:22,237:INFO:SubProcess create_model() end ==================================
2025-10-15 03:58:22,237:INFO:Creating metrics dataframe
2025-10-15 03:58:22,267:INFO:Initializing SVM - Linear Kernel
2025-10-15 03:58:22,267:INFO:Total runtime is 2.1795914371808367 minutes
2025-10-15 03:58:22,297:INFO:SubProcess create_model() called ==================================
2025-10-15 03:58:22,297:INFO:Initializing create_model()
2025-10-15 03:58:22,297:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A983A9B5E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:58:22,297:INFO:Checking exceptions
2025-10-15 03:58:22,297:INFO:Importing libraries
2025-10-15 03:58:22,297:INFO:Copying training dataset
2025-10-15 03:58:22,692:INFO:Defining folds
2025-10-15 03:58:22,692:INFO:Declaring metric variables
2025-10-15 03:58:22,709:INFO:Importing untrained model
2025-10-15 03:58:22,722:INFO:SVM - Linear Kernel Imported successfully
2025-10-15 03:58:22,753:INFO:Starting cross validation
2025-10-15 03:58:22,753:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 03:58:25,875:INFO:Calculating mean and std
2025-10-15 03:58:25,877:INFO:Creating metrics dataframe
2025-10-15 03:58:25,885:INFO:Uploading results into container
2025-10-15 03:58:25,886:INFO:Uploading model into container now
2025-10-15 03:58:25,887:INFO:_master_model_container: 5
2025-10-15 03:58:25,887:INFO:_display_container: 2
2025-10-15 03:58:25,888:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-15 03:58:25,888:INFO:create_model() successfully completed......................................
2025-10-15 03:58:26,294:INFO:SubProcess create_model() end ==================================
2025-10-15 03:58:26,294:INFO:Creating metrics dataframe
2025-10-15 03:58:26,315:INFO:Initializing Ridge Classifier
2025-10-15 03:58:26,315:INFO:Total runtime is 2.247050627072652 minutes
2025-10-15 03:58:26,325:INFO:SubProcess create_model() called ==================================
2025-10-15 03:58:26,325:INFO:Initializing create_model()
2025-10-15 03:58:26,325:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A983A9B5E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:58:26,325:INFO:Checking exceptions
2025-10-15 03:58:26,325:INFO:Importing libraries
2025-10-15 03:58:26,325:INFO:Copying training dataset
2025-10-15 03:58:26,660:INFO:Defining folds
2025-10-15 03:58:26,660:INFO:Declaring metric variables
2025-10-15 03:58:26,675:INFO:Importing untrained model
2025-10-15 03:58:26,683:INFO:Ridge Classifier Imported successfully
2025-10-15 03:58:26,703:INFO:Starting cross validation
2025-10-15 03:58:26,706:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 03:58:28,064:INFO:Calculating mean and std
2025-10-15 03:58:28,066:INFO:Creating metrics dataframe
2025-10-15 03:58:28,072:INFO:Uploading results into container
2025-10-15 03:58:28,073:INFO:Uploading model into container now
2025-10-15 03:58:28,074:INFO:_master_model_container: 6
2025-10-15 03:58:28,074:INFO:_display_container: 2
2025-10-15 03:58:28,075:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-15 03:58:28,075:INFO:create_model() successfully completed......................................
2025-10-15 03:58:28,351:INFO:SubProcess create_model() end ==================================
2025-10-15 03:58:28,351:INFO:Creating metrics dataframe
2025-10-15 03:58:28,371:INFO:Initializing Random Forest Classifier
2025-10-15 03:58:28,371:INFO:Total runtime is 2.281330589453379 minutes
2025-10-15 03:58:28,379:INFO:SubProcess create_model() called ==================================
2025-10-15 03:58:28,379:INFO:Initializing create_model()
2025-10-15 03:58:28,379:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A983A9B5E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:58:28,379:INFO:Checking exceptions
2025-10-15 03:58:28,379:INFO:Importing libraries
2025-10-15 03:58:28,379:INFO:Copying training dataset
2025-10-15 03:58:28,807:INFO:Defining folds
2025-10-15 03:58:28,807:INFO:Declaring metric variables
2025-10-15 03:58:28,821:INFO:Importing untrained model
2025-10-15 03:58:28,831:INFO:Random Forest Classifier Imported successfully
2025-10-15 03:58:28,856:INFO:Starting cross validation
2025-10-15 03:58:28,860:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 03:59:09,019:INFO:Calculating mean and std
2025-10-15 03:59:09,075:INFO:Creating metrics dataframe
2025-10-15 03:59:09,393:INFO:Uploading results into container
2025-10-15 03:59:09,409:INFO:Uploading model into container now
2025-10-15 03:59:09,420:INFO:_master_model_container: 7
2025-10-15 03:59:09,421:INFO:_display_container: 2
2025-10-15 03:59:09,429:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-10-15 03:59:09,435:INFO:create_model() successfully completed......................................
2025-10-15 03:59:11,321:INFO:SubProcess create_model() end ==================================
2025-10-15 03:59:11,329:INFO:Creating metrics dataframe
2025-10-15 03:59:11,588:INFO:Initializing Quadratic Discriminant Analysis
2025-10-15 03:59:11,591:INFO:Total runtime is 3.0016380190849303 minutes
2025-10-15 03:59:11,695:INFO:SubProcess create_model() called ==================================
2025-10-15 03:59:11,705:INFO:Initializing create_model()
2025-10-15 03:59:11,705:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A983A9B5E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:59:11,714:INFO:Checking exceptions
2025-10-15 03:59:11,728:INFO:Importing libraries
2025-10-15 03:59:11,729:INFO:Copying training dataset
2025-10-15 03:59:15,870:INFO:Defining folds
2025-10-15 03:59:15,870:INFO:Declaring metric variables
2025-10-15 03:59:16,025:INFO:Importing untrained model
2025-10-15 03:59:16,502:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-15 03:59:17,226:INFO:Starting cross validation
2025-10-15 03:59:17,237:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 03:59:31,704:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-15 03:59:33,934:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-15 03:59:35,432:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-15 03:59:36,710:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-15 03:59:42,442:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-15 03:59:44,598:INFO:Calculating mean and std
2025-10-15 03:59:44,619:INFO:Creating metrics dataframe
2025-10-15 03:59:44,735:INFO:Uploading results into container
2025-10-15 03:59:44,743:INFO:Uploading model into container now
2025-10-15 03:59:44,750:INFO:_master_model_container: 8
2025-10-15 03:59:44,750:INFO:_display_container: 2
2025-10-15 03:59:44,754:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-15 03:59:44,760:INFO:create_model() successfully completed......................................
2025-10-15 03:59:45,761:INFO:SubProcess create_model() end ==================================
2025-10-15 03:59:45,761:INFO:Creating metrics dataframe
2025-10-15 03:59:45,852:INFO:Initializing Ada Boost Classifier
2025-10-15 03:59:45,852:INFO:Total runtime is 3.5726801951726275 minutes
2025-10-15 03:59:45,871:INFO:SubProcess create_model() called ==================================
2025-10-15 03:59:45,871:INFO:Initializing create_model()
2025-10-15 03:59:45,873:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A983A9B5E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:59:45,876:INFO:Checking exceptions
2025-10-15 03:59:45,876:INFO:Importing libraries
2025-10-15 03:59:45,876:INFO:Copying training dataset
2025-10-15 03:59:46,581:INFO:Defining folds
2025-10-15 03:59:46,581:INFO:Declaring metric variables
2025-10-15 03:59:46,654:INFO:Importing untrained model
2025-10-15 03:59:46,668:INFO:Ada Boost Classifier Imported successfully
2025-10-15 03:59:46,727:INFO:Starting cross validation
2025-10-15 03:59:46,736:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 03:59:47,704:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-15 03:59:48,223:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-15 03:59:48,446:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-15 03:59:48,568:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-15 03:59:53,893:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-15 03:59:56,673:INFO:Calculating mean and std
2025-10-15 03:59:56,675:INFO:Creating metrics dataframe
2025-10-15 03:59:56,684:INFO:Uploading results into container
2025-10-15 03:59:56,685:INFO:Uploading model into container now
2025-10-15 03:59:56,686:INFO:_master_model_container: 9
2025-10-15 03:59:56,686:INFO:_display_container: 2
2025-10-15 03:59:56,686:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-10-15 03:59:56,687:INFO:create_model() successfully completed......................................
2025-10-15 03:59:56,889:INFO:SubProcess create_model() end ==================================
2025-10-15 03:59:56,889:INFO:Creating metrics dataframe
2025-10-15 03:59:56,909:INFO:Initializing Gradient Boosting Classifier
2025-10-15 03:59:56,909:INFO:Total runtime is 3.756962207953135 minutes
2025-10-15 03:59:56,917:INFO:SubProcess create_model() called ==================================
2025-10-15 03:59:56,917:INFO:Initializing create_model()
2025-10-15 03:59:56,917:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A983A9B5E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 03:59:56,917:INFO:Checking exceptions
2025-10-15 03:59:56,917:INFO:Importing libraries
2025-10-15 03:59:56,917:INFO:Copying training dataset
2025-10-15 03:59:57,231:INFO:Defining folds
2025-10-15 03:59:57,231:INFO:Declaring metric variables
2025-10-15 03:59:57,245:INFO:Importing untrained model
2025-10-15 03:59:57,255:INFO:Gradient Boosting Classifier Imported successfully
2025-10-15 03:59:57,277:INFO:Starting cross validation
2025-10-15 03:59:57,280:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 04:00:35,553:INFO:Calculating mean and std
2025-10-15 04:00:35,561:INFO:Creating metrics dataframe
2025-10-15 04:00:35,570:INFO:Uploading results into container
2025-10-15 04:00:35,572:INFO:Uploading model into container now
2025-10-15 04:00:35,573:INFO:_master_model_container: 10
2025-10-15 04:00:35,573:INFO:_display_container: 2
2025-10-15 04:00:35,575:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-15 04:00:35,575:INFO:create_model() successfully completed......................................
2025-10-15 04:00:36,440:INFO:SubProcess create_model() end ==================================
2025-10-15 04:00:36,441:INFO:Creating metrics dataframe
2025-10-15 04:00:36,563:INFO:Initializing Linear Discriminant Analysis
2025-10-15 04:00:36,563:INFO:Total runtime is 4.417850220203399 minutes
2025-10-15 04:00:36,645:INFO:SubProcess create_model() called ==================================
2025-10-15 04:00:36,645:INFO:Initializing create_model()
2025-10-15 04:00:36,645:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A983A9B5E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 04:00:36,645:INFO:Checking exceptions
2025-10-15 04:00:36,645:INFO:Importing libraries
2025-10-15 04:00:36,649:INFO:Copying training dataset
2025-10-15 04:00:37,468:INFO:Defining folds
2025-10-15 04:00:37,480:INFO:Declaring metric variables
2025-10-15 04:00:37,508:INFO:Importing untrained model
2025-10-15 04:00:37,518:INFO:Linear Discriminant Analysis Imported successfully
2025-10-15 04:00:37,553:INFO:Starting cross validation
2025-10-15 04:00:37,556:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 04:01:17,593:INFO:Calculating mean and std
2025-10-15 04:01:17,725:INFO:Creating metrics dataframe
2025-10-15 04:01:18,820:INFO:Uploading results into container
2025-10-15 04:01:18,828:INFO:Uploading model into container now
2025-10-15 04:01:18,832:INFO:_master_model_container: 11
2025-10-15 04:01:18,832:INFO:_display_container: 2
2025-10-15 04:01:18,836:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-15 04:01:18,837:INFO:create_model() successfully completed......................................
2025-10-15 04:01:29,163:INFO:SubProcess create_model() end ==================================
2025-10-15 04:01:29,164:INFO:Creating metrics dataframe
2025-10-15 04:01:31,452:INFO:Initializing Extra Trees Classifier
2025-10-15 04:01:31,453:INFO:Total runtime is 5.33269449075063 minutes
2025-10-15 04:01:32,450:INFO:SubProcess create_model() called ==================================
2025-10-15 04:01:32,452:INFO:Initializing create_model()
2025-10-15 04:01:32,453:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A983A9B5E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 04:01:32,462:INFO:Checking exceptions
2025-10-15 04:01:32,463:INFO:Importing libraries
2025-10-15 04:01:32,464:INFO:Copying training dataset
2025-10-15 04:01:40,448:INFO:Defining folds
2025-10-15 04:01:40,449:INFO:Declaring metric variables
2025-10-15 04:01:40,563:INFO:Importing untrained model
2025-10-15 04:01:40,594:INFO:Extra Trees Classifier Imported successfully
2025-10-15 04:01:40,819:INFO:Starting cross validation
2025-10-15 04:01:40,824:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 04:02:21,729:INFO:Calculating mean and std
2025-10-15 04:02:21,739:INFO:Creating metrics dataframe
2025-10-15 04:02:21,749:INFO:Uploading results into container
2025-10-15 04:02:21,749:INFO:Uploading model into container now
2025-10-15 04:02:21,749:INFO:_master_model_container: 12
2025-10-15 04:02:21,749:INFO:_display_container: 2
2025-10-15 04:02:21,749:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-10-15 04:02:21,749:INFO:create_model() successfully completed......................................
2025-10-15 04:02:22,012:INFO:SubProcess create_model() end ==================================
2025-10-15 04:02:22,013:INFO:Creating metrics dataframe
2025-10-15 04:02:22,042:INFO:Initializing Extreme Gradient Boosting
2025-10-15 04:02:22,043:INFO:Total runtime is 6.175859276453654 minutes
2025-10-15 04:02:22,053:INFO:SubProcess create_model() called ==================================
2025-10-15 04:02:22,054:INFO:Initializing create_model()
2025-10-15 04:02:22,054:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator=xgboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A983A9B5E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 04:02:22,055:INFO:Checking exceptions
2025-10-15 04:02:22,056:INFO:Importing libraries
2025-10-15 04:02:22,056:INFO:Copying training dataset
2025-10-15 04:02:22,470:INFO:Defining folds
2025-10-15 04:02:22,470:INFO:Declaring metric variables
2025-10-15 04:02:22,482:INFO:Importing untrained model
2025-10-15 04:02:22,501:INFO:Extreme Gradient Boosting Imported successfully
2025-10-15 04:02:22,536:INFO:Starting cross validation
2025-10-15 04:02:22,538:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 04:02:30,401:INFO:Calculating mean and std
2025-10-15 04:02:30,405:INFO:Creating metrics dataframe
2025-10-15 04:02:30,486:INFO:Uploading results into container
2025-10-15 04:02:30,486:INFO:Uploading model into container now
2025-10-15 04:02:30,486:INFO:_master_model_container: 13
2025-10-15 04:02:30,486:INFO:_display_container: 2
2025-10-15 04:02:30,495:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-10-15 04:02:30,495:INFO:create_model() successfully completed......................................
2025-10-15 04:02:31,062:INFO:SubProcess create_model() end ==================================
2025-10-15 04:02:31,062:INFO:Creating metrics dataframe
2025-10-15 04:02:31,114:INFO:Initializing Light Gradient Boosting Machine
2025-10-15 04:02:31,114:INFO:Total runtime is 6.32704735994339 minutes
2025-10-15 04:02:31,127:INFO:SubProcess create_model() called ==================================
2025-10-15 04:02:31,132:INFO:Initializing create_model()
2025-10-15 04:02:31,132:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A983A9B5E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 04:02:31,132:INFO:Checking exceptions
2025-10-15 04:02:31,132:INFO:Importing libraries
2025-10-15 04:02:31,132:INFO:Copying training dataset
2025-10-15 04:02:31,826:INFO:Defining folds
2025-10-15 04:02:31,826:INFO:Declaring metric variables
2025-10-15 04:02:31,834:INFO:Importing untrained model
2025-10-15 04:02:31,855:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-15 04:02:31,883:INFO:Starting cross validation
2025-10-15 04:02:31,885:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 04:02:41,205:INFO:Calculating mean and std
2025-10-15 04:02:41,210:INFO:Creating metrics dataframe
2025-10-15 04:02:41,216:INFO:Uploading results into container
2025-10-15 04:02:41,216:INFO:Uploading model into container now
2025-10-15 04:02:41,219:INFO:_master_model_container: 14
2025-10-15 04:02:41,219:INFO:_display_container: 2
2025-10-15 04:02:41,221:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-15 04:02:41,221:INFO:create_model() successfully completed......................................
2025-10-15 04:02:41,532:INFO:SubProcess create_model() end ==================================
2025-10-15 04:02:41,532:INFO:Creating metrics dataframe
2025-10-15 04:02:41,563:INFO:Initializing Dummy Classifier
2025-10-15 04:02:41,563:INFO:Total runtime is 6.501184995969137 minutes
2025-10-15 04:02:41,589:INFO:SubProcess create_model() called ==================================
2025-10-15 04:02:41,589:INFO:Initializing create_model()
2025-10-15 04:02:41,589:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A983A9B5E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 04:02:41,592:INFO:Checking exceptions
2025-10-15 04:02:41,593:INFO:Importing libraries
2025-10-15 04:02:41,593:INFO:Copying training dataset
2025-10-15 04:02:42,018:INFO:Defining folds
2025-10-15 04:02:42,018:INFO:Declaring metric variables
2025-10-15 04:02:42,030:INFO:Importing untrained model
2025-10-15 04:02:42,041:INFO:Dummy Classifier Imported successfully
2025-10-15 04:02:42,073:INFO:Starting cross validation
2025-10-15 04:02:42,076:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 04:02:42,626:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-15 04:02:42,763:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-15 04:02:43,021:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-15 04:02:43,152:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-15 04:02:43,231:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-15 04:02:43,276:INFO:Calculating mean and std
2025-10-15 04:02:43,276:INFO:Creating metrics dataframe
2025-10-15 04:02:43,286:INFO:Uploading results into container
2025-10-15 04:02:43,287:INFO:Uploading model into container now
2025-10-15 04:02:43,287:INFO:_master_model_container: 15
2025-10-15 04:02:43,287:INFO:_display_container: 2
2025-10-15 04:02:43,287:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-10-15 04:02:43,290:INFO:create_model() successfully completed......................................
2025-10-15 04:02:43,762:INFO:SubProcess create_model() end ==================================
2025-10-15 04:02:43,763:INFO:Creating metrics dataframe
2025-10-15 04:02:43,845:INFO:Initializing create_model()
2025-10-15 04:02:43,845:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 04:02:43,845:INFO:Checking exceptions
2025-10-15 04:02:43,849:INFO:Importing libraries
2025-10-15 04:02:43,849:INFO:Copying training dataset
2025-10-15 04:02:44,225:INFO:Defining folds
2025-10-15 04:02:44,225:INFO:Declaring metric variables
2025-10-15 04:02:44,228:INFO:Importing untrained model
2025-10-15 04:02:44,229:INFO:Declaring custom model
2025-10-15 04:02:44,232:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-15 04:02:44,232:INFO:Cross validation set to False
2025-10-15 04:02:44,232:INFO:Fitting Model
2025-10-15 04:02:44,533:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:02:44,534:INFO:[LightGBM] [Info] Number of positive: 7846, number of negative: 23809
2025-10-15 04:02:44,554:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009368 seconds.
2025-10-15 04:02:44,555:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:02:44,555:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:02:44,555:INFO:[LightGBM] [Info] Total Bins 514
2025-10-15 04:02:44,558:INFO:[LightGBM] [Info] Number of data points in the train set: 31655, number of used features: 90
2025-10-15 04:02:44,558:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247860 -> initscore=-1.110060
2025-10-15 04:02:44,561:INFO:[LightGBM] [Info] Start training from score -1.110060
2025-10-15 04:02:45,650:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-15 04:02:45,650:INFO:create_model() successfully completed......................................
2025-10-15 04:02:45,932:INFO:Initializing create_model()
2025-10-15 04:02:45,932:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 04:02:45,932:INFO:Checking exceptions
2025-10-15 04:02:45,932:INFO:Importing libraries
2025-10-15 04:02:45,932:INFO:Copying training dataset
2025-10-15 04:02:46,268:INFO:Defining folds
2025-10-15 04:02:46,268:INFO:Declaring metric variables
2025-10-15 04:02:46,268:INFO:Importing untrained model
2025-10-15 04:02:46,268:INFO:Declaring custom model
2025-10-15 04:02:46,278:INFO:Extreme Gradient Boosting Imported successfully
2025-10-15 04:02:46,279:INFO:Cross validation set to False
2025-10-15 04:02:46,279:INFO:Fitting Model
2025-10-15 04:02:49,380:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-10-15 04:02:49,380:INFO:create_model() successfully completed......................................
2025-10-15 04:02:49,710:INFO:Initializing create_model()
2025-10-15 04:02:49,710:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 04:02:49,710:INFO:Checking exceptions
2025-10-15 04:02:49,713:INFO:Importing libraries
2025-10-15 04:02:49,713:INFO:Copying training dataset
2025-10-15 04:02:50,097:INFO:Defining folds
2025-10-15 04:02:50,097:INFO:Declaring metric variables
2025-10-15 04:02:50,097:INFO:Importing untrained model
2025-10-15 04:02:50,097:INFO:Declaring custom model
2025-10-15 04:02:50,100:INFO:Gradient Boosting Classifier Imported successfully
2025-10-15 04:02:50,101:INFO:Cross validation set to False
2025-10-15 04:02:50,102:INFO:Fitting Model
2025-10-15 04:03:10,327:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-15 04:03:10,327:INFO:create_model() successfully completed......................................
2025-10-15 04:03:10,794:INFO:Initializing create_model()
2025-10-15 04:03:10,794:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 04:03:10,794:INFO:Checking exceptions
2025-10-15 04:03:10,796:INFO:Importing libraries
2025-10-15 04:03:10,796:INFO:Copying training dataset
2025-10-15 04:03:11,467:INFO:Defining folds
2025-10-15 04:03:11,467:INFO:Declaring metric variables
2025-10-15 04:03:11,469:INFO:Importing untrained model
2025-10-15 04:03:11,469:INFO:Declaring custom model
2025-10-15 04:03:11,479:INFO:Ada Boost Classifier Imported successfully
2025-10-15 04:03:11,489:INFO:Cross validation set to False
2025-10-15 04:03:11,489:INFO:Fitting Model
2025-10-15 04:03:16,262:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-10-15 04:03:16,262:INFO:create_model() successfully completed......................................
2025-10-15 04:03:16,559:INFO:Initializing create_model()
2025-10-15 04:03:16,559:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 04:03:16,559:INFO:Checking exceptions
2025-10-15 04:03:16,559:INFO:Importing libraries
2025-10-15 04:03:16,559:INFO:Copying training dataset
2025-10-15 04:03:16,980:INFO:Defining folds
2025-10-15 04:03:16,981:INFO:Declaring metric variables
2025-10-15 04:03:16,981:INFO:Importing untrained model
2025-10-15 04:03:16,981:INFO:Declaring custom model
2025-10-15 04:03:16,982:INFO:Logistic Regression Imported successfully
2025-10-15 04:03:16,985:INFO:Cross validation set to False
2025-10-15 04:03:16,985:INFO:Fitting Model
2025-10-15 04:03:18,123:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-15 04:03:18,123:INFO:create_model() successfully completed......................................
2025-10-15 04:03:18,510:INFO:_master_model_container: 15
2025-10-15 04:03:18,510:INFO:_display_container: 2
2025-10-15 04:03:18,513:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)]
2025-10-15 04:03:18,517:INFO:compare_models() successfully completed......................................
2025-10-15 04:03:44,970:INFO:Initializing blend_models()
2025-10-15 04:03:44,970:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-15 04:03:44,972:INFO:Checking exceptions
2025-10-15 04:03:45,200:INFO:Importing libraries
2025-10-15 04:03:45,200:INFO:Copying training dataset
2025-10-15 04:03:45,205:INFO:Getting model names
2025-10-15 04:03:45,224:INFO:SubProcess create_model() called ==================================
2025-10-15 04:03:45,304:INFO:Initializing create_model()
2025-10-15 04:03:45,304:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                 random_state=42)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=42,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A9888696F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 04:03:45,304:INFO:Checking exceptions
2025-10-15 04:03:45,304:INFO:Importing libraries
2025-10-15 04:03:45,304:INFO:Copying training dataset
2025-10-15 04:03:45,691:INFO:Defining folds
2025-10-15 04:03:45,691:INFO:Declaring metric variables
2025-10-15 04:03:45,702:INFO:Importing untrained model
2025-10-15 04:03:45,702:INFO:Declaring custom model
2025-10-15 04:03:45,714:INFO:Voting Classifier Imported successfully
2025-10-15 04:03:45,731:INFO:Starting cross validation
2025-10-15 04:03:45,732:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 04:03:46,327:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-15 04:03:47,666:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-15 04:03:47,780:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-15 04:03:48,264:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-15 04:04:20,576:WARNING:c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-15 04:04:33,415:INFO:Calculating mean and std
2025-10-15 04:04:33,422:INFO:Creating metrics dataframe
2025-10-15 04:04:33,443:INFO:Finalizing model
2025-10-15 04:07:17,814:INFO:Initializing blend_models()
2025-10-15 04:07:17,814:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-15 04:07:17,815:INFO:Checking exceptions
2025-10-15 04:07:18,034:INFO:Importing libraries
2025-10-15 04:07:18,042:INFO:Copying training dataset
2025-10-15 04:07:18,087:INFO:Getting model names
2025-10-15 04:07:18,097:INFO:SubProcess create_model() called ==================================
2025-10-15 04:07:18,165:INFO:Initializing create_model()
2025-10-15 04:07:18,165:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                 random_state=42)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=42,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A9DCB99720>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 04:07:18,165:INFO:Checking exceptions
2025-10-15 04:07:18,165:INFO:Importing libraries
2025-10-15 04:07:18,167:INFO:Copying training dataset
2025-10-15 04:07:18,496:INFO:Defining folds
2025-10-15 04:07:18,496:INFO:Declaring metric variables
2025-10-15 04:07:18,502:INFO:Importing untrained model
2025-10-15 04:07:18,502:INFO:Declaring custom model
2025-10-15 04:07:18,517:INFO:Voting Classifier Imported successfully
2025-10-15 04:07:18,542:INFO:Starting cross validation
2025-10-15 04:07:18,543:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 04:07:18,829:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:07:18,830:INFO:[LightGBM] [Info] Number of positive: 6276, number of negative: 19048
2025-10-15 04:07:18,862:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015898 seconds.
2025-10-15 04:07:18,862:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:07:18,862:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:07:18,862:INFO:[LightGBM] [Info] Total Bins 500
2025-10-15 04:07:18,862:INFO:[LightGBM] [Info] Number of data points in the train set: 25324, number of used features: 88
2025-10-15 04:07:18,862:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247828 -> initscore=-1.110229
2025-10-15 04:07:18,862:INFO:[LightGBM] [Info] Start training from score -1.110229
2025-10-15 04:07:35,853:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:07:35,854:INFO:[LightGBM] [Info] Number of positive: 6277, number of negative: 19047
2025-10-15 04:07:35,877:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011545 seconds.
2025-10-15 04:07:35,877:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:07:35,877:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:07:35,877:INFO:[LightGBM] [Info] Total Bins 500
2025-10-15 04:07:35,877:INFO:[LightGBM] [Info] Number of data points in the train set: 25324, number of used features: 89
2025-10-15 04:07:35,877:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247868 -> initscore=-1.110017
2025-10-15 04:07:35,884:INFO:[LightGBM] [Info] Start training from score -1.110017
2025-10-15 04:07:53,755:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:07:53,756:INFO:[LightGBM] [Info] Number of positive: 6277, number of negative: 19047
2025-10-15 04:07:53,767:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008158 seconds.
2025-10-15 04:07:53,767:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:07:53,767:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:07:53,767:INFO:[LightGBM] [Info] Total Bins 490
2025-10-15 04:07:53,767:INFO:[LightGBM] [Info] Number of data points in the train set: 25324, number of used features: 87
2025-10-15 04:07:53,767:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247868 -> initscore=-1.110017
2025-10-15 04:07:53,767:INFO:[LightGBM] [Info] Start training from score -1.110017
2025-10-15 04:08:09,503:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:08:09,503:INFO:[LightGBM] [Info] Number of positive: 6277, number of negative: 19047
2025-10-15 04:08:09,533:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011477 seconds.
2025-10-15 04:08:09,533:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:08:09,533:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:08:09,533:INFO:[LightGBM] [Info] Total Bins 501
2025-10-15 04:08:09,533:INFO:[LightGBM] [Info] Number of data points in the train set: 25324, number of used features: 89
2025-10-15 04:08:09,533:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247868 -> initscore=-1.110017
2025-10-15 04:08:09,533:INFO:[LightGBM] [Info] Start training from score -1.110017
2025-10-15 04:08:27,678:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:08:27,678:INFO:[LightGBM] [Info] Number of positive: 6277, number of negative: 19047
2025-10-15 04:08:27,711:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011451 seconds.
2025-10-15 04:08:27,711:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:08:27,711:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:08:27,712:INFO:[LightGBM] [Info] Total Bins 503
2025-10-15 04:08:27,712:INFO:[LightGBM] [Info] Number of data points in the train set: 25324, number of used features: 89
2025-10-15 04:08:27,712:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247868 -> initscore=-1.110017
2025-10-15 04:08:27,712:INFO:[LightGBM] [Info] Start training from score -1.110017
2025-10-15 04:08:43,376:INFO:Calculating mean and std
2025-10-15 04:08:43,378:INFO:Creating metrics dataframe
2025-10-15 04:08:43,393:INFO:Finalizing model
2025-10-15 04:08:43,676:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:08:43,676:INFO:[LightGBM] [Info] Number of positive: 7846, number of negative: 23809
2025-10-15 04:08:43,710:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013087 seconds.
2025-10-15 04:08:43,710:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:08:43,710:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:08:43,710:INFO:[LightGBM] [Info] Total Bins 514
2025-10-15 04:08:43,710:INFO:[LightGBM] [Info] Number of data points in the train set: 31655, number of used features: 90
2025-10-15 04:08:43,710:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247860 -> initscore=-1.110060
2025-10-15 04:08:43,710:INFO:[LightGBM] [Info] Start training from score -1.110060
2025-10-15 04:09:00,776:INFO:Uploading results into container
2025-10-15 04:09:00,779:INFO:Uploading model into container now
2025-10-15 04:09:00,779:INFO:_master_model_container: 16
2025-10-15 04:09:00,781:INFO:_display_container: 3
2025-10-15 04:09:00,821:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                 random_state=42)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=42,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-10-15 04:09:00,821:INFO:create_model() successfully completed......................................
2025-10-15 04:09:01,156:INFO:SubProcess create_model() end ==================================
2025-10-15 04:09:01,179:INFO:_master_model_container: 16
2025-10-15 04:09:01,179:INFO:_display_container: 3
2025-10-15 04:09:01,227:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                 random_state=42)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=42,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-10-15 04:09:01,229:INFO:blend_models() successfully completed......................................
2025-10-15 04:09:01,455:INFO:Initializing stack_models()
2025-10-15 04:09:01,455:INFO:stack_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], meta_model=None, meta_model_fold=5, fold=None, round=4, method=auto, restack=False, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-15 04:09:01,455:INFO:Checking exceptions
2025-10-15 04:09:01,591:INFO:Defining meta model
2025-10-15 04:09:01,643:INFO:Getting model names
2025-10-15 04:09:01,643:INFO:[('Light Gradient Boosting Machine', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)), ('Extreme Gradient Boosting', XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)), ('Gradient Boosting Classifier', GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)), ('Ada Boost Classifier', AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)), ('Logistic Regression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False))]
2025-10-15 04:09:01,678:INFO:SubProcess create_model() called ==================================
2025-10-15 04:09:01,760:INFO:Initializing create_model()
2025-10-15 04:09:01,761:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator=StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=42, reg_alpha=0.0,
                                               reg...
                                                   solver='lbfgs', tol=0.0001,
                                                   verbose=0,
                                                   warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A985779900>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 04:09:01,761:INFO:Checking exceptions
2025-10-15 04:09:01,762:INFO:Importing libraries
2025-10-15 04:09:01,762:INFO:Copying training dataset
2025-10-15 04:09:02,110:INFO:Defining folds
2025-10-15 04:09:02,111:INFO:Declaring metric variables
2025-10-15 04:09:02,123:INFO:Importing untrained model
2025-10-15 04:09:02,124:INFO:Declaring custom model
2025-10-15 04:09:02,147:INFO:Stacking Classifier Imported successfully
2025-10-15 04:09:02,170:INFO:Starting cross validation
2025-10-15 04:09:02,173:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-10-15 04:09:02,496:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:09:02,501:INFO:[LightGBM] [Info] Number of positive: 6276, number of negative: 19048
2025-10-15 04:09:02,527:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016970 seconds.
2025-10-15 04:09:02,527:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:09:02,527:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:09:02,527:INFO:[LightGBM] [Info] Total Bins 500
2025-10-15 04:09:02,527:INFO:[LightGBM] [Info] Number of data points in the train set: 25324, number of used features: 88
2025-10-15 04:09:02,527:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247828 -> initscore=-1.110229
2025-10-15 04:09:02,527:INFO:[LightGBM] [Info] Start training from score -1.110229
2025-10-15 04:09:16,868:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:09:16,868:INFO:[LightGBM] [Info] Number of positive: 5020, number of negative: 15239
2025-10-15 04:09:16,883:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009768 seconds.
2025-10-15 04:09:16,883:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:09:16,883:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:09:16,883:INFO:[LightGBM] [Info] Total Bins 483
2025-10-15 04:09:16,883:INFO:[LightGBM] [Info] Number of data points in the train set: 20259, number of used features: 87
2025-10-15 04:09:16,883:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247791 -> initscore=-1.110428
2025-10-15 04:09:16,883:INFO:[LightGBM] [Info] Start training from score -1.110428
2025-10-15 04:09:17,469:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:09:17,469:INFO:[LightGBM] [Info] Number of positive: 5021, number of negative: 15238
2025-10-15 04:09:17,487:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006416 seconds.
2025-10-15 04:09:17,487:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:09:17,487:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:09:17,487:INFO:[LightGBM] [Info] Total Bins 478
2025-10-15 04:09:17,487:INFO:[LightGBM] [Info] Number of data points in the train set: 20259, number of used features: 86
2025-10-15 04:09:17,487:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247840 -> initscore=-1.110163
2025-10-15 04:09:17,487:INFO:[LightGBM] [Info] Start training from score -1.110163
2025-10-15 04:09:18,045:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:09:18,045:INFO:[LightGBM] [Info] Number of positive: 5021, number of negative: 15238
2025-10-15 04:09:18,067:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005923 seconds.
2025-10-15 04:09:18,067:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:09:18,067:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:09:18,067:INFO:[LightGBM] [Info] Total Bins 479
2025-10-15 04:09:18,068:INFO:[LightGBM] [Info] Number of data points in the train set: 20259, number of used features: 87
2025-10-15 04:09:18,069:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247840 -> initscore=-1.110163
2025-10-15 04:09:18,069:INFO:[LightGBM] [Info] Start training from score -1.110163
2025-10-15 04:09:18,635:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:09:18,635:INFO:[LightGBM] [Info] Number of positive: 5021, number of negative: 15238
2025-10-15 04:09:18,653:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005705 seconds.
2025-10-15 04:09:18,653:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:09:18,653:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:09:18,653:INFO:[LightGBM] [Info] Total Bins 486
2025-10-15 04:09:18,655:INFO:[LightGBM] [Info] Number of data points in the train set: 20259, number of used features: 87
2025-10-15 04:09:18,655:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247840 -> initscore=-1.110163
2025-10-15 04:09:18,655:INFO:[LightGBM] [Info] Start training from score -1.110163
2025-10-15 04:09:19,212:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:09:19,212:INFO:[LightGBM] [Info] Number of positive: 5021, number of negative: 15239
2025-10-15 04:09:19,235:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010093 seconds.
2025-10-15 04:09:19,235:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:09:19,235:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:09:19,235:INFO:[LightGBM] [Info] Total Bins 488
2025-10-15 04:09:19,235:INFO:[LightGBM] [Info] Number of data points in the train set: 20260, number of used features: 87
2025-10-15 04:09:19,235:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247828 -> initscore=-1.110229
2025-10-15 04:09:19,235:INFO:[LightGBM] [Info] Start training from score -1.110229
2025-10-15 04:10:25,904:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:10:25,905:INFO:[LightGBM] [Info] Number of positive: 6277, number of negative: 19047
2025-10-15 04:10:25,968:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025677 seconds.
2025-10-15 04:10:25,968:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:10:25,968:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:10:25,971:INFO:[LightGBM] [Info] Total Bins 500
2025-10-15 04:10:25,971:INFO:[LightGBM] [Info] Number of data points in the train set: 25324, number of used features: 89
2025-10-15 04:10:25,972:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247868 -> initscore=-1.110017
2025-10-15 04:10:25,972:INFO:[LightGBM] [Info] Start training from score -1.110017
2025-10-15 04:10:41,703:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:10:41,703:INFO:[LightGBM] [Info] Number of positive: 5021, number of negative: 15238
2025-10-15 04:10:41,720:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009614 seconds.
2025-10-15 04:10:41,720:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:10:41,720:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:10:41,720:INFO:[LightGBM] [Info] Total Bins 482
2025-10-15 04:10:41,720:INFO:[LightGBM] [Info] Number of data points in the train set: 20259, number of used features: 87
2025-10-15 04:10:41,720:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247840 -> initscore=-1.110163
2025-10-15 04:10:41,720:INFO:[LightGBM] [Info] Start training from score -1.110163
2025-10-15 04:10:42,252:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:10:42,252:INFO:[LightGBM] [Info] Number of positive: 5021, number of negative: 15238
2025-10-15 04:10:42,273:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010613 seconds.
2025-10-15 04:10:42,273:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:10:42,273:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:10:42,273:INFO:[LightGBM] [Info] Total Bins 475
2025-10-15 04:10:42,273:INFO:[LightGBM] [Info] Number of data points in the train set: 20259, number of used features: 85
2025-10-15 04:10:42,283:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247840 -> initscore=-1.110163
2025-10-15 04:10:42,283:INFO:[LightGBM] [Info] Start training from score -1.110163
2025-10-15 04:10:43,353:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:10:43,360:INFO:[LightGBM] [Info] Number of positive: 5022, number of negative: 15237
2025-10-15 04:10:43,410:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028310 seconds.
2025-10-15 04:10:43,410:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:10:43,411:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:10:43,411:INFO:[LightGBM] [Info] Total Bins 473
2025-10-15 04:10:43,411:INFO:[LightGBM] [Info] Number of data points in the train set: 20259, number of used features: 86
2025-10-15 04:10:43,422:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247890 -> initscore=-1.109898
2025-10-15 04:10:43,423:INFO:[LightGBM] [Info] Start training from score -1.109898
2025-10-15 04:10:44,623:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:10:44,625:INFO:[LightGBM] [Info] Number of positive: 5022, number of negative: 15237
2025-10-15 04:10:44,652:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013462 seconds.
2025-10-15 04:10:44,652:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:10:44,652:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:10:44,653:INFO:[LightGBM] [Info] Total Bins 482
2025-10-15 04:10:44,654:INFO:[LightGBM] [Info] Number of data points in the train set: 20259, number of used features: 85
2025-10-15 04:10:44,656:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247890 -> initscore=-1.109898
2025-10-15 04:10:44,656:INFO:[LightGBM] [Info] Start training from score -1.109898
2025-10-15 04:10:45,497:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:10:45,500:INFO:[LightGBM] [Info] Number of positive: 5022, number of negative: 15238
2025-10-15 04:10:45,530:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012495 seconds.
2025-10-15 04:10:45,530:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:10:45,530:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:10:45,533:INFO:[LightGBM] [Info] Total Bins 481
2025-10-15 04:10:45,535:INFO:[LightGBM] [Info] Number of data points in the train set: 20260, number of used features: 86
2025-10-15 04:10:45,535:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247878 -> initscore=-1.109964
2025-10-15 04:10:45,536:INFO:[LightGBM] [Info] Start training from score -1.109964
2025-10-15 04:12:02,376:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:12:02,384:INFO:[LightGBM] [Info] Number of positive: 6277, number of negative: 19047
2025-10-15 04:12:02,395:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010146 seconds.
2025-10-15 04:12:02,395:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:12:02,395:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:12:02,395:INFO:[LightGBM] [Info] Total Bins 490
2025-10-15 04:12:02,395:INFO:[LightGBM] [Info] Number of data points in the train set: 25324, number of used features: 87
2025-10-15 04:12:02,395:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247868 -> initscore=-1.110017
2025-10-15 04:12:02,395:INFO:[LightGBM] [Info] Start training from score -1.110017
2025-10-15 04:12:43,515:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:12:43,515:INFO:[LightGBM] [Info] Number of positive: 5021, number of negative: 15238
2025-10-15 04:12:43,532:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005618 seconds.
2025-10-15 04:12:43,532:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:12:43,532:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:12:43,532:INFO:[LightGBM] [Info] Total Bins 475
2025-10-15 04:12:43,532:INFO:[LightGBM] [Info] Number of data points in the train set: 20259, number of used features: 86
2025-10-15 04:12:43,532:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247840 -> initscore=-1.110163
2025-10-15 04:12:43,532:INFO:[LightGBM] [Info] Start training from score -1.110163
2025-10-15 04:12:44,096:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:12:44,096:INFO:[LightGBM] [Info] Number of positive: 5021, number of negative: 15238
2025-10-15 04:12:44,127:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009386 seconds.
2025-10-15 04:12:44,127:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:12:44,127:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:12:44,127:INFO:[LightGBM] [Info] Total Bins 473
2025-10-15 04:12:44,128:INFO:[LightGBM] [Info] Number of data points in the train set: 20259, number of used features: 85
2025-10-15 04:12:44,128:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247840 -> initscore=-1.110163
2025-10-15 04:12:44,128:INFO:[LightGBM] [Info] Start training from score -1.110163
2025-10-15 04:12:44,660:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:12:44,660:INFO:[LightGBM] [Info] Number of positive: 5022, number of negative: 15237
2025-10-15 04:12:44,691:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012627 seconds.
2025-10-15 04:12:44,692:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-15 04:12:44,693:INFO:[LightGBM] [Info] Total Bins 465
2025-10-15 04:12:44,693:INFO:[LightGBM] [Info] Number of data points in the train set: 20259, number of used features: 85
2025-10-15 04:12:44,694:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247890 -> initscore=-1.109898
2025-10-15 04:12:44,694:INFO:[LightGBM] [Info] Start training from score -1.109898
2025-10-15 04:12:45,275:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:12:45,276:INFO:[LightGBM] [Info] Number of positive: 5022, number of negative: 15237
2025-10-15 04:12:45,277:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007430 seconds.
2025-10-15 04:12:45,277:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-15 04:12:45,277:INFO:[LightGBM] [Info] Total Bins 481
2025-10-15 04:12:45,277:INFO:[LightGBM] [Info] Number of data points in the train set: 20259, number of used features: 85
2025-10-15 04:12:45,293:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247890 -> initscore=-1.109898
2025-10-15 04:12:45,293:INFO:[LightGBM] [Info] Start training from score -1.109898
2025-10-15 04:12:45,877:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:12:45,881:INFO:[LightGBM] [Info] Number of positive: 5022, number of negative: 15238
2025-10-15 04:12:45,900:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010078 seconds.
2025-10-15 04:12:45,900:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:12:45,900:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:12:45,900:INFO:[LightGBM] [Info] Total Bins 478
2025-10-15 04:12:45,900:INFO:[LightGBM] [Info] Number of data points in the train set: 20260, number of used features: 86
2025-10-15 04:12:45,900:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247878 -> initscore=-1.109964
2025-10-15 04:12:45,900:INFO:[LightGBM] [Info] Start training from score -1.109964
2025-10-15 04:13:54,748:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:13:54,749:INFO:[LightGBM] [Info] Number of positive: 6277, number of negative: 19047
2025-10-15 04:13:54,775:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016015 seconds.
2025-10-15 04:13:54,775:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-15 04:13:54,775:INFO:[LightGBM] [Info] Total Bins 501
2025-10-15 04:13:54,775:INFO:[LightGBM] [Info] Number of data points in the train set: 25324, number of used features: 89
2025-10-15 04:13:54,780:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247868 -> initscore=-1.110017
2025-10-15 04:13:54,780:INFO:[LightGBM] [Info] Start training from score -1.110017
2025-10-15 04:14:09,211:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:14:09,211:INFO:[LightGBM] [Info] Number of positive: 5021, number of negative: 15238
2025-10-15 04:14:09,227:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007403 seconds.
2025-10-15 04:14:09,227:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:14:09,227:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:14:09,227:INFO:[LightGBM] [Info] Total Bins 483
2025-10-15 04:14:09,227:INFO:[LightGBM] [Info] Number of data points in the train set: 20259, number of used features: 87
2025-10-15 04:14:09,227:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247840 -> initscore=-1.110163
2025-10-15 04:14:09,227:INFO:[LightGBM] [Info] Start training from score -1.110163
2025-10-15 04:14:10,550:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:14:10,550:INFO:[LightGBM] [Info] Number of positive: 5021, number of negative: 15238
2025-10-15 04:14:10,592:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014715 seconds.
2025-10-15 04:14:10,592:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:14:10,592:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:14:10,592:INFO:[LightGBM] [Info] Total Bins 478
2025-10-15 04:14:10,592:INFO:[LightGBM] [Info] Number of data points in the train set: 20259, number of used features: 84
2025-10-15 04:14:10,592:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247840 -> initscore=-1.110163
2025-10-15 04:14:10,592:INFO:[LightGBM] [Info] Start training from score -1.110163
2025-10-15 04:14:11,613:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:14:11,614:INFO:[LightGBM] [Info] Number of positive: 5022, number of negative: 15237
2025-10-15 04:14:11,645:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014349 seconds.
2025-10-15 04:14:11,645:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:14:11,645:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:14:11,645:INFO:[LightGBM] [Info] Total Bins 473
2025-10-15 04:14:11,646:INFO:[LightGBM] [Info] Number of data points in the train set: 20259, number of used features: 84
2025-10-15 04:14:11,646:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247890 -> initscore=-1.109898
2025-10-15 04:14:11,647:INFO:[LightGBM] [Info] Start training from score -1.109898
2025-10-15 04:14:12,285:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:14:12,285:INFO:[LightGBM] [Info] Number of positive: 5022, number of negative: 15237
2025-10-15 04:14:12,295:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008111 seconds.
2025-10-15 04:14:12,295:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:14:12,302:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:14:12,302:INFO:[LightGBM] [Info] Total Bins 485
2025-10-15 04:14:12,302:INFO:[LightGBM] [Info] Number of data points in the train set: 20259, number of used features: 86
2025-10-15 04:14:12,304:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247890 -> initscore=-1.109898
2025-10-15 04:14:12,304:INFO:[LightGBM] [Info] Start training from score -1.109898
2025-10-15 04:14:13,427:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:14:13,427:INFO:[LightGBM] [Info] Number of positive: 5022, number of negative: 15238
2025-10-15 04:14:13,469:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025097 seconds.
2025-10-15 04:14:13,469:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-15 04:14:13,470:INFO:[LightGBM] [Info] Total Bins 480
2025-10-15 04:14:13,470:INFO:[LightGBM] [Info] Number of data points in the train set: 20260, number of used features: 86
2025-10-15 04:14:13,470:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247878 -> initscore=-1.109964
2025-10-15 04:14:13,470:INFO:[LightGBM] [Info] Start training from score -1.109964
2025-10-15 04:15:12,030:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:15:12,030:INFO:[LightGBM] [Info] Number of positive: 6277, number of negative: 19047
2025-10-15 04:15:12,058:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008925 seconds.
2025-10-15 04:15:12,058:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:15:12,058:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:15:12,058:INFO:[LightGBM] [Info] Total Bins 503
2025-10-15 04:15:12,060:INFO:[LightGBM] [Info] Number of data points in the train set: 25324, number of used features: 89
2025-10-15 04:15:12,060:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247868 -> initscore=-1.110017
2025-10-15 04:15:12,060:INFO:[LightGBM] [Info] Start training from score -1.110017
2025-10-15 04:15:26,391:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:15:26,391:INFO:[LightGBM] [Info] Number of positive: 5021, number of negative: 15238
2025-10-15 04:15:26,411:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009920 seconds.
2025-10-15 04:15:26,411:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:15:26,413:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:15:26,413:INFO:[LightGBM] [Info] Total Bins 485
2025-10-15 04:15:26,413:INFO:[LightGBM] [Info] Number of data points in the train set: 20259, number of used features: 86
2025-10-15 04:15:26,414:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247840 -> initscore=-1.110163
2025-10-15 04:15:26,414:INFO:[LightGBM] [Info] Start training from score -1.110163
2025-10-15 04:15:27,054:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:15:27,054:INFO:[LightGBM] [Info] Number of positive: 5021, number of negative: 15238
2025-10-15 04:15:27,076:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012155 seconds.
2025-10-15 04:15:27,076:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:15:27,076:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:15:27,076:INFO:[LightGBM] [Info] Total Bins 483
2025-10-15 04:15:27,076:INFO:[LightGBM] [Info] Number of data points in the train set: 20259, number of used features: 85
2025-10-15 04:15:27,076:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247840 -> initscore=-1.110163
2025-10-15 04:15:27,076:INFO:[LightGBM] [Info] Start training from score -1.110163
2025-10-15 04:15:27,727:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:15:27,727:INFO:[LightGBM] [Info] Number of positive: 5022, number of negative: 15237
2025-10-15 04:15:27,746:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008371 seconds.
2025-10-15 04:15:27,746:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:15:27,748:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:15:27,748:INFO:[LightGBM] [Info] Total Bins 479
2025-10-15 04:15:27,749:INFO:[LightGBM] [Info] Number of data points in the train set: 20259, number of used features: 86
2025-10-15 04:15:27,750:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247890 -> initscore=-1.109898
2025-10-15 04:15:27,750:INFO:[LightGBM] [Info] Start training from score -1.109898
2025-10-15 04:15:28,361:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:15:28,361:INFO:[LightGBM] [Info] Number of positive: 5022, number of negative: 15237
2025-10-15 04:15:28,377:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006727 seconds.
2025-10-15 04:15:28,378:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:15:28,378:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:15:28,378:INFO:[LightGBM] [Info] Total Bins 484
2025-10-15 04:15:28,379:INFO:[LightGBM] [Info] Number of data points in the train set: 20259, number of used features: 86
2025-10-15 04:15:28,379:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247890 -> initscore=-1.109898
2025-10-15 04:15:28,379:INFO:[LightGBM] [Info] Start training from score -1.109898
2025-10-15 04:15:29,414:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:15:29,414:INFO:[LightGBM] [Info] Number of positive: 5022, number of negative: 15238
2025-10-15 04:15:29,452:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015703 seconds.
2025-10-15 04:15:29,452:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:15:29,452:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:15:29,452:INFO:[LightGBM] [Info] Total Bins 484
2025-10-15 04:15:29,452:INFO:[LightGBM] [Info] Number of data points in the train set: 20260, number of used features: 86
2025-10-15 04:15:29,454:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247878 -> initscore=-1.109964
2025-10-15 04:15:29,454:INFO:[LightGBM] [Info] Start training from score -1.109964
2025-10-15 04:16:27,429:INFO:Calculating mean and std
2025-10-15 04:16:27,436:INFO:Creating metrics dataframe
2025-10-15 04:16:27,454:INFO:Finalizing model
2025-10-15 04:16:27,717:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:16:27,717:INFO:[LightGBM] [Info] Number of positive: 7846, number of negative: 23809
2025-10-15 04:16:27,748:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011119 seconds.
2025-10-15 04:16:27,748:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:16:27,748:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:16:27,748:INFO:[LightGBM] [Info] Total Bins 514
2025-10-15 04:16:27,749:INFO:[LightGBM] [Info] Number of data points in the train set: 31655, number of used features: 90
2025-10-15 04:16:27,749:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247860 -> initscore=-1.110060
2025-10-15 04:16:27,749:INFO:[LightGBM] [Info] Start training from score -1.110060
2025-10-15 04:16:48,620:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:16:48,622:INFO:[LightGBM] [Info] Number of positive: 6276, number of negative: 19048
2025-10-15 04:16:48,662:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020881 seconds.
2025-10-15 04:16:48,662:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:16:48,662:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:16:48,662:INFO:[LightGBM] [Info] Total Bins 500
2025-10-15 04:16:48,664:INFO:[LightGBM] [Info] Number of data points in the train set: 25324, number of used features: 88
2025-10-15 04:16:48,664:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247828 -> initscore=-1.110229
2025-10-15 04:16:48,664:INFO:[LightGBM] [Info] Start training from score -1.110229
2025-10-15 04:16:50,007:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:16:50,009:INFO:[LightGBM] [Info] Number of positive: 6277, number of negative: 19047
2025-10-15 04:16:50,044:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014749 seconds.
2025-10-15 04:16:50,045:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:16:50,045:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:16:50,046:INFO:[LightGBM] [Info] Total Bins 500
2025-10-15 04:16:50,046:INFO:[LightGBM] [Info] Number of data points in the train set: 25324, number of used features: 89
2025-10-15 04:16:50,046:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247868 -> initscore=-1.110017
2025-10-15 04:16:50,046:INFO:[LightGBM] [Info] Start training from score -1.110017
2025-10-15 04:16:50,829:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:16:50,829:INFO:[LightGBM] [Info] Number of positive: 6277, number of negative: 19047
2025-10-15 04:16:50,851:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008530 seconds.
2025-10-15 04:16:50,852:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:16:50,852:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:16:50,852:INFO:[LightGBM] [Info] Total Bins 490
2025-10-15 04:16:50,852:INFO:[LightGBM] [Info] Number of data points in the train set: 25324, number of used features: 87
2025-10-15 04:16:50,852:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247868 -> initscore=-1.110017
2025-10-15 04:16:50,852:INFO:[LightGBM] [Info] Start training from score -1.110017
2025-10-15 04:16:52,088:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:16:52,088:INFO:[LightGBM] [Info] Number of positive: 6277, number of negative: 19047
2025-10-15 04:16:52,130:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018396 seconds.
2025-10-15 04:16:52,130:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:16:52,130:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:16:52,138:INFO:[LightGBM] [Info] Total Bins 501
2025-10-15 04:16:52,138:INFO:[LightGBM] [Info] Number of data points in the train set: 25324, number of used features: 89
2025-10-15 04:16:52,139:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247868 -> initscore=-1.110017
2025-10-15 04:16:52,140:INFO:[LightGBM] [Info] Start training from score -1.110017
2025-10-15 04:16:53,344:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:16:53,345:INFO:[LightGBM] [Info] Number of positive: 6277, number of negative: 19047
2025-10-15 04:16:53,377:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010679 seconds.
2025-10-15 04:16:53,377:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:16:53,378:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:16:53,378:INFO:[LightGBM] [Info] Total Bins 503
2025-10-15 04:16:53,378:INFO:[LightGBM] [Info] Number of data points in the train set: 25324, number of used features: 89
2025-10-15 04:16:53,380:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247868 -> initscore=-1.110017
2025-10-15 04:16:53,380:INFO:[LightGBM] [Info] Start training from score -1.110017
2025-10-15 04:18:09,874:INFO:Uploading results into container
2025-10-15 04:18:09,878:INFO:Uploading model into container now
2025-10-15 04:18:09,884:INFO:_master_model_container: 17
2025-10-15 04:18:09,885:INFO:_display_container: 4
2025-10-15 04:18:09,921:INFO:StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=42, reg_alpha=0.0,
                                               reg...
                                                   solver='lbfgs', tol=0.0001,
                                                   verbose=0,
                                                   warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0)
2025-10-15 04:18:09,921:INFO:create_model() successfully completed......................................
2025-10-15 04:18:10,170:INFO:SubProcess create_model() end ==================================
2025-10-15 04:18:10,202:INFO:_master_model_container: 17
2025-10-15 04:18:10,204:INFO:_display_container: 4
2025-10-15 04:18:10,244:INFO:StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=42, reg_alpha=0.0,
                                               reg...
                                                   solver='lbfgs', tol=0.0001,
                                                   verbose=0,
                                                   warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0)
2025-10-15 04:18:10,244:INFO:stack_models() successfully completed......................................
2025-10-15 04:18:10,512:INFO:Initializing evaluate_model()
2025-10-15 04:18:10,512:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator=StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=42, reg_alpha=0.0,
                                               reg...
                                                   solver='lbfgs', tol=0.0001,
                                                   verbose=0,
                                                   warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-10-15 04:18:10,750:INFO:Initializing plot_model()
2025-10-15 04:18:10,750:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=42, reg_alpha=0.0,
                                               reg...
                                                   solver='lbfgs', tol=0.0001,
                                                   verbose=0,
                                                   warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, system=True)
2025-10-15 04:18:10,750:INFO:Checking exceptions
2025-10-15 04:18:10,849:INFO:Preloading libraries
2025-10-15 04:18:10,930:INFO:Copying training dataset
2025-10-15 04:18:10,930:INFO:Plot type: pipeline
2025-10-15 04:18:11,545:INFO:Visual Rendered Successfully
2025-10-15 04:18:11,929:INFO:plot_model() successfully completed......................................
2025-10-15 04:18:11,965:INFO:Initializing finalize_model()
2025-10-15 04:18:11,966:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator=StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=42, reg_alpha=0.0,
                                               reg...
                                                   solver='lbfgs', tol=0.0001,
                                                   verbose=0,
                                                   warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-10-15 04:18:11,987:INFO:Finalizing StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=42, reg_alpha=0.0,
                                               reg...
                                                   solver='lbfgs', tol=0.0001,
                                                   verbose=0,
                                                   warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0)
2025-10-15 04:18:12,248:INFO:Initializing create_model()
2025-10-15 04:18:12,248:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator=StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=42, reg_alpha=0.0,
                                               reg...
                                                   solver='lbfgs', tol=0.0001,
                                                   verbose=0,
                                                   warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 04:18:12,248:INFO:Checking exceptions
2025-10-15 04:18:12,248:INFO:Importing libraries
2025-10-15 04:18:12,248:INFO:Copying training dataset
2025-10-15 04:18:12,280:INFO:Defining folds
2025-10-15 04:18:12,280:INFO:Declaring metric variables
2025-10-15 04:18:12,280:INFO:Importing untrained model
2025-10-15 04:18:12,280:INFO:Declaring custom model
2025-10-15 04:18:12,280:INFO:Stacking Classifier Imported successfully
2025-10-15 04:18:12,280:INFO:Cross validation set to False
2025-10-15 04:18:12,280:INFO:Fitting Model
2025-10-15 04:18:12,604:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:18:12,604:INFO:[LightGBM] [Info] Number of positive: 11208, number of negative: 34014
2025-10-15 04:18:12,652:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024237 seconds.
2025-10-15 04:18:12,661:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:18:12,662:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:18:12,662:INFO:[LightGBM] [Info] Total Bins 552
2025-10-15 04:18:12,662:INFO:[LightGBM] [Info] Number of data points in the train set: 45222, number of used features: 99
2025-10-15 04:18:12,662:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247844 -> initscore=-1.110144
2025-10-15 04:18:12,662:INFO:[LightGBM] [Info] Start training from score -1.110144
2025-10-15 04:18:41,574:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:18:41,574:INFO:[LightGBM] [Info] Number of positive: 8966, number of negative: 27211
2025-10-15 04:18:41,607:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016467 seconds.
2025-10-15 04:18:41,607:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:18:41,607:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:18:41,607:INFO:[LightGBM] [Info] Total Bins 536
2025-10-15 04:18:41,607:INFO:[LightGBM] [Info] Number of data points in the train set: 36177, number of used features: 95
2025-10-15 04:18:41,607:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247837 -> initscore=-1.110182
2025-10-15 04:18:41,607:INFO:[LightGBM] [Info] Start training from score -1.110182
2025-10-15 04:18:42,508:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:18:42,508:INFO:[LightGBM] [Info] Number of positive: 8966, number of negative: 27211
2025-10-15 04:18:42,542:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018927 seconds.
2025-10-15 04:18:42,542:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:18:42,542:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:18:42,542:INFO:[LightGBM] [Info] Total Bins 530
2025-10-15 04:18:42,542:INFO:[LightGBM] [Info] Number of data points in the train set: 36177, number of used features: 93
2025-10-15 04:18:42,557:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247837 -> initscore=-1.110182
2025-10-15 04:18:42,557:INFO:[LightGBM] [Info] Start training from score -1.110182
2025-10-15 04:18:43,457:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:18:43,460:INFO:[LightGBM] [Info] Number of positive: 8966, number of negative: 27212
2025-10-15 04:18:43,495:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016928 seconds.
2025-10-15 04:18:43,495:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:18:43,495:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:18:43,495:INFO:[LightGBM] [Info] Total Bins 537
2025-10-15 04:18:43,495:INFO:[LightGBM] [Info] Number of data points in the train set: 36178, number of used features: 96
2025-10-15 04:18:43,495:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247830 -> initscore=-1.110218
2025-10-15 04:18:43,495:INFO:[LightGBM] [Info] Start training from score -1.110218
2025-10-15 04:18:44,595:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:18:44,596:INFO:[LightGBM] [Info] Number of positive: 8967, number of negative: 27211
2025-10-15 04:18:44,635:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021031 seconds.
2025-10-15 04:18:44,637:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:18:44,637:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:18:44,637:INFO:[LightGBM] [Info] Total Bins 532
2025-10-15 04:18:44,639:INFO:[LightGBM] [Info] Number of data points in the train set: 36178, number of used features: 95
2025-10-15 04:18:44,688:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247858 -> initscore=-1.110070
2025-10-15 04:18:44,688:INFO:[LightGBM] [Info] Start training from score -1.110070
2025-10-15 04:18:46,745:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 04:18:46,745:INFO:[LightGBM] [Info] Number of positive: 8967, number of negative: 27211
2025-10-15 04:18:46,798:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021204 seconds.
2025-10-15 04:18:46,798:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 04:18:46,798:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 04:18:46,798:INFO:[LightGBM] [Info] Total Bins 527
2025-10-15 04:18:46,798:INFO:[LightGBM] [Info] Number of data points in the train set: 36178, number of used features: 94
2025-10-15 04:18:46,804:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247858 -> initscore=-1.110070
2025-10-15 04:18:46,805:INFO:[LightGBM] [Info] Start training from score -1.110070
2025-10-15 04:21:21,780:INFO:Pipeline(memory=Memory(location=None),
         steps=[('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 StackingClassifier(cv=5,
                                    estimators=[('Light Gradient Boosting '
                                                 'Machine',
                                                 LGBMClassifier(boosting_type='gbdt',
                                                                class_weight=None,
                                                                colsample_bytree=1.0,
                                                                importan...
                                                                    verbose=0,
                                                                    warm_start=False))],
                                    final_estimator=LogisticRegression(C=1.0,
                                                                       class_weight=None,
                                                                       dual=False,
                                                                       fit_intercept=True,
                                                                       intercept_scaling=1,
                                                                       l1_ratio=None,
                                                                       max_iter=1000,
                                                                       multi_class='auto',
                                                                       n_jobs=None,
                                                                       penalty='l2',
                                                                       random_state=42,
                                                                       solver='lbfgs',
                                                                       tol=0.0001,
                                                                       verbose=0,
                                                                       warm_start=False),
                                    n_jobs=-1, passthrough=False,
                                    stack_method='auto', verbose=0))],
         verbose=False)
2025-10-15 04:21:21,780:INFO:create_model() successfully completed......................................
2025-10-15 04:21:21,999:INFO:_master_model_container: 17
2025-10-15 04:21:21,999:INFO:_display_container: 4
2025-10-15 04:21:22,081:INFO:Pipeline(memory=Memory(location=None),
         steps=[('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 StackingClassifier(cv=5,
                                    estimators=[('Light Gradient Boosting '
                                                 'Machine',
                                                 LGBMClassifier(boosting_type='gbdt',
                                                                class_weight=None,
                                                                colsample_bytree=1.0,
                                                                importan...
                                                                    verbose=0,
                                                                    warm_start=False))],
                                    final_estimator=LogisticRegression(C=1.0,
                                                                       class_weight=None,
                                                                       dual=False,
                                                                       fit_intercept=True,
                                                                       intercept_scaling=1,
                                                                       l1_ratio=None,
                                                                       max_iter=1000,
                                                                       multi_class='auto',
                                                                       n_jobs=None,
                                                                       penalty='l2',
                                                                       random_state=42,
                                                                       solver='lbfgs',
                                                                       tol=0.0001,
                                                                       verbose=0,
                                                                       warm_start=False),
                                    n_jobs=-1, passthrough=False,
                                    stack_method='auto', verbose=0))],
         verbose=False)
2025-10-15 04:21:22,081:INFO:finalize_model() successfully completed......................................
2025-10-15 04:21:22,325:INFO:Initializing predict_model()
2025-10-15 04:21:22,325:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 StackingClassifier(cv=5,
                                    estimators=[('Light Gradient Boosting '
                                                 'Machine',
                                                 LGBMClassifier(boosting_type='gbdt',
                                                                class_weight=None,
                                                                colsample_bytree=1.0,
                                                                importan...
                                                                    verbose=0,
                                                                    warm_start=False))],
                                    final_estimator=LogisticRegression(C=1.0,
                                                                       class_weight=None,
                                                                       dual=False,
                                                                       fit_intercept=True,
                                                                       intercept_scaling=1,
                                                                       l1_ratio=None,
                                                                       max_iter=1000,
                                                                       multi_class='auto',
                                                                       n_jobs=None,
                                                                       penalty='l2',
                                                                       random_state=42,
                                                                       solver='lbfgs',
                                                                       tol=0.0001,
                                                                       verbose=0,
                                                                       warm_start=False),
                                    n_jobs=-1, passthrough=False,
                                    stack_method='auto', verbose=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001A9DC4FCF70>)
2025-10-15 04:21:22,325:INFO:Checking exceptions
2025-10-15 04:21:22,325:INFO:Preloading libraries
2025-10-15 04:21:22,334:INFO:Set up data.
2025-10-15 04:21:22,429:INFO:Set up index.
2025-10-15 04:21:23,868:INFO:Initializing save_model()
2025-10-15 04:21:23,868:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 StackingClassifier(cv=5,
                                    estimators=[('Light Gradient Boosting '
                                                 'Machine',
                                                 LGBMClassifier(boosting_type='gbdt',
                                                                class_weight=None,
                                                                colsample_bytree=1.0,
                                                                importan...
                                                                    verbose=0,
                                                                    warm_start=False))],
                                    final_estimator=LogisticRegression(C=1.0,
                                                                       class_weight=None,
                                                                       dual=False,
                                                                       fit_intercept=True,
                                                                       intercept_scaling=1,
                                                                       l1_ratio=None,
                                                                       max_iter=1000,
                                                                       multi_class='auto',
                                                                       n_jobs=None,
                                                                       penalty='l2',
                                                                       random_state=42,
                                                                       solver='lbfgs',
                                                                       tol=0.0001,
                                                                       verbose=0,
                                                                       warm_start=False),
                                    n_jobs=-1, passthrough=False,
                                    stack_method='auto', verbose=0))],
         verbose=False), model_name=best_pycaret_automl_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Khaled\AppData\Local\Temp\joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-10-15 04:21:23,868:INFO:Adding model into prep_pipe
2025-10-15 04:21:23,868:WARNING:Only Model saved as it was a pipeline.
2025-10-15 04:21:24,055:INFO:best_pycaret_automl_model.pkl saved in current working directory
2025-10-15 04:21:24,128:INFO:Pipeline(memory=Memory(location=None),
         steps=[('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 StackingClassifier(cv=5,
                                    estimators=[('Light Gradient Boosting '
                                                 'Machine',
                                                 LGBMClassifier(boosting_type='gbdt',
                                                                class_weight=None,
                                                                colsample_bytree=1.0,
                                                                importan...
                                                                    verbose=0,
                                                                    warm_start=False))],
                                    final_estimator=LogisticRegression(C=1.0,
                                                                       class_weight=None,
                                                                       dual=False,
                                                                       fit_intercept=True,
                                                                       intercept_scaling=1,
                                                                       l1_ratio=None,
                                                                       max_iter=1000,
                                                                       multi_class='auto',
                                                                       n_jobs=None,
                                                                       penalty='l2',
                                                                       random_state=42,
                                                                       solver='lbfgs',
                                                                       tol=0.0001,
                                                                       verbose=0,
                                                                       warm_start=False),
                                    n_jobs=-1, passthrough=False,
                                    stack_method='auto', verbose=0))],
         verbose=False)
2025-10-15 04:21:24,128:INFO:save_model() successfully completed......................................
2025-10-15 11:27:17,469:INFO:Initializing blend_models()
2025-10-15 11:27:17,470:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-15 11:27:17,470:INFO:Checking exceptions
2025-10-15 11:28:19,397:INFO:Importing libraries
2025-10-15 11:28:19,398:INFO:Copying training dataset
2025-10-15 11:29:03,844:INFO:Getting model names
2025-10-15 11:30:00,926:INFO:SubProcess create_model() called ==================================
2025-10-15 11:30:00,990:INFO:Initializing create_model()
2025-10-15 11:30:00,990:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A9888653C0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                 random_state=42)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=42,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A9DCBC87C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 11:30:00,990:INFO:Checking exceptions
2025-10-15 11:30:00,991:INFO:Importing libraries
2025-10-15 11:30:00,991:INFO:Copying training dataset
2025-10-15 11:30:01,351:INFO:Defining folds
2025-10-15 11:30:01,351:INFO:Declaring metric variables
2025-10-15 11:30:13,293:INFO:Importing untrained model
2025-10-15 11:30:13,293:INFO:Declaring custom model
2025-10-15 11:31:18,944:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 11:31:18,944:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 11:31:18,944:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 11:31:18,944:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 11:47:29,664:INFO:PyCaret ClassificationExperiment
2025-10-15 11:47:29,664:INFO:Logging name: clf-default-name
2025-10-15 11:47:29,670:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-15 11:47:29,670:INFO:version 3.3.2
2025-10-15 11:47:29,671:INFO:Initializing setup()
2025-10-15 11:47:29,672:INFO:self.USI: 4dfc
2025-10-15 11:47:29,673:INFO:self._variable_keys: {'is_multiclass', 'USI', 'log_plots_param', 'fix_imbalance', '_ml_usecase', 'html_param', 'seed', 'logging_param', 'fold_generator', 'exp_id', 'y', 'X_train', 'data', 'fold_shuffle_param', 'gpu_param', 'n_jobs_param', '_available_plots', 'target_param', 'memory', 'y_test', 'idx', 'X', 'y_train', 'fold_groups_param', 'X_test', 'pipeline', 'exp_name_log', 'gpu_n_jobs_param'}
2025-10-15 11:47:29,673:INFO:Checking environment
2025-10-15 11:47:29,674:INFO:python_version: 3.10.0
2025-10-15 11:47:29,675:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-10-15 11:47:29,675:INFO:machine: AMD64
2025-10-15 11:47:29,675:INFO:platform: Windows-10-10.0.19045-SP0
2025-10-15 11:47:29,705:INFO:Memory: svmem(total=8465043456, available=1256050688, percent=85.2, used=7208992768, free=1256050688)
2025-10-15 11:47:29,706:INFO:Physical Core: 2
2025-10-15 11:47:29,706:INFO:Logical Core: 4
2025-10-15 11:47:29,706:INFO:Checking libraries
2025-10-15 11:47:29,706:INFO:System:
2025-10-15 11:47:29,706:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-10-15 11:47:29,706:INFO:executable: c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\Scripts\python.exe
2025-10-15 11:47:29,706:INFO:   machine: Windows-10-10.0.19045-SP0
2025-10-15 11:47:29,706:INFO:PyCaret required dependencies:
2025-10-15 11:47:29,736:INFO:                 pip: 25.2
2025-10-15 11:47:29,736:INFO:          setuptools: 57.4.0
2025-10-15 11:47:29,872:INFO:             pycaret: 3.3.2
2025-10-15 11:47:29,873:INFO:             IPython: 8.37.0
2025-10-15 11:47:29,874:INFO:          ipywidgets: 8.1.7
2025-10-15 11:47:29,875:INFO:                tqdm: 4.67.1
2025-10-15 11:47:29,876:INFO:               numpy: 1.26.4
2025-10-15 11:47:29,876:INFO:              pandas: 2.0.3
2025-10-15 11:47:29,877:INFO:              jinja2: 3.1.6
2025-10-15 11:47:29,879:INFO:               scipy: 1.11.4
2025-10-15 11:47:29,879:INFO:              joblib: 1.3.2
2025-10-15 11:47:29,888:INFO:             sklearn: 1.4.2
2025-10-15 11:47:29,889:INFO:                pyod: 2.0.5
2025-10-15 11:47:29,890:INFO:            imblearn: 0.14.0
2025-10-15 11:47:29,890:INFO:   category_encoders: 2.7.0
2025-10-15 11:47:29,891:INFO:            lightgbm: 4.6.0
2025-10-15 11:47:29,892:INFO:               numba: 0.62.1
2025-10-15 11:47:29,892:INFO:            requests: 2.32.5
2025-10-15 11:47:29,893:INFO:          matplotlib: 3.7.5
2025-10-15 11:47:29,893:INFO:          scikitplot: 0.3.7
2025-10-15 11:47:29,893:INFO:         yellowbrick: 1.5
2025-10-15 11:47:29,893:INFO:              plotly: 6.3.1
2025-10-15 11:47:29,893:INFO:    plotly-resampler: Not installed
2025-10-15 11:47:29,893:INFO:             kaleido: 1.1.0
2025-10-15 11:47:29,900:INFO:           schemdraw: 0.15
2025-10-15 11:47:29,900:INFO:         statsmodels: 0.14.5
2025-10-15 11:47:29,903:INFO:              sktime: 0.26.0
2025-10-15 11:47:29,904:INFO:               tbats: 1.1.3
2025-10-15 11:47:29,905:INFO:            pmdarima: 2.0.4
2025-10-15 11:47:29,906:INFO:              psutil: 7.1.0
2025-10-15 11:47:29,907:INFO:          markupsafe: 3.0.3
2025-10-15 11:47:29,907:INFO:             pickle5: Not installed
2025-10-15 11:47:29,907:INFO:         cloudpickle: 3.1.1
2025-10-15 11:47:29,907:INFO:         deprecation: 2.1.0
2025-10-15 11:47:29,910:INFO:              xxhash: 3.6.0
2025-10-15 11:47:29,910:INFO:           wurlitzer: Not installed
2025-10-15 11:47:29,910:INFO:PyCaret optional dependencies:
2025-10-15 11:47:37,423:INFO:                shap: Not installed
2025-10-15 11:47:37,423:INFO:           interpret: Not installed
2025-10-15 11:47:37,423:INFO:                umap: Not installed
2025-10-15 11:47:37,424:INFO:     ydata_profiling: Not installed
2025-10-15 11:47:37,424:INFO:  explainerdashboard: Not installed
2025-10-15 11:47:37,424:INFO:             autoviz: Not installed
2025-10-15 11:47:37,424:INFO:           fairlearn: Not installed
2025-10-15 11:47:37,424:INFO:          deepchecks: Not installed
2025-10-15 11:47:37,425:INFO:             xgboost: 2.1.4
2025-10-15 11:47:37,425:INFO:            catboost: Not installed
2025-10-15 11:47:37,425:INFO:              kmodes: Not installed
2025-10-15 11:47:37,425:INFO:             mlxtend: Not installed
2025-10-15 11:47:37,426:INFO:       statsforecast: Not installed
2025-10-15 11:47:37,426:INFO:        tune_sklearn: Not installed
2025-10-15 11:47:37,426:INFO:                 ray: Not installed
2025-10-15 11:47:37,426:INFO:            hyperopt: Not installed
2025-10-15 11:47:37,426:INFO:              optuna: Not installed
2025-10-15 11:47:37,427:INFO:               skopt: Not installed
2025-10-15 11:47:37,427:INFO:              mlflow: 3.4.0
2025-10-15 11:47:37,427:INFO:              gradio: Not installed
2025-10-15 11:47:37,427:INFO:             fastapi: 0.119.0
2025-10-15 11:47:37,427:INFO:             uvicorn: 0.37.0
2025-10-15 11:47:37,427:INFO:              m2cgen: Not installed
2025-10-15 11:47:37,427:INFO:           evidently: Not installed
2025-10-15 11:47:37,427:INFO:               fugue: Not installed
2025-10-15 11:47:37,427:INFO:           streamlit: Not installed
2025-10-15 11:47:37,427:INFO:             prophet: Not installed
2025-10-15 11:47:37,432:INFO:None
2025-10-15 11:47:37,433:INFO:Set up data.
2025-10-15 17:50:12,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 17:50:12,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 17:50:12,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 17:50:12,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-15 17:50:20,848:INFO:PyCaret ClassificationExperiment
2025-10-15 17:50:20,849:INFO:Logging name: clf-default-name
2025-10-15 17:50:20,849:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-15 17:50:20,849:INFO:version 3.3.2
2025-10-15 17:50:20,849:INFO:Initializing setup()
2025-10-15 17:50:20,849:INFO:self.USI: 473d
2025-10-15 17:50:20,849:INFO:self._variable_keys: {'log_plots_param', 'data', 'fold_generator', 'idx', 'html_param', 'logging_param', 'gpu_param', 'gpu_n_jobs_param', 'X_train', '_ml_usecase', 'memory', '_available_plots', 'fold_shuffle_param', 'exp_id', 'is_multiclass', 'target_param', 'fix_imbalance', 'y_train', 'seed', 'exp_name_log', 'USI', 'y', 'X', 'X_test', 'n_jobs_param', 'pipeline', 'fold_groups_param', 'y_test'}
2025-10-15 17:50:20,849:INFO:Checking environment
2025-10-15 17:50:20,849:INFO:python_version: 3.10.0
2025-10-15 17:50:20,850:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-10-15 17:50:20,850:INFO:machine: AMD64
2025-10-15 17:50:20,850:INFO:platform: Windows-10-10.0.19045-SP0
2025-10-15 17:50:20,854:INFO:Memory: svmem(total=8465043456, available=1224355840, percent=85.5, used=7240687616, free=1224355840)
2025-10-15 17:50:20,854:INFO:Physical Core: 2
2025-10-15 17:50:20,856:INFO:Logical Core: 4
2025-10-15 17:50:20,856:INFO:Checking libraries
2025-10-15 17:50:20,856:INFO:System:
2025-10-15 17:50:20,857:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-10-15 17:50:20,857:INFO:executable: c:\Users\Khaled\Depi_Amit_A1_BNS3\Depi_Amit_A1_BNS3\pycaret_env\Scripts\python.exe
2025-10-15 17:50:20,857:INFO:   machine: Windows-10-10.0.19045-SP0
2025-10-15 17:50:20,857:INFO:PyCaret required dependencies:
2025-10-15 17:50:20,859:INFO:                 pip: 25.2
2025-10-15 17:50:20,859:INFO:          setuptools: 57.4.0
2025-10-15 17:50:20,859:INFO:             pycaret: 3.3.2
2025-10-15 17:50:20,859:INFO:             IPython: 8.37.0
2025-10-15 17:50:20,859:INFO:          ipywidgets: 8.1.7
2025-10-15 17:50:20,859:INFO:                tqdm: 4.67.1
2025-10-15 17:50:20,859:INFO:               numpy: 1.26.4
2025-10-15 17:50:20,859:INFO:              pandas: 2.0.3
2025-10-15 17:50:20,859:INFO:              jinja2: 3.1.6
2025-10-15 17:50:20,859:INFO:               scipy: 1.11.4
2025-10-15 17:50:20,863:INFO:              joblib: 1.3.2
2025-10-15 17:50:20,863:INFO:             sklearn: 1.4.2
2025-10-15 17:50:20,863:INFO:                pyod: 2.0.5
2025-10-15 17:50:20,863:INFO:            imblearn: 0.14.0
2025-10-15 17:50:20,863:INFO:   category_encoders: 2.7.0
2025-10-15 17:50:20,863:INFO:            lightgbm: 4.6.0
2025-10-15 17:50:20,863:INFO:               numba: 0.62.1
2025-10-15 17:50:20,863:INFO:            requests: 2.32.5
2025-10-15 17:50:20,864:INFO:          matplotlib: 3.7.5
2025-10-15 17:50:20,864:INFO:          scikitplot: 0.3.7
2025-10-15 17:50:20,864:INFO:         yellowbrick: 1.5
2025-10-15 17:50:20,864:INFO:              plotly: 6.3.1
2025-10-15 17:50:20,864:INFO:    plotly-resampler: Not installed
2025-10-15 17:50:20,864:INFO:             kaleido: 1.1.0
2025-10-15 17:50:20,864:INFO:           schemdraw: 0.15
2025-10-15 17:50:20,864:INFO:         statsmodels: 0.14.5
2025-10-15 17:50:20,865:INFO:              sktime: 0.26.0
2025-10-15 17:50:20,865:INFO:               tbats: 1.1.3
2025-10-15 17:50:20,865:INFO:            pmdarima: 2.0.4
2025-10-15 17:50:20,865:INFO:              psutil: 7.1.0
2025-10-15 17:50:20,865:INFO:          markupsafe: 3.0.3
2025-10-15 17:50:20,865:INFO:             pickle5: Not installed
2025-10-15 17:50:20,865:INFO:         cloudpickle: 3.1.1
2025-10-15 17:50:20,865:INFO:         deprecation: 2.1.0
2025-10-15 17:50:20,866:INFO:              xxhash: 3.6.0
2025-10-15 17:50:20,866:INFO:           wurlitzer: Not installed
2025-10-15 17:50:20,866:INFO:PyCaret optional dependencies:
2025-10-15 17:50:22,967:INFO:                shap: Not installed
2025-10-15 17:50:22,967:INFO:           interpret: Not installed
2025-10-15 17:50:22,968:INFO:                umap: Not installed
2025-10-15 17:50:22,968:INFO:     ydata_profiling: Not installed
2025-10-15 17:50:22,968:INFO:  explainerdashboard: Not installed
2025-10-15 17:50:22,968:INFO:             autoviz: Not installed
2025-10-15 17:50:22,968:INFO:           fairlearn: Not installed
2025-10-15 17:50:22,968:INFO:          deepchecks: Not installed
2025-10-15 17:50:22,968:INFO:             xgboost: 2.1.4
2025-10-15 17:50:22,968:INFO:            catboost: Not installed
2025-10-15 17:50:22,968:INFO:              kmodes: Not installed
2025-10-15 17:50:22,968:INFO:             mlxtend: Not installed
2025-10-15 17:50:22,968:INFO:       statsforecast: Not installed
2025-10-15 17:50:22,968:INFO:        tune_sklearn: Not installed
2025-10-15 17:50:22,968:INFO:                 ray: Not installed
2025-10-15 17:50:22,968:INFO:            hyperopt: Not installed
2025-10-15 17:50:22,968:INFO:              optuna: Not installed
2025-10-15 17:50:22,968:INFO:               skopt: Not installed
2025-10-15 17:50:22,968:INFO:              mlflow: 3.4.0
2025-10-15 17:50:22,969:INFO:              gradio: Not installed
2025-10-15 17:50:22,969:INFO:             fastapi: 0.119.0
2025-10-15 17:50:22,969:INFO:             uvicorn: 0.37.0
2025-10-15 17:50:22,969:INFO:              m2cgen: Not installed
2025-10-15 17:50:22,969:INFO:           evidently: Not installed
2025-10-15 17:50:22,970:INFO:               fugue: Not installed
2025-10-15 17:50:22,970:INFO:           streamlit: Not installed
2025-10-15 17:50:22,970:INFO:             prophet: Not installed
2025-10-15 17:50:22,970:INFO:None
2025-10-15 17:50:22,970:INFO:Set up data.
2025-10-15 17:50:23,264:INFO:Set up folding strategy.
2025-10-15 17:50:23,264:INFO:Set up train/test split.
2025-10-15 17:50:23,610:INFO:Set up index.
2025-10-15 17:50:23,618:INFO:Assigning column types.
2025-10-15 17:50:24,058:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-15 17:50:24,194:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-15 17:50:24,202:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-15 17:50:24,317:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 17:50:24,328:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 17:50:24,526:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-15 17:50:24,528:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-15 17:50:24,626:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 17:50:24,634:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 17:50:24,635:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-15 17:50:24,739:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-15 17:50:24,772:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 17:50:24,790:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 17:50:24,859:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-15 17:50:24,940:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 17:50:24,940:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 17:50:24,940:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-15 17:50:25,158:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 17:50:25,163:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 17:50:25,289:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 17:50:25,308:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 17:50:25,374:INFO:Set up column name cleaning.
2025-10-15 17:50:25,612:INFO:Finished creating preprocessing pipeline.
2025-10-15 17:50:25,625:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Khaled\AppData\Local\Temp\joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-15 17:50:25,625:INFO:Creating final display dataframe.
2025-10-15 17:50:26,883:INFO:Setup _display_container:                    Description         Value
0                   Session id            42
1                       Target        donate
2                  Target type        Binary
3          Original data shape  (36177, 104)
4       Transformed data shape  (36177, 104)
5  Transformed train set shape  (25323, 104)
6   Transformed test set shape  (10854, 104)
7             Numeric features           103
2025-10-15 17:50:27,057:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 17:50:27,063:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 17:50:27,274:INFO:Soft dependency imported: xgboost: 2.1.4
2025-10-15 17:50:27,278:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-15 17:50:27,278:INFO:setup() successfully completed in 6.46s...............
2025-10-15 17:50:27,291:INFO:Initializing compare_models()
2025-10-15 17:50:27,292:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D06F668910>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001D06F668910>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-10-15 17:50:27,292:INFO:Checking exceptions
2025-10-15 17:50:27,574:INFO:Preparing display monitor
2025-10-15 17:50:27,691:INFO:Initializing Logistic Regression
2025-10-15 17:50:27,691:INFO:Total runtime is 9.735425313313801e-07 minutes
2025-10-15 17:50:27,705:INFO:SubProcess create_model() called ==================================
2025-10-15 17:50:27,705:INFO:Initializing create_model()
2025-10-15 17:50:27,705:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D06F668910>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D072B109D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 17:50:27,705:INFO:Checking exceptions
2025-10-15 17:50:27,705:INFO:Importing libraries
2025-10-15 17:50:27,705:INFO:Copying training dataset
2025-10-15 17:50:28,160:INFO:Defining folds
2025-10-15 17:50:28,160:INFO:Declaring metric variables
2025-10-15 17:50:28,166:INFO:Importing untrained model
2025-10-15 17:50:28,179:INFO:Logistic Regression Imported successfully
2025-10-15 17:50:28,202:INFO:Starting cross validation
2025-10-15 17:50:28,208:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-10-15 17:50:34,246:INFO:Calculating mean and std
2025-10-15 17:50:34,280:INFO:Creating metrics dataframe
2025-10-15 17:50:34,289:INFO:Uploading results into container
2025-10-15 17:50:34,289:INFO:Uploading model into container now
2025-10-15 17:50:34,289:INFO:_master_model_container: 1
2025-10-15 17:50:34,289:INFO:_display_container: 2
2025-10-15 17:50:34,289:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-15 17:50:34,289:INFO:create_model() successfully completed......................................
2025-10-15 17:50:34,481:INFO:SubProcess create_model() end ==================================
2025-10-15 17:50:34,481:INFO:Creating metrics dataframe
2025-10-15 17:50:34,496:INFO:Initializing K Neighbors Classifier
2025-10-15 17:50:34,496:INFO:Total runtime is 0.11340849399566649 minutes
2025-10-15 17:50:34,506:INFO:SubProcess create_model() called ==================================
2025-10-15 17:50:34,506:INFO:Initializing create_model()
2025-10-15 17:50:34,506:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D06F668910>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D072B109D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 17:50:34,507:INFO:Checking exceptions
2025-10-15 17:50:34,507:INFO:Importing libraries
2025-10-15 17:50:34,507:INFO:Copying training dataset
2025-10-15 17:50:34,859:INFO:Defining folds
2025-10-15 17:50:34,859:INFO:Declaring metric variables
2025-10-15 17:50:34,873:INFO:Importing untrained model
2025-10-15 17:50:34,882:INFO:K Neighbors Classifier Imported successfully
2025-10-15 17:50:34,909:INFO:Starting cross validation
2025-10-15 17:50:34,913:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-10-15 17:50:49,678:INFO:Calculating mean and std
2025-10-15 17:50:49,689:INFO:Creating metrics dataframe
2025-10-15 17:50:49,696:INFO:Uploading results into container
2025-10-15 17:50:49,697:INFO:Uploading model into container now
2025-10-15 17:50:49,700:INFO:_master_model_container: 2
2025-10-15 17:50:49,700:INFO:_display_container: 2
2025-10-15 17:50:49,700:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-15 17:50:49,700:INFO:create_model() successfully completed......................................
2025-10-15 17:50:49,852:INFO:SubProcess create_model() end ==================================
2025-10-15 17:50:49,852:INFO:Creating metrics dataframe
2025-10-15 17:50:49,872:INFO:Initializing Naive Bayes
2025-10-15 17:50:49,873:INFO:Total runtime is 0.3696936289469401 minutes
2025-10-15 17:50:49,881:INFO:SubProcess create_model() called ==================================
2025-10-15 17:50:49,884:INFO:Initializing create_model()
2025-10-15 17:50:49,884:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D06F668910>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D072B109D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 17:50:49,885:INFO:Checking exceptions
2025-10-15 17:50:49,885:INFO:Importing libraries
2025-10-15 17:50:49,885:INFO:Copying training dataset
2025-10-15 17:50:50,161:INFO:Defining folds
2025-10-15 17:50:50,161:INFO:Declaring metric variables
2025-10-15 17:50:50,174:INFO:Importing untrained model
2025-10-15 17:50:50,184:INFO:Naive Bayes Imported successfully
2025-10-15 17:50:50,202:INFO:Starting cross validation
2025-10-15 17:50:50,203:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-10-15 17:50:51,487:INFO:Calculating mean and std
2025-10-15 17:50:51,492:INFO:Creating metrics dataframe
2025-10-15 17:50:51,495:INFO:Uploading results into container
2025-10-15 17:50:51,498:INFO:Uploading model into container now
2025-10-15 17:50:51,502:INFO:_master_model_container: 3
2025-10-15 17:50:51,502:INFO:_display_container: 2
2025-10-15 17:50:51,503:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-15 17:50:51,503:INFO:create_model() successfully completed......................................
2025-10-15 17:50:51,775:INFO:SubProcess create_model() end ==================================
2025-10-15 17:50:51,775:INFO:Creating metrics dataframe
2025-10-15 17:50:51,795:INFO:Initializing Decision Tree Classifier
2025-10-15 17:50:51,796:INFO:Total runtime is 0.40175155401229856 minutes
2025-10-15 17:50:51,806:INFO:SubProcess create_model() called ==================================
2025-10-15 17:50:51,807:INFO:Initializing create_model()
2025-10-15 17:50:51,808:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D06F668910>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D072B109D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 17:50:51,808:INFO:Checking exceptions
2025-10-15 17:50:51,808:INFO:Importing libraries
2025-10-15 17:50:51,808:INFO:Copying training dataset
2025-10-15 17:50:52,088:INFO:Defining folds
2025-10-15 17:50:52,088:INFO:Declaring metric variables
2025-10-15 17:50:52,099:INFO:Importing untrained model
2025-10-15 17:50:52,111:INFO:Decision Tree Classifier Imported successfully
2025-10-15 17:50:52,127:INFO:Starting cross validation
2025-10-15 17:50:52,130:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-10-15 17:50:54,927:INFO:Calculating mean and std
2025-10-15 17:50:54,934:INFO:Creating metrics dataframe
2025-10-15 17:50:54,940:INFO:Uploading results into container
2025-10-15 17:50:54,942:INFO:Uploading model into container now
2025-10-15 17:50:54,944:INFO:_master_model_container: 4
2025-10-15 17:50:54,944:INFO:_display_container: 2
2025-10-15 17:50:54,944:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-10-15 17:50:54,945:INFO:create_model() successfully completed......................................
2025-10-15 17:50:55,085:INFO:SubProcess create_model() end ==================================
2025-10-15 17:50:55,085:INFO:Creating metrics dataframe
2025-10-15 17:50:55,107:INFO:Initializing SVM - Linear Kernel
2025-10-15 17:50:55,107:INFO:Total runtime is 0.45693959792455036 minutes
2025-10-15 17:50:55,117:INFO:SubProcess create_model() called ==================================
2025-10-15 17:50:55,118:INFO:Initializing create_model()
2025-10-15 17:50:55,118:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D06F668910>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D072B109D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 17:50:55,118:INFO:Checking exceptions
2025-10-15 17:50:55,118:INFO:Importing libraries
2025-10-15 17:50:55,118:INFO:Copying training dataset
2025-10-15 17:50:55,407:INFO:Defining folds
2025-10-15 17:50:55,407:INFO:Declaring metric variables
2025-10-15 17:50:55,419:INFO:Importing untrained model
2025-10-15 17:50:55,428:INFO:SVM - Linear Kernel Imported successfully
2025-10-15 17:50:55,447:INFO:Starting cross validation
2025-10-15 17:50:55,455:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-10-15 17:50:59,884:INFO:Calculating mean and std
2025-10-15 17:50:59,889:INFO:Creating metrics dataframe
2025-10-15 17:50:59,902:INFO:Uploading results into container
2025-10-15 17:50:59,906:INFO:Uploading model into container now
2025-10-15 17:50:59,907:INFO:_master_model_container: 5
2025-10-15 17:50:59,907:INFO:_display_container: 2
2025-10-15 17:50:59,908:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-15 17:50:59,908:INFO:create_model() successfully completed......................................
2025-10-15 17:51:00,068:INFO:SubProcess create_model() end ==================================
2025-10-15 17:51:00,068:INFO:Creating metrics dataframe
2025-10-15 17:51:00,100:INFO:Initializing Ridge Classifier
2025-10-15 17:51:00,100:INFO:Total runtime is 0.5401484290758769 minutes
2025-10-15 17:51:00,108:INFO:SubProcess create_model() called ==================================
2025-10-15 17:51:00,108:INFO:Initializing create_model()
2025-10-15 17:51:00,109:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D06F668910>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D072B109D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 17:51:00,109:INFO:Checking exceptions
2025-10-15 17:51:00,109:INFO:Importing libraries
2025-10-15 17:51:00,109:INFO:Copying training dataset
2025-10-15 17:51:00,420:INFO:Defining folds
2025-10-15 17:51:00,420:INFO:Declaring metric variables
2025-10-15 17:51:00,437:INFO:Importing untrained model
2025-10-15 17:51:00,445:INFO:Ridge Classifier Imported successfully
2025-10-15 17:51:00,479:INFO:Starting cross validation
2025-10-15 17:51:00,479:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-10-15 17:51:01,449:INFO:Calculating mean and std
2025-10-15 17:51:01,450:INFO:Creating metrics dataframe
2025-10-15 17:51:01,453:INFO:Uploading results into container
2025-10-15 17:51:01,454:INFO:Uploading model into container now
2025-10-15 17:51:01,455:INFO:_master_model_container: 6
2025-10-15 17:51:01,455:INFO:_display_container: 2
2025-10-15 17:51:01,456:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-15 17:51:01,456:INFO:create_model() successfully completed......................................
2025-10-15 17:51:01,615:INFO:SubProcess create_model() end ==================================
2025-10-15 17:51:01,615:INFO:Creating metrics dataframe
2025-10-15 17:51:01,632:INFO:Initializing Random Forest Classifier
2025-10-15 17:51:01,632:INFO:Total runtime is 0.5656902194023132 minutes
2025-10-15 17:51:01,645:INFO:SubProcess create_model() called ==================================
2025-10-15 17:51:01,645:INFO:Initializing create_model()
2025-10-15 17:51:01,645:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D06F668910>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D072B109D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 17:51:01,645:INFO:Checking exceptions
2025-10-15 17:51:01,645:INFO:Importing libraries
2025-10-15 17:51:01,645:INFO:Copying training dataset
2025-10-15 17:51:02,060:INFO:Defining folds
2025-10-15 17:51:02,060:INFO:Declaring metric variables
2025-10-15 17:51:02,073:INFO:Importing untrained model
2025-10-15 17:51:02,084:INFO:Random Forest Classifier Imported successfully
2025-10-15 17:51:02,102:INFO:Starting cross validation
2025-10-15 17:51:02,106:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-10-15 17:51:33,429:INFO:Calculating mean and std
2025-10-15 17:51:33,436:INFO:Creating metrics dataframe
2025-10-15 17:51:33,445:INFO:Uploading results into container
2025-10-15 17:51:33,446:INFO:Uploading model into container now
2025-10-15 17:51:33,447:INFO:_master_model_container: 7
2025-10-15 17:51:33,447:INFO:_display_container: 2
2025-10-15 17:51:33,450:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-10-15 17:51:33,450:INFO:create_model() successfully completed......................................
2025-10-15 17:51:33,611:INFO:SubProcess create_model() end ==================================
2025-10-15 17:51:33,611:INFO:Creating metrics dataframe
2025-10-15 17:51:33,635:INFO:Initializing Quadratic Discriminant Analysis
2025-10-15 17:51:33,636:INFO:Total runtime is 1.0990790287653605 minutes
2025-10-15 17:51:33,649:INFO:SubProcess create_model() called ==================================
2025-10-15 17:51:33,649:INFO:Initializing create_model()
2025-10-15 17:51:33,650:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D06F668910>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D072B109D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 17:51:33,650:INFO:Checking exceptions
2025-10-15 17:51:33,650:INFO:Importing libraries
2025-10-15 17:51:33,650:INFO:Copying training dataset
2025-10-15 17:51:33,953:INFO:Defining folds
2025-10-15 17:51:33,953:INFO:Declaring metric variables
2025-10-15 17:51:33,964:INFO:Importing untrained model
2025-10-15 17:51:33,977:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-15 17:51:33,994:INFO:Starting cross validation
2025-10-15 17:51:33,996:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-10-15 17:51:38,292:INFO:Calculating mean and std
2025-10-15 17:51:38,308:INFO:Creating metrics dataframe
2025-10-15 17:51:38,316:INFO:Uploading results into container
2025-10-15 17:51:38,316:INFO:Uploading model into container now
2025-10-15 17:51:38,318:INFO:_master_model_container: 8
2025-10-15 17:51:38,318:INFO:_display_container: 2
2025-10-15 17:51:38,318:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-15 17:51:38,318:INFO:create_model() successfully completed......................................
2025-10-15 17:51:38,523:INFO:SubProcess create_model() end ==================================
2025-10-15 17:51:38,525:INFO:Creating metrics dataframe
2025-10-15 17:51:38,555:INFO:Initializing Ada Boost Classifier
2025-10-15 17:51:38,555:INFO:Total runtime is 1.1810685714085896 minutes
2025-10-15 17:51:38,580:INFO:SubProcess create_model() called ==================================
2025-10-15 17:51:38,581:INFO:Initializing create_model()
2025-10-15 17:51:38,582:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D06F668910>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D072B109D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 17:51:38,582:INFO:Checking exceptions
2025-10-15 17:51:38,582:INFO:Importing libraries
2025-10-15 17:51:38,582:INFO:Copying training dataset
2025-10-15 17:51:38,897:INFO:Defining folds
2025-10-15 17:51:38,898:INFO:Declaring metric variables
2025-10-15 17:51:38,914:INFO:Importing untrained model
2025-10-15 17:51:38,929:INFO:Ada Boost Classifier Imported successfully
2025-10-15 17:51:38,954:INFO:Starting cross validation
2025-10-15 17:51:38,959:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-10-15 17:51:49,373:INFO:Calculating mean and std
2025-10-15 17:51:49,375:INFO:Creating metrics dataframe
2025-10-15 17:51:49,383:INFO:Uploading results into container
2025-10-15 17:51:49,383:INFO:Uploading model into container now
2025-10-15 17:51:49,385:INFO:_master_model_container: 9
2025-10-15 17:51:49,385:INFO:_display_container: 2
2025-10-15 17:51:49,386:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-10-15 17:51:49,387:INFO:create_model() successfully completed......................................
2025-10-15 17:51:49,523:INFO:SubProcess create_model() end ==================================
2025-10-15 17:51:49,523:INFO:Creating metrics dataframe
2025-10-15 17:51:49,546:INFO:Initializing Gradient Boosting Classifier
2025-10-15 17:51:49,546:INFO:Total runtime is 1.364246376355489 minutes
2025-10-15 17:51:49,553:INFO:SubProcess create_model() called ==================================
2025-10-15 17:51:49,556:INFO:Initializing create_model()
2025-10-15 17:51:49,557:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D06F668910>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D072B109D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 17:51:49,557:INFO:Checking exceptions
2025-10-15 17:51:49,557:INFO:Importing libraries
2025-10-15 17:51:49,557:INFO:Copying training dataset
2025-10-15 17:51:49,807:INFO:Defining folds
2025-10-15 17:51:49,808:INFO:Declaring metric variables
2025-10-15 17:51:49,816:INFO:Importing untrained model
2025-10-15 17:51:49,829:INFO:Gradient Boosting Classifier Imported successfully
2025-10-15 17:51:49,848:INFO:Starting cross validation
2025-10-15 17:51:49,852:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-10-15 17:52:30,265:INFO:Calculating mean and std
2025-10-15 17:52:30,267:INFO:Creating metrics dataframe
2025-10-15 17:52:30,271:INFO:Uploading results into container
2025-10-15 17:52:30,275:INFO:Uploading model into container now
2025-10-15 17:52:30,275:INFO:_master_model_container: 10
2025-10-15 17:52:30,275:INFO:_display_container: 2
2025-10-15 17:52:30,280:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-15 17:52:30,280:INFO:create_model() successfully completed......................................
2025-10-15 17:52:30,443:INFO:SubProcess create_model() end ==================================
2025-10-15 17:52:30,443:INFO:Creating metrics dataframe
2025-10-15 17:52:30,467:INFO:Initializing Linear Discriminant Analysis
2025-10-15 17:52:30,467:INFO:Total runtime is 2.0462713400522867 minutes
2025-10-15 17:52:30,476:INFO:SubProcess create_model() called ==================================
2025-10-15 17:52:30,476:INFO:Initializing create_model()
2025-10-15 17:52:30,477:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D06F668910>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D072B109D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 17:52:30,477:INFO:Checking exceptions
2025-10-15 17:52:30,478:INFO:Importing libraries
2025-10-15 17:52:30,478:INFO:Copying training dataset
2025-10-15 17:52:30,767:INFO:Defining folds
2025-10-15 17:52:30,768:INFO:Declaring metric variables
2025-10-15 17:52:30,786:INFO:Importing untrained model
2025-10-15 17:52:30,797:INFO:Linear Discriminant Analysis Imported successfully
2025-10-15 17:52:30,821:INFO:Starting cross validation
2025-10-15 17:52:30,824:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-10-15 17:52:34,977:INFO:Calculating mean and std
2025-10-15 17:52:34,983:INFO:Creating metrics dataframe
2025-10-15 17:52:34,988:INFO:Uploading results into container
2025-10-15 17:52:34,990:INFO:Uploading model into container now
2025-10-15 17:52:34,991:INFO:_master_model_container: 11
2025-10-15 17:52:34,992:INFO:_display_container: 2
2025-10-15 17:52:34,997:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-15 17:52:34,997:INFO:create_model() successfully completed......................................
2025-10-15 17:52:35,165:INFO:SubProcess create_model() end ==================================
2025-10-15 17:52:35,165:INFO:Creating metrics dataframe
2025-10-15 17:52:35,188:INFO:Initializing Extra Trees Classifier
2025-10-15 17:52:35,188:INFO:Total runtime is 2.124957227706909 minutes
2025-10-15 17:52:35,203:INFO:SubProcess create_model() called ==================================
2025-10-15 17:52:35,203:INFO:Initializing create_model()
2025-10-15 17:52:35,204:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D06F668910>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D072B109D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 17:52:35,204:INFO:Checking exceptions
2025-10-15 17:52:35,205:INFO:Importing libraries
2025-10-15 17:52:35,205:INFO:Copying training dataset
2025-10-15 17:52:35,635:INFO:Defining folds
2025-10-15 17:52:35,637:INFO:Declaring metric variables
2025-10-15 17:52:35,652:INFO:Importing untrained model
2025-10-15 17:52:35,665:INFO:Extra Trees Classifier Imported successfully
2025-10-15 17:52:35,692:INFO:Starting cross validation
2025-10-15 17:52:35,700:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-10-15 17:53:26,087:INFO:Calculating mean and std
2025-10-15 17:53:26,089:INFO:Creating metrics dataframe
2025-10-15 17:53:26,093:INFO:Uploading results into container
2025-10-15 17:53:26,095:INFO:Uploading model into container now
2025-10-15 17:53:26,096:INFO:_master_model_container: 12
2025-10-15 17:53:26,096:INFO:_display_container: 2
2025-10-15 17:53:26,098:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-10-15 17:53:26,099:INFO:create_model() successfully completed......................................
2025-10-15 17:53:26,235:INFO:SubProcess create_model() end ==================================
2025-10-15 17:53:26,235:INFO:Creating metrics dataframe
2025-10-15 17:53:26,253:INFO:Initializing Extreme Gradient Boosting
2025-10-15 17:53:26,253:INFO:Total runtime is 2.976025414466858 minutes
2025-10-15 17:53:26,261:INFO:SubProcess create_model() called ==================================
2025-10-15 17:53:26,261:INFO:Initializing create_model()
2025-10-15 17:53:26,261:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D06F668910>, estimator=xgboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D072B109D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 17:53:26,262:INFO:Checking exceptions
2025-10-15 17:53:26,262:INFO:Importing libraries
2025-10-15 17:53:26,262:INFO:Copying training dataset
2025-10-15 17:53:26,493:INFO:Defining folds
2025-10-15 17:53:26,493:INFO:Declaring metric variables
2025-10-15 17:53:26,505:INFO:Importing untrained model
2025-10-15 17:53:26,514:INFO:Extreme Gradient Boosting Imported successfully
2025-10-15 17:53:26,532:INFO:Starting cross validation
2025-10-15 17:53:26,533:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-10-15 17:53:34,746:INFO:Calculating mean and std
2025-10-15 17:53:34,748:INFO:Creating metrics dataframe
2025-10-15 17:53:34,753:INFO:Uploading results into container
2025-10-15 17:53:34,755:INFO:Uploading model into container now
2025-10-15 17:53:34,755:INFO:_master_model_container: 13
2025-10-15 17:53:34,756:INFO:_display_container: 2
2025-10-15 17:53:34,759:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-10-15 17:53:34,759:INFO:create_model() successfully completed......................................
2025-10-15 17:53:34,918:INFO:SubProcess create_model() end ==================================
2025-10-15 17:53:34,919:INFO:Creating metrics dataframe
2025-10-15 17:53:34,941:INFO:Initializing Light Gradient Boosting Machine
2025-10-15 17:53:34,941:INFO:Total runtime is 3.1208370685577393 minutes
2025-10-15 17:53:34,948:INFO:SubProcess create_model() called ==================================
2025-10-15 17:53:34,949:INFO:Initializing create_model()
2025-10-15 17:53:34,951:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D06F668910>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D072B109D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 17:53:34,952:INFO:Checking exceptions
2025-10-15 17:53:34,952:INFO:Importing libraries
2025-10-15 17:53:34,953:INFO:Copying training dataset
2025-10-15 17:53:35,203:INFO:Defining folds
2025-10-15 17:53:35,203:INFO:Declaring metric variables
2025-10-15 17:53:35,211:INFO:Importing untrained model
2025-10-15 17:53:35,227:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-15 17:53:35,243:INFO:Starting cross validation
2025-10-15 17:53:35,245:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-10-15 17:53:35,470:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:53:35,477:INFO:[LightGBM] [Info] Number of positive: 5021, number of negative: 15237
2025-10-15 17:53:35,503:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010774 seconds.
2025-10-15 17:53:35,503:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:53:35,503:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:53:35,503:INFO:[LightGBM] [Info] Total Bins 483
2025-10-15 17:53:35,505:INFO:[LightGBM] [Info] Number of data points in the train set: 20258, number of used features: 86
2025-10-15 17:53:35,508:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247853 -> initscore=-1.110098
2025-10-15 17:53:35,508:INFO:[LightGBM] [Info] Start training from score -1.110098
2025-10-15 17:53:36,212:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:53:36,219:INFO:[LightGBM] [Info] Number of positive: 5021, number of negative: 15237
2025-10-15 17:53:36,233:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005840 seconds.
2025-10-15 17:53:36,233:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:53:36,233:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:53:36,234:INFO:[LightGBM] [Info] Total Bins 477
2025-10-15 17:53:36,235:INFO:[LightGBM] [Info] Number of data points in the train set: 20258, number of used features: 85
2025-10-15 17:53:36,236:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247853 -> initscore=-1.110098
2025-10-15 17:53:36,236:INFO:[LightGBM] [Info] Start training from score -1.110098
2025-10-15 17:53:37,136:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:53:37,136:INFO:[LightGBM] [Info] Number of positive: 5020, number of negative: 15238
2025-10-15 17:53:37,155:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006086 seconds.
2025-10-15 17:53:37,155:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:53:37,155:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:53:37,155:INFO:[LightGBM] [Info] Total Bins 479
2025-10-15 17:53:37,155:INFO:[LightGBM] [Info] Number of data points in the train set: 20258, number of used features: 86
2025-10-15 17:53:37,157:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247803 -> initscore=-1.110362
2025-10-15 17:53:37,157:INFO:[LightGBM] [Info] Start training from score -1.110362
2025-10-15 17:53:37,849:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:53:37,851:INFO:[LightGBM] [Info] Number of positive: 5021, number of negative: 15238
2025-10-15 17:53:37,866:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006266 seconds.
2025-10-15 17:53:37,867:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:53:37,867:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:53:37,867:INFO:[LightGBM] [Info] Total Bins 479
2025-10-15 17:53:37,867:INFO:[LightGBM] [Info] Number of data points in the train set: 20259, number of used features: 86
2025-10-15 17:53:37,867:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247840 -> initscore=-1.110163
2025-10-15 17:53:37,867:INFO:[LightGBM] [Info] Start training from score -1.110163
2025-10-15 17:53:38,642:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:53:38,642:INFO:[LightGBM] [Info] Number of positive: 5021, number of negative: 15238
2025-10-15 17:53:38,671:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011437 seconds.
2025-10-15 17:53:38,671:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:53:38,671:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:53:38,671:INFO:[LightGBM] [Info] Total Bins 484
2025-10-15 17:53:38,671:INFO:[LightGBM] [Info] Number of data points in the train set: 20259, number of used features: 86
2025-10-15 17:53:38,671:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247840 -> initscore=-1.110163
2025-10-15 17:53:38,671:INFO:[LightGBM] [Info] Start training from score -1.110163
2025-10-15 17:53:39,674:INFO:Calculating mean and std
2025-10-15 17:53:39,694:INFO:Creating metrics dataframe
2025-10-15 17:53:39,710:INFO:Uploading results into container
2025-10-15 17:53:39,710:INFO:Uploading model into container now
2025-10-15 17:53:39,713:INFO:_master_model_container: 14
2025-10-15 17:53:39,713:INFO:_display_container: 2
2025-10-15 17:53:39,717:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-15 17:53:39,717:INFO:create_model() successfully completed......................................
2025-10-15 17:53:40,011:INFO:SubProcess create_model() end ==================================
2025-10-15 17:53:40,011:INFO:Creating metrics dataframe
2025-10-15 17:53:40,066:INFO:Initializing Dummy Classifier
2025-10-15 17:53:40,070:INFO:Total runtime is 3.2063239852587384 minutes
2025-10-15 17:53:40,079:INFO:SubProcess create_model() called ==================================
2025-10-15 17:53:40,079:INFO:Initializing create_model()
2025-10-15 17:53:40,080:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D06F668910>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D072B109D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 17:53:40,082:INFO:Checking exceptions
2025-10-15 17:53:40,087:INFO:Importing libraries
2025-10-15 17:53:40,087:INFO:Copying training dataset
2025-10-15 17:53:40,742:INFO:Defining folds
2025-10-15 17:53:40,742:INFO:Declaring metric variables
2025-10-15 17:53:40,757:INFO:Importing untrained model
2025-10-15 17:53:40,766:INFO:Dummy Classifier Imported successfully
2025-10-15 17:53:40,792:INFO:Starting cross validation
2025-10-15 17:53:40,794:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-10-15 17:53:41,698:INFO:Calculating mean and std
2025-10-15 17:53:41,702:INFO:Creating metrics dataframe
2025-10-15 17:53:41,721:INFO:Uploading results into container
2025-10-15 17:53:41,722:INFO:Uploading model into container now
2025-10-15 17:53:41,722:INFO:_master_model_container: 15
2025-10-15 17:53:41,722:INFO:_display_container: 2
2025-10-15 17:53:41,722:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-10-15 17:53:41,722:INFO:create_model() successfully completed......................................
2025-10-15 17:53:41,870:INFO:SubProcess create_model() end ==================================
2025-10-15 17:53:41,870:INFO:Creating metrics dataframe
2025-10-15 17:53:41,940:INFO:Initializing create_model()
2025-10-15 17:53:41,940:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D06F668910>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 17:53:41,940:INFO:Checking exceptions
2025-10-15 17:53:41,940:INFO:Importing libraries
2025-10-15 17:53:41,940:INFO:Copying training dataset
2025-10-15 17:53:42,424:INFO:Defining folds
2025-10-15 17:53:42,424:INFO:Declaring metric variables
2025-10-15 17:53:42,424:INFO:Importing untrained model
2025-10-15 17:53:42,424:INFO:Declaring custom model
2025-10-15 17:53:42,433:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-15 17:53:42,435:INFO:Cross validation set to False
2025-10-15 17:53:42,435:INFO:Fitting Model
2025-10-15 17:53:42,603:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:53:42,603:INFO:[LightGBM] [Info] Number of positive: 6276, number of negative: 19047
2025-10-15 17:53:42,632:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011767 seconds.
2025-10-15 17:53:42,633:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:53:42,633:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:53:42,633:INFO:[LightGBM] [Info] Total Bins 504
2025-10-15 17:53:42,634:INFO:[LightGBM] [Info] Number of data points in the train set: 25323, number of used features: 90
2025-10-15 17:53:42,634:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247838 -> initscore=-1.110177
2025-10-15 17:53:42,634:INFO:[LightGBM] [Info] Start training from score -1.110177
2025-10-15 17:53:43,009:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-15 17:53:43,009:INFO:create_model() successfully completed......................................
2025-10-15 17:53:43,210:INFO:Initializing create_model()
2025-10-15 17:53:43,210:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D06F668910>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 17:53:43,211:INFO:Checking exceptions
2025-10-15 17:53:43,215:INFO:Importing libraries
2025-10-15 17:53:43,215:INFO:Copying training dataset
2025-10-15 17:53:43,551:INFO:Defining folds
2025-10-15 17:53:43,551:INFO:Declaring metric variables
2025-10-15 17:53:43,551:INFO:Importing untrained model
2025-10-15 17:53:43,551:INFO:Declaring custom model
2025-10-15 17:53:43,551:INFO:Extreme Gradient Boosting Imported successfully
2025-10-15 17:53:43,551:INFO:Cross validation set to False
2025-10-15 17:53:43,551:INFO:Fitting Model
2025-10-15 17:53:45,218:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-10-15 17:53:45,218:INFO:create_model() successfully completed......................................
2025-10-15 17:53:45,396:INFO:Initializing create_model()
2025-10-15 17:53:45,396:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D06F668910>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 17:53:45,396:INFO:Checking exceptions
2025-10-15 17:53:45,409:INFO:Importing libraries
2025-10-15 17:53:45,409:INFO:Copying training dataset
2025-10-15 17:53:45,617:INFO:Defining folds
2025-10-15 17:53:45,617:INFO:Declaring metric variables
2025-10-15 17:53:45,617:INFO:Importing untrained model
2025-10-15 17:53:45,617:INFO:Declaring custom model
2025-10-15 17:53:45,617:INFO:Gradient Boosting Classifier Imported successfully
2025-10-15 17:53:45,617:INFO:Cross validation set to False
2025-10-15 17:53:45,617:INFO:Fitting Model
2025-10-15 17:53:55,387:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-15 17:53:55,387:INFO:create_model() successfully completed......................................
2025-10-15 17:53:55,652:INFO:_master_model_container: 15
2025-10-15 17:53:55,653:INFO:_display_container: 2
2025-10-15 17:53:55,655:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)]
2025-10-15 17:53:55,655:INFO:compare_models() successfully completed......................................
2025-10-15 17:53:55,675:INFO:Initializing blend_models()
2025-10-15 17:53:55,675:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D06F668910>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-15 17:53:55,675:INFO:Checking exceptions
2025-10-15 17:53:55,835:INFO:Importing libraries
2025-10-15 17:53:55,835:INFO:Copying training dataset
2025-10-15 17:53:55,858:INFO:Getting model names
2025-10-15 17:53:55,880:INFO:SubProcess create_model() called ==================================
2025-10-15 17:53:55,937:INFO:Initializing create_model()
2025-10-15 17:53:55,939:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D06F668910>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda=...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=42,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='soft',
                 weights=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D06ED754B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 17:53:55,939:INFO:Checking exceptions
2025-10-15 17:53:55,939:INFO:Importing libraries
2025-10-15 17:53:55,939:INFO:Copying training dataset
2025-10-15 17:53:56,200:INFO:Defining folds
2025-10-15 17:53:56,200:INFO:Declaring metric variables
2025-10-15 17:53:56,208:INFO:Importing untrained model
2025-10-15 17:53:56,208:INFO:Declaring custom model
2025-10-15 17:53:56,223:INFO:Voting Classifier Imported successfully
2025-10-15 17:53:56,243:INFO:Starting cross validation
2025-10-15 17:53:56,248:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-10-15 17:53:56,468:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:53:56,468:INFO:[LightGBM] [Info] Number of positive: 5021, number of negative: 15237
2025-10-15 17:53:56,489:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006379 seconds.
2025-10-15 17:53:56,489:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:53:56,489:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:53:56,489:INFO:[LightGBM] [Info] Total Bins 483
2025-10-15 17:53:56,489:INFO:[LightGBM] [Info] Number of data points in the train set: 20258, number of used features: 86
2025-10-15 17:53:56,489:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247853 -> initscore=-1.110098
2025-10-15 17:53:56,489:INFO:[LightGBM] [Info] Start training from score -1.110098
2025-10-15 17:54:05,262:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:54:05,262:INFO:[LightGBM] [Info] Number of positive: 5021, number of negative: 15237
2025-10-15 17:54:05,280:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006011 seconds.
2025-10-15 17:54:05,280:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:54:05,280:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:54:05,280:INFO:[LightGBM] [Info] Total Bins 477
2025-10-15 17:54:05,280:INFO:[LightGBM] [Info] Number of data points in the train set: 20258, number of used features: 85
2025-10-15 17:54:05,289:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247853 -> initscore=-1.110098
2025-10-15 17:54:05,289:INFO:[LightGBM] [Info] Start training from score -1.110098
2025-10-15 17:54:13,651:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:54:13,655:INFO:[LightGBM] [Info] Number of positive: 5020, number of negative: 15238
2025-10-15 17:54:13,696:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026920 seconds.
2025-10-15 17:54:13,696:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-15 17:54:13,696:INFO:[LightGBM] [Info] Total Bins 479
2025-10-15 17:54:13,696:INFO:[LightGBM] [Info] Number of data points in the train set: 20258, number of used features: 86
2025-10-15 17:54:13,697:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247803 -> initscore=-1.110362
2025-10-15 17:54:13,697:INFO:[LightGBM] [Info] Start training from score -1.110362
2025-10-15 17:54:22,050:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:54:22,051:INFO:[LightGBM] [Info] Number of positive: 5021, number of negative: 15238
2025-10-15 17:54:22,059:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009364 seconds.
2025-10-15 17:54:22,059:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:54:22,059:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:54:22,059:INFO:[LightGBM] [Info] Total Bins 479
2025-10-15 17:54:22,059:INFO:[LightGBM] [Info] Number of data points in the train set: 20259, number of used features: 86
2025-10-15 17:54:22,059:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247840 -> initscore=-1.110163
2025-10-15 17:54:22,059:INFO:[LightGBM] [Info] Start training from score -1.110163
2025-10-15 17:54:30,484:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:54:30,489:INFO:[LightGBM] [Info] Number of positive: 5021, number of negative: 15238
2025-10-15 17:54:30,509:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008465 seconds.
2025-10-15 17:54:30,509:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:54:30,509:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:54:30,509:INFO:[LightGBM] [Info] Total Bins 484
2025-10-15 17:54:30,512:INFO:[LightGBM] [Info] Number of data points in the train set: 20259, number of used features: 86
2025-10-15 17:54:30,512:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247840 -> initscore=-1.110163
2025-10-15 17:54:30,512:INFO:[LightGBM] [Info] Start training from score -1.110163
2025-10-15 17:54:39,103:INFO:Calculating mean and std
2025-10-15 17:54:39,107:INFO:Creating metrics dataframe
2025-10-15 17:54:39,126:INFO:Finalizing model
2025-10-15 17:54:39,331:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:54:39,331:INFO:[LightGBM] [Info] Number of positive: 6276, number of negative: 19047
2025-10-15 17:54:39,364:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013757 seconds.
2025-10-15 17:54:39,372:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:54:39,372:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:54:39,373:INFO:[LightGBM] [Info] Total Bins 504
2025-10-15 17:54:39,374:INFO:[LightGBM] [Info] Number of data points in the train set: 25323, number of used features: 90
2025-10-15 17:54:39,375:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247838 -> initscore=-1.110177
2025-10-15 17:54:39,375:INFO:[LightGBM] [Info] Start training from score -1.110177
2025-10-15 17:54:49,669:INFO:Uploading results into container
2025-10-15 17:54:49,673:INFO:Uploading model into container now
2025-10-15 17:54:49,674:INFO:_master_model_container: 16
2025-10-15 17:54:49,674:INFO:_display_container: 3
2025-10-15 17:54:49,704:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda=...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=42,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='soft',
                 weights=None)
2025-10-15 17:54:49,705:INFO:create_model() successfully completed......................................
2025-10-15 17:54:49,872:INFO:SubProcess create_model() end ==================================
2025-10-15 17:54:49,895:INFO:_master_model_container: 16
2025-10-15 17:54:49,895:INFO:_display_container: 3
2025-10-15 17:54:49,905:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda=...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=42,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='soft',
                 weights=None)
2025-10-15 17:54:49,905:INFO:blend_models() successfully completed......................................
2025-10-15 17:54:50,072:INFO:Initializing stack_models()
2025-10-15 17:54:50,072:INFO:stack_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D06F668910>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)], meta_model=None, meta_model_fold=5, fold=None, round=4, method=auto, restack=False, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-15 17:54:50,072:INFO:Checking exceptions
2025-10-15 17:54:50,139:INFO:Defining meta model
2025-10-15 17:54:50,201:INFO:Getting model names
2025-10-15 17:54:50,201:INFO:[('Light Gradient Boosting Machine', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)), ('Extreme Gradient Boosting', XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)), ('Gradient Boosting Classifier', GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False))]
2025-10-15 17:54:50,221:INFO:SubProcess create_model() called ==================================
2025-10-15 17:54:50,260:INFO:Initializing create_model()
2025-10-15 17:54:50,260:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D06F668910>, estimator=StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=1,
                                               num_leaves=31, objective=None,
                                               random_state=42, reg_alpha=0.0,
                                               reg_...
                                                           validation_fraction=0.1,
                                                           verbose=0,
                                                           warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=1, passthrough=False, stack_method='auto', verbose=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D072706CB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 17:54:50,260:INFO:Checking exceptions
2025-10-15 17:54:50,260:INFO:Importing libraries
2025-10-15 17:54:50,260:INFO:Copying training dataset
2025-10-15 17:54:50,542:INFO:Defining folds
2025-10-15 17:54:50,542:INFO:Declaring metric variables
2025-10-15 17:54:50,547:INFO:Importing untrained model
2025-10-15 17:54:50,547:INFO:Declaring custom model
2025-10-15 17:54:50,565:INFO:Stacking Classifier Imported successfully
2025-10-15 17:54:50,588:INFO:Starting cross validation
2025-10-15 17:54:50,588:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-10-15 17:54:50,853:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:54:50,853:INFO:[LightGBM] [Info] Number of positive: 5021, number of negative: 15237
2025-10-15 17:54:50,871:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005632 seconds.
2025-10-15 17:54:50,871:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:54:50,871:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:54:50,871:INFO:[LightGBM] [Info] Total Bins 483
2025-10-15 17:54:50,871:INFO:[LightGBM] [Info] Number of data points in the train set: 20258, number of used features: 86
2025-10-15 17:54:50,871:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247853 -> initscore=-1.110098
2025-10-15 17:54:50,871:INFO:[LightGBM] [Info] Start training from score -1.110098
2025-10-15 17:55:00,903:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:55:00,903:INFO:[LightGBM] [Info] Number of positive: 4016, number of negative: 12190
2025-10-15 17:55:00,918:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004791 seconds.
2025-10-15 17:55:00,918:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:55:00,919:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:55:00,919:INFO:[LightGBM] [Info] Total Bins 465
2025-10-15 17:55:00,919:INFO:[LightGBM] [Info] Number of data points in the train set: 16206, number of used features: 84
2025-10-15 17:55:00,919:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247809 -> initscore=-1.110330
2025-10-15 17:55:00,919:INFO:[LightGBM] [Info] Start training from score -1.110330
2025-10-15 17:55:01,319:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:55:01,319:INFO:[LightGBM] [Info] Number of positive: 4017, number of negative: 12189
2025-10-15 17:55:01,336:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007907 seconds.
2025-10-15 17:55:01,336:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:55:01,336:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:55:01,336:INFO:[LightGBM] [Info] Total Bins 465
2025-10-15 17:55:01,336:INFO:[LightGBM] [Info] Number of data points in the train set: 16206, number of used features: 84
2025-10-15 17:55:01,336:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247871 -> initscore=-1.109999
2025-10-15 17:55:01,349:INFO:[LightGBM] [Info] Start training from score -1.109999
2025-10-15 17:55:01,792:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:55:01,792:INFO:[LightGBM] [Info] Number of positive: 4017, number of negative: 12189
2025-10-15 17:55:01,802:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007867 seconds.
2025-10-15 17:55:01,802:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:55:01,802:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:55:01,802:INFO:[LightGBM] [Info] Total Bins 467
2025-10-15 17:55:01,802:INFO:[LightGBM] [Info] Number of data points in the train set: 16206, number of used features: 83
2025-10-15 17:55:01,802:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247871 -> initscore=-1.109999
2025-10-15 17:55:01,802:INFO:[LightGBM] [Info] Start training from score -1.109999
2025-10-15 17:55:02,238:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:55:02,239:INFO:[LightGBM] [Info] Number of positive: 4017, number of negative: 12190
2025-10-15 17:55:02,252:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004815 seconds.
2025-10-15 17:55:02,252:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:55:02,252:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:55:02,252:INFO:[LightGBM] [Info] Total Bins 464
2025-10-15 17:55:02,252:INFO:[LightGBM] [Info] Number of data points in the train set: 16207, number of used features: 84
2025-10-15 17:55:02,252:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247856 -> initscore=-1.110081
2025-10-15 17:55:02,252:INFO:[LightGBM] [Info] Start training from score -1.110081
2025-10-15 17:55:02,671:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:55:02,671:INFO:[LightGBM] [Info] Number of positive: 4017, number of negative: 12190
2025-10-15 17:55:02,685:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004892 seconds.
2025-10-15 17:55:02,685:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:55:02,685:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:55:02,685:INFO:[LightGBM] [Info] Total Bins 462
2025-10-15 17:55:02,685:INFO:[LightGBM] [Info] Number of data points in the train set: 16207, number of used features: 82
2025-10-15 17:55:02,685:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247856 -> initscore=-1.110081
2025-10-15 17:55:02,685:INFO:[LightGBM] [Info] Start training from score -1.110081
2025-10-15 17:55:35,080:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:55:35,095:INFO:[LightGBM] [Info] Number of positive: 5021, number of negative: 15237
2025-10-15 17:55:35,097:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005513 seconds.
2025-10-15 17:55:35,097:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:55:35,097:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:55:35,097:INFO:[LightGBM] [Info] Total Bins 477
2025-10-15 17:55:35,097:INFO:[LightGBM] [Info] Number of data points in the train set: 20258, number of used features: 85
2025-10-15 17:55:35,111:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247853 -> initscore=-1.110098
2025-10-15 17:55:35,111:INFO:[LightGBM] [Info] Start training from score -1.110098
2025-10-15 17:55:44,183:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:55:44,183:INFO:[LightGBM] [Info] Number of positive: 4017, number of negative: 12189
2025-10-15 17:55:44,195:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008912 seconds.
2025-10-15 17:55:44,208:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:55:44,208:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:55:44,209:INFO:[LightGBM] [Info] Total Bins 465
2025-10-15 17:55:44,210:INFO:[LightGBM] [Info] Number of data points in the train set: 16206, number of used features: 84
2025-10-15 17:55:44,210:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247871 -> initscore=-1.109999
2025-10-15 17:55:44,212:INFO:[LightGBM] [Info] Start training from score -1.109999
2025-10-15 17:55:44,711:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:55:44,711:INFO:[LightGBM] [Info] Number of positive: 4017, number of negative: 12189
2025-10-15 17:55:44,717:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004350 seconds.
2025-10-15 17:55:44,717:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:55:44,717:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:55:44,717:INFO:[LightGBM] [Info] Total Bins 459
2025-10-15 17:55:44,717:INFO:[LightGBM] [Info] Number of data points in the train set: 16206, number of used features: 83
2025-10-15 17:55:44,717:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247871 -> initscore=-1.109999
2025-10-15 17:55:44,717:INFO:[LightGBM] [Info] Start training from score -1.109999
2025-10-15 17:55:45,178:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:55:45,178:INFO:[LightGBM] [Info] Number of positive: 4016, number of negative: 12190
2025-10-15 17:55:45,194:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005602 seconds.
2025-10-15 17:55:45,194:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:55:45,194:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:55:45,194:INFO:[LightGBM] [Info] Total Bins 461
2025-10-15 17:55:45,194:INFO:[LightGBM] [Info] Number of data points in the train set: 16206, number of used features: 82
2025-10-15 17:55:45,194:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247809 -> initscore=-1.110330
2025-10-15 17:55:45,194:INFO:[LightGBM] [Info] Start training from score -1.110330
2025-10-15 17:55:45,677:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:55:45,678:INFO:[LightGBM] [Info] Number of positive: 4017, number of negative: 12190
2025-10-15 17:55:45,682:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004325 seconds.
2025-10-15 17:55:45,682:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:55:45,682:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:55:45,682:INFO:[LightGBM] [Info] Total Bins 462
2025-10-15 17:55:45,682:INFO:[LightGBM] [Info] Number of data points in the train set: 16207, number of used features: 83
2025-10-15 17:55:45,682:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247856 -> initscore=-1.110081
2025-10-15 17:55:45,682:INFO:[LightGBM] [Info] Start training from score -1.110081
2025-10-15 17:55:46,099:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:55:46,099:INFO:[LightGBM] [Info] Number of positive: 4017, number of negative: 12190
2025-10-15 17:55:46,111:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005226 seconds.
2025-10-15 17:55:46,111:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:55:46,111:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:55:46,111:INFO:[LightGBM] [Info] Total Bins 460
2025-10-15 17:55:46,111:INFO:[LightGBM] [Info] Number of data points in the train set: 16207, number of used features: 82
2025-10-15 17:55:46,111:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247856 -> initscore=-1.110081
2025-10-15 17:55:46,111:INFO:[LightGBM] [Info] Start training from score -1.110081
2025-10-15 17:56:18,326:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:56:18,327:INFO:[LightGBM] [Info] Number of positive: 5020, number of negative: 15238
2025-10-15 17:56:18,337:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005621 seconds.
2025-10-15 17:56:18,337:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:56:18,337:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:56:18,337:INFO:[LightGBM] [Info] Total Bins 479
2025-10-15 17:56:18,337:INFO:[LightGBM] [Info] Number of data points in the train set: 20258, number of used features: 86
2025-10-15 17:56:18,337:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247803 -> initscore=-1.110362
2025-10-15 17:56:18,337:INFO:[LightGBM] [Info] Start training from score -1.110362
2025-10-15 17:56:26,035:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:56:26,035:INFO:[LightGBM] [Info] Number of positive: 4016, number of negative: 12190
2025-10-15 17:56:26,054:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004541 seconds.
2025-10-15 17:56:26,054:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:56:26,054:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:56:26,055:INFO:[LightGBM] [Info] Total Bins 461
2025-10-15 17:56:26,055:INFO:[LightGBM] [Info] Number of data points in the train set: 16206, number of used features: 84
2025-10-15 17:56:26,055:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247809 -> initscore=-1.110330
2025-10-15 17:56:26,055:INFO:[LightGBM] [Info] Start training from score -1.110330
2025-10-15 17:56:26,519:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:56:26,519:INFO:[LightGBM] [Info] Number of positive: 4016, number of negative: 12190
2025-10-15 17:56:26,536:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004514 seconds.
2025-10-15 17:56:26,536:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:56:26,536:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:56:26,536:INFO:[LightGBM] [Info] Total Bins 460
2025-10-15 17:56:26,536:INFO:[LightGBM] [Info] Number of data points in the train set: 16206, number of used features: 82
2025-10-15 17:56:26,536:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247809 -> initscore=-1.110330
2025-10-15 17:56:26,536:INFO:[LightGBM] [Info] Start training from score -1.110330
2025-10-15 17:56:27,011:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:56:27,011:INFO:[LightGBM] [Info] Number of positive: 4016, number of negative: 12190
2025-10-15 17:56:27,027:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008068 seconds.
2025-10-15 17:56:27,027:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:56:27,027:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:56:27,027:INFO:[LightGBM] [Info] Total Bins 462
2025-10-15 17:56:27,027:INFO:[LightGBM] [Info] Number of data points in the train set: 16206, number of used features: 82
2025-10-15 17:56:27,028:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247809 -> initscore=-1.110330
2025-10-15 17:56:27,028:INFO:[LightGBM] [Info] Start training from score -1.110330
2025-10-15 17:56:27,470:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:56:27,470:INFO:[LightGBM] [Info] Number of positive: 4016, number of negative: 12191
2025-10-15 17:56:27,487:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007011 seconds.
2025-10-15 17:56:27,487:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:56:27,487:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:56:27,487:INFO:[LightGBM] [Info] Total Bins 463
2025-10-15 17:56:27,487:INFO:[LightGBM] [Info] Number of data points in the train set: 16207, number of used features: 84
2025-10-15 17:56:27,487:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247794 -> initscore=-1.110412
2025-10-15 17:56:27,487:INFO:[LightGBM] [Info] Start training from score -1.110412
2025-10-15 17:56:27,960:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:56:27,960:INFO:[LightGBM] [Info] Number of positive: 4016, number of negative: 12191
2025-10-15 17:56:27,966:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006024 seconds.
2025-10-15 17:56:27,966:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:56:27,966:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:56:27,966:INFO:[LightGBM] [Info] Total Bins 462
2025-10-15 17:56:27,966:INFO:[LightGBM] [Info] Number of data points in the train set: 16207, number of used features: 82
2025-10-15 17:56:27,966:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247794 -> initscore=-1.110412
2025-10-15 17:56:27,966:INFO:[LightGBM] [Info] Start training from score -1.110412
2025-10-15 17:57:02,695:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:57:02,695:INFO:[LightGBM] [Info] Number of positive: 5021, number of negative: 15238
2025-10-15 17:57:02,713:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005723 seconds.
2025-10-15 17:57:02,713:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:57:02,713:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:57:02,713:INFO:[LightGBM] [Info] Total Bins 479
2025-10-15 17:57:02,713:INFO:[LightGBM] [Info] Number of data points in the train set: 20259, number of used features: 86
2025-10-15 17:57:02,713:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247840 -> initscore=-1.110163
2025-10-15 17:57:02,713:INFO:[LightGBM] [Info] Start training from score -1.110163
2025-10-15 17:57:12,001:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:57:12,001:INFO:[LightGBM] [Info] Number of positive: 4017, number of negative: 12190
2025-10-15 17:57:12,020:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007337 seconds.
2025-10-15 17:57:12,020:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:57:12,020:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:57:12,021:INFO:[LightGBM] [Info] Total Bins 466
2025-10-15 17:57:12,021:INFO:[LightGBM] [Info] Number of data points in the train set: 16207, number of used features: 85
2025-10-15 17:57:12,021:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247856 -> initscore=-1.110081
2025-10-15 17:57:12,021:INFO:[LightGBM] [Info] Start training from score -1.110081
2025-10-15 17:57:12,965:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:57:12,966:INFO:[LightGBM] [Info] Number of positive: 4017, number of negative: 12190
2025-10-15 17:57:12,999:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015526 seconds.
2025-10-15 17:57:12,999:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:57:13,000:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:57:13,001:INFO:[LightGBM] [Info] Total Bins 460
2025-10-15 17:57:13,001:INFO:[LightGBM] [Info] Number of data points in the train set: 16207, number of used features: 83
2025-10-15 17:57:13,001:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247856 -> initscore=-1.110081
2025-10-15 17:57:13,002:INFO:[LightGBM] [Info] Start training from score -1.110081
2025-10-15 17:57:13,848:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:57:13,848:INFO:[LightGBM] [Info] Number of positive: 4017, number of negative: 12190
2025-10-15 17:57:13,874:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013495 seconds.
2025-10-15 17:57:13,875:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-15 17:57:13,876:INFO:[LightGBM] [Info] Total Bins 461
2025-10-15 17:57:13,876:INFO:[LightGBM] [Info] Number of data points in the train set: 16207, number of used features: 83
2025-10-15 17:57:13,876:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247856 -> initscore=-1.110081
2025-10-15 17:57:13,877:INFO:[LightGBM] [Info] Start training from score -1.110081
2025-10-15 17:57:14,526:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:57:14,527:INFO:[LightGBM] [Info] Number of positive: 4016, number of negative: 12191
2025-10-15 17:57:14,530:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004307 seconds.
2025-10-15 17:57:14,530:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:57:14,530:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:57:14,530:INFO:[LightGBM] [Info] Total Bins 457
2025-10-15 17:57:14,530:INFO:[LightGBM] [Info] Number of data points in the train set: 16207, number of used features: 83
2025-10-15 17:57:14,530:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247794 -> initscore=-1.110412
2025-10-15 17:57:14,530:INFO:[LightGBM] [Info] Start training from score -1.110412
2025-10-15 17:57:14,975:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:57:14,975:INFO:[LightGBM] [Info] Number of positive: 4017, number of negative: 12191
2025-10-15 17:57:14,994:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006176 seconds.
2025-10-15 17:57:14,994:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:57:14,994:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:57:14,994:INFO:[LightGBM] [Info] Total Bins 465
2025-10-15 17:57:14,994:INFO:[LightGBM] [Info] Number of data points in the train set: 16208, number of used features: 83
2025-10-15 17:57:14,994:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247841 -> initscore=-1.110163
2025-10-15 17:57:14,994:INFO:[LightGBM] [Info] Start training from score -1.110163
2025-10-15 17:57:50,236:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:57:50,236:INFO:[LightGBM] [Info] Number of positive: 5021, number of negative: 15238
2025-10-15 17:57:50,253:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005703 seconds.
2025-10-15 17:57:50,253:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:57:50,253:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:57:50,253:INFO:[LightGBM] [Info] Total Bins 484
2025-10-15 17:57:50,253:INFO:[LightGBM] [Info] Number of data points in the train set: 20259, number of used features: 86
2025-10-15 17:57:50,253:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247840 -> initscore=-1.110163
2025-10-15 17:57:50,253:INFO:[LightGBM] [Info] Start training from score -1.110163
2025-10-15 17:57:59,874:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:57:59,881:INFO:[LightGBM] [Info] Number of positive: 4017, number of negative: 12190
2025-10-15 17:57:59,900:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009129 seconds.
2025-10-15 17:57:59,900:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:57:59,901:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:57:59,901:INFO:[LightGBM] [Info] Total Bins 464
2025-10-15 17:57:59,901:INFO:[LightGBM] [Info] Number of data points in the train set: 16207, number of used features: 82
2025-10-15 17:57:59,903:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247856 -> initscore=-1.110081
2025-10-15 17:57:59,903:INFO:[LightGBM] [Info] Start training from score -1.110081
2025-10-15 17:58:00,358:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:58:00,358:INFO:[LightGBM] [Info] Number of positive: 4017, number of negative: 12190
2025-10-15 17:58:00,365:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007239 seconds.
2025-10-15 17:58:00,365:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:58:00,365:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:58:00,365:INFO:[LightGBM] [Info] Total Bins 459
2025-10-15 17:58:00,365:INFO:[LightGBM] [Info] Number of data points in the train set: 16207, number of used features: 81
2025-10-15 17:58:00,365:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247856 -> initscore=-1.110081
2025-10-15 17:58:00,365:INFO:[LightGBM] [Info] Start training from score -1.110081
2025-10-15 17:58:00,828:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:58:00,844:INFO:[LightGBM] [Info] Number of positive: 4017, number of negative: 12190
2025-10-15 17:58:00,847:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004504 seconds.
2025-10-15 17:58:00,847:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:58:00,847:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:58:00,847:INFO:[LightGBM] [Info] Total Bins 460
2025-10-15 17:58:00,847:INFO:[LightGBM] [Info] Number of data points in the train set: 16207, number of used features: 82
2025-10-15 17:58:00,847:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247856 -> initscore=-1.110081
2025-10-15 17:58:00,847:INFO:[LightGBM] [Info] Start training from score -1.110081
2025-10-15 17:58:01,178:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:58:01,179:INFO:[LightGBM] [Info] Number of positive: 4016, number of negative: 12191
2025-10-15 17:58:01,188:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004201 seconds.
2025-10-15 17:58:01,188:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:58:01,188:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:58:01,188:INFO:[LightGBM] [Info] Total Bins 466
2025-10-15 17:58:01,188:INFO:[LightGBM] [Info] Number of data points in the train set: 16207, number of used features: 82
2025-10-15 17:58:01,188:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247794 -> initscore=-1.110412
2025-10-15 17:58:01,188:INFO:[LightGBM] [Info] Start training from score -1.110412
2025-10-15 17:58:01,634:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:58:01,635:INFO:[LightGBM] [Info] Number of positive: 4017, number of negative: 12191
2025-10-15 17:58:01,665:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015063 seconds.
2025-10-15 17:58:01,665:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:58:01,665:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:58:01,665:INFO:[LightGBM] [Info] Total Bins 463
2025-10-15 17:58:01,666:INFO:[LightGBM] [Info] Number of data points in the train set: 16208, number of used features: 83
2025-10-15 17:58:01,666:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247841 -> initscore=-1.110163
2025-10-15 17:58:01,666:INFO:[LightGBM] [Info] Start training from score -1.110163
2025-10-15 17:58:46,877:INFO:Calculating mean and std
2025-10-15 17:58:46,879:INFO:Creating metrics dataframe
2025-10-15 17:58:46,888:INFO:Finalizing model
2025-10-15 17:58:47,129:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:58:47,129:INFO:[LightGBM] [Info] Number of positive: 6276, number of negative: 19047
2025-10-15 17:58:47,160:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013632 seconds.
2025-10-15 17:58:47,160:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:58:47,160:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:58:47,160:INFO:[LightGBM] [Info] Total Bins 504
2025-10-15 17:58:47,160:INFO:[LightGBM] [Info] Number of data points in the train set: 25323, number of used features: 90
2025-10-15 17:58:47,160:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247838 -> initscore=-1.110177
2025-10-15 17:58:47,160:INFO:[LightGBM] [Info] Start training from score -1.110177
2025-10-15 17:58:59,341:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:58:59,342:INFO:[LightGBM] [Info] Number of positive: 5021, number of negative: 15237
2025-10-15 17:58:59,372:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019875 seconds.
2025-10-15 17:58:59,372:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-15 17:58:59,373:INFO:[LightGBM] [Info] Total Bins 483
2025-10-15 17:58:59,374:INFO:[LightGBM] [Info] Number of data points in the train set: 20258, number of used features: 86
2025-10-15 17:58:59,375:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247853 -> initscore=-1.110098
2025-10-15 17:58:59,376:INFO:[LightGBM] [Info] Start training from score -1.110098
2025-10-15 17:59:00,293:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:59:00,293:INFO:[LightGBM] [Info] Number of positive: 5021, number of negative: 15237
2025-10-15 17:59:00,318:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005850 seconds.
2025-10-15 17:59:00,318:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:59:00,318:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:59:00,318:INFO:[LightGBM] [Info] Total Bins 477
2025-10-15 17:59:00,321:INFO:[LightGBM] [Info] Number of data points in the train set: 20258, number of used features: 85
2025-10-15 17:59:00,322:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247853 -> initscore=-1.110098
2025-10-15 17:59:00,322:INFO:[LightGBM] [Info] Start training from score -1.110098
2025-10-15 17:59:01,115:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:59:01,116:INFO:[LightGBM] [Info] Number of positive: 5020, number of negative: 15238
2025-10-15 17:59:01,144:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011506 seconds.
2025-10-15 17:59:01,144:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:59:01,144:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:59:01,146:INFO:[LightGBM] [Info] Total Bins 479
2025-10-15 17:59:01,146:INFO:[LightGBM] [Info] Number of data points in the train set: 20258, number of used features: 86
2025-10-15 17:59:01,146:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247803 -> initscore=-1.110362
2025-10-15 17:59:01,146:INFO:[LightGBM] [Info] Start training from score -1.110362
2025-10-15 17:59:01,946:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:59:01,946:INFO:[LightGBM] [Info] Number of positive: 5021, number of negative: 15238
2025-10-15 17:59:01,974:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011602 seconds.
2025-10-15 17:59:01,975:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:59:01,975:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:59:01,975:INFO:[LightGBM] [Info] Total Bins 479
2025-10-15 17:59:01,976:INFO:[LightGBM] [Info] Number of data points in the train set: 20259, number of used features: 86
2025-10-15 17:59:01,977:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247840 -> initscore=-1.110163
2025-10-15 17:59:01,977:INFO:[LightGBM] [Info] Start training from score -1.110163
2025-10-15 17:59:02,772:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:59:02,773:INFO:[LightGBM] [Info] Number of positive: 5021, number of negative: 15238
2025-10-15 17:59:02,796:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009312 seconds.
2025-10-15 17:59:02,796:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:59:02,796:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:59:02,799:INFO:[LightGBM] [Info] Total Bins 484
2025-10-15 17:59:02,800:INFO:[LightGBM] [Info] Number of data points in the train set: 20259, number of used features: 86
2025-10-15 17:59:02,800:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247840 -> initscore=-1.110163
2025-10-15 17:59:02,800:INFO:[LightGBM] [Info] Start training from score -1.110163
2025-10-15 17:59:50,936:INFO:Uploading results into container
2025-10-15 17:59:50,938:INFO:Uploading model into container now
2025-10-15 17:59:50,939:INFO:_master_model_container: 17
2025-10-15 17:59:50,939:INFO:_display_container: 4
2025-10-15 17:59:50,979:INFO:StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=1,
                                               num_leaves=31, objective=None,
                                               random_state=42, reg_alpha=0.0,
                                               reg_...
                                                           validation_fraction=0.1,
                                                           verbose=0,
                                                           warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=1, passthrough=False, stack_method='auto', verbose=0)
2025-10-15 17:59:50,980:INFO:create_model() successfully completed......................................
2025-10-15 17:59:51,185:INFO:SubProcess create_model() end ==================================
2025-10-15 17:59:51,205:INFO:_master_model_container: 17
2025-10-15 17:59:51,205:INFO:_display_container: 4
2025-10-15 17:59:51,234:INFO:StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=1,
                                               num_leaves=31, objective=None,
                                               random_state=42, reg_alpha=0.0,
                                               reg_...
                                                           validation_fraction=0.1,
                                                           verbose=0,
                                                           warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=1, passthrough=False, stack_method='auto', verbose=0)
2025-10-15 17:59:51,234:INFO:stack_models() successfully completed......................................
2025-10-15 17:59:51,402:INFO:Initializing evaluate_model()
2025-10-15 17:59:51,402:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D06F668910>, estimator=StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=1,
                                               num_leaves=31, objective=None,
                                               random_state=42, reg_alpha=0.0,
                                               reg_...
                                                           validation_fraction=0.1,
                                                           verbose=0,
                                                           warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=1, passthrough=False, stack_method='auto', verbose=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-10-15 17:59:51,585:INFO:Initializing plot_model()
2025-10-15 17:59:51,585:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=1,
                                               num_leaves=31, objective=None,
                                               random_state=42, reg_alpha=0.0,
                                               reg_...
                                                           validation_fraction=0.1,
                                                           verbose=0,
                                                           warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=1, passthrough=False, stack_method='auto', verbose=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D06F668910>, system=True)
2025-10-15 17:59:51,585:INFO:Checking exceptions
2025-10-15 17:59:51,664:INFO:Preloading libraries
2025-10-15 17:59:51,730:INFO:Copying training dataset
2025-10-15 17:59:51,730:INFO:Plot type: pipeline
2025-10-15 17:59:52,203:INFO:Visual Rendered Successfully
2025-10-15 17:59:52,350:INFO:plot_model() successfully completed......................................
2025-10-15 17:59:52,378:INFO:Initializing finalize_model()
2025-10-15 17:59:52,378:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D06F668910>, estimator=StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=1,
                                               num_leaves=31, objective=None,
                                               random_state=42, reg_alpha=0.0,
                                               reg_...
                                                           validation_fraction=0.1,
                                                           verbose=0,
                                                           warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=1, passthrough=False, stack_method='auto', verbose=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-10-15 17:59:52,385:INFO:Finalizing StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=1,
                                               num_leaves=31, objective=None,
                                               random_state=42, reg_alpha=0.0,
                                               reg_...
                                                           validation_fraction=0.1,
                                                           verbose=0,
                                                           warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=1, passthrough=False, stack_method='auto', verbose=0)
2025-10-15 17:59:52,617:INFO:Initializing create_model()
2025-10-15 17:59:52,617:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D06F668910>, estimator=StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=1,
                                               num_leaves=31, objective=None,
                                               random_state=42, reg_alpha=0.0,
                                               reg_...
                                                           validation_fraction=0.1,
                                                           verbose=0,
                                                           warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=1, passthrough=False, stack_method='auto', verbose=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-10-15 17:59:52,617:INFO:Checking exceptions
2025-10-15 17:59:52,631:INFO:Importing libraries
2025-10-15 17:59:52,631:INFO:Copying training dataset
2025-10-15 17:59:52,650:INFO:Defining folds
2025-10-15 17:59:52,650:INFO:Declaring metric variables
2025-10-15 17:59:52,650:INFO:Importing untrained model
2025-10-15 17:59:52,650:INFO:Declaring custom model
2025-10-15 17:59:52,665:INFO:Stacking Classifier Imported successfully
2025-10-15 17:59:52,666:INFO:Cross validation set to False
2025-10-15 17:59:52,666:INFO:Fitting Model
2025-10-15 17:59:52,896:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 17:59:52,896:INFO:[LightGBM] [Info] Number of positive: 8966, number of negative: 27211
2025-10-15 17:59:52,913:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012263 seconds.
2025-10-15 17:59:52,913:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 17:59:52,913:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 17:59:52,928:INFO:[LightGBM] [Info] Total Bins 532
2025-10-15 17:59:52,929:INFO:[LightGBM] [Info] Number of data points in the train set: 36177, number of used features: 94
2025-10-15 17:59:52,929:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247837 -> initscore=-1.110182
2025-10-15 17:59:52,929:INFO:[LightGBM] [Info] Start training from score -1.110182
2025-10-15 18:00:08,729:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 18:00:08,729:INFO:[LightGBM] [Info] Number of positive: 7173, number of negative: 21768
2025-10-15 18:00:08,779:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018533 seconds.
2025-10-15 18:00:08,779:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 18:00:08,779:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 18:00:08,779:INFO:[LightGBM] [Info] Total Bins 518
2025-10-15 18:00:08,779:INFO:[LightGBM] [Info] Number of data points in the train set: 28941, number of used features: 91
2025-10-15 18:00:08,779:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247849 -> initscore=-1.110117
2025-10-15 18:00:08,779:INFO:[LightGBM] [Info] Start training from score -1.110117
2025-10-15 18:00:10,163:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 18:00:10,164:INFO:[LightGBM] [Info] Number of positive: 7172, number of negative: 21769
2025-10-15 18:00:10,201:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016002 seconds.
2025-10-15 18:00:10,201:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 18:00:10,201:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 18:00:10,201:INFO:[LightGBM] [Info] Total Bins 510
2025-10-15 18:00:10,202:INFO:[LightGBM] [Info] Number of data points in the train set: 28941, number of used features: 89
2025-10-15 18:00:10,202:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247815 -> initscore=-1.110302
2025-10-15 18:00:10,202:INFO:[LightGBM] [Info] Start training from score -1.110302
2025-10-15 18:00:10,994:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 18:00:10,994:INFO:[LightGBM] [Info] Number of positive: 7173, number of negative: 21769
2025-10-15 18:00:11,031:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009792 seconds.
2025-10-15 18:00:11,031:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 18:00:11,031:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 18:00:11,031:INFO:[LightGBM] [Info] Total Bins 510
2025-10-15 18:00:11,031:INFO:[LightGBM] [Info] Number of data points in the train set: 28942, number of used features: 91
2025-10-15 18:00:11,031:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247841 -> initscore=-1.110163
2025-10-15 18:00:11,031:INFO:[LightGBM] [Info] Start training from score -1.110163
2025-10-15 18:00:11,776:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 18:00:11,776:INFO:[LightGBM] [Info] Number of positive: 7173, number of negative: 21769
2025-10-15 18:00:11,811:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011422 seconds.
2025-10-15 18:00:11,811:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 18:00:11,811:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 18:00:11,811:INFO:[LightGBM] [Info] Total Bins 509
2025-10-15 18:00:11,811:INFO:[LightGBM] [Info] Number of data points in the train set: 28942, number of used features: 89
2025-10-15 18:00:11,811:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247841 -> initscore=-1.110163
2025-10-15 18:00:11,811:INFO:[LightGBM] [Info] Start training from score -1.110163
2025-10-15 18:00:12,545:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-15 18:00:12,545:INFO:[LightGBM] [Info] Number of positive: 7173, number of negative: 21769
2025-10-15 18:00:12,561:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008751 seconds.
2025-10-15 18:00:12,561:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-15 18:00:12,561:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-15 18:00:12,561:INFO:[LightGBM] [Info] Total Bins 512
2025-10-15 18:00:12,561:INFO:[LightGBM] [Info] Number of data points in the train set: 28942, number of used features: 91
2025-10-15 18:00:12,561:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247841 -> initscore=-1.110163
2025-10-15 18:00:12,561:INFO:[LightGBM] [Info] Start training from score -1.110163
2025-10-15 18:01:11,347:INFO:Pipeline(memory=Memory(location=None),
         steps=[('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 StackingClassifier(cv=5,
                                    estimators=[('Light Gradient Boosting '
                                                 'Machine',
                                                 LGBMClassifier(boosting_type='gbdt',
                                                                class_weight=None,
                                                                colsample_bytree=1.0,
                                                                importan...
                                                                            verbose=0,
                                                                            warm_start=False))],
                                    final_estimator=LogisticRegression(C=1.0,
                                                                       class_weight=None,
                                                                       dual=False,
                                                                       fit_intercept=True,
                                                                       intercept_scaling=1,
                                                                       l1_ratio=None,
                                                                       max_iter=1000,
                                                                       multi_class='auto',
                                                                       n_jobs=None,
                                                                       penalty='l2',
                                                                       random_state=42,
                                                                       solver='lbfgs',
                                                                       tol=0.0001,
                                                                       verbose=0,
                                                                       warm_start=False),
                                    n_jobs=1, passthrough=False,
                                    stack_method='auto', verbose=0))],
         verbose=False)
2025-10-15 18:01:11,348:INFO:create_model() successfully completed......................................
2025-10-15 18:01:11,534:INFO:_master_model_container: 17
2025-10-15 18:01:11,534:INFO:_display_container: 4
2025-10-15 18:01:11,599:INFO:Pipeline(memory=Memory(location=None),
         steps=[('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 StackingClassifier(cv=5,
                                    estimators=[('Light Gradient Boosting '
                                                 'Machine',
                                                 LGBMClassifier(boosting_type='gbdt',
                                                                class_weight=None,
                                                                colsample_bytree=1.0,
                                                                importan...
                                                                            verbose=0,
                                                                            warm_start=False))],
                                    final_estimator=LogisticRegression(C=1.0,
                                                                       class_weight=None,
                                                                       dual=False,
                                                                       fit_intercept=True,
                                                                       intercept_scaling=1,
                                                                       l1_ratio=None,
                                                                       max_iter=1000,
                                                                       multi_class='auto',
                                                                       n_jobs=None,
                                                                       penalty='l2',
                                                                       random_state=42,
                                                                       solver='lbfgs',
                                                                       tol=0.0001,
                                                                       verbose=0,
                                                                       warm_start=False),
                                    n_jobs=1, passthrough=False,
                                    stack_method='auto', verbose=0))],
         verbose=False)
2025-10-15 18:01:11,599:INFO:finalize_model() successfully completed......................................
2025-10-15 18:01:11,805:INFO:Initializing predict_model()
2025-10-15 18:01:11,805:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D06F668910>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 StackingClassifier(cv=5,
                                    estimators=[('Light Gradient Boosting '
                                                 'Machine',
                                                 LGBMClassifier(boosting_type='gbdt',
                                                                class_weight=None,
                                                                colsample_bytree=1.0,
                                                                importan...
                                                                            verbose=0,
                                                                            warm_start=False))],
                                    final_estimator=LogisticRegression(C=1.0,
                                                                       class_weight=None,
                                                                       dual=False,
                                                                       fit_intercept=True,
                                                                       intercept_scaling=1,
                                                                       l1_ratio=None,
                                                                       max_iter=1000,
                                                                       multi_class='auto',
                                                                       n_jobs=None,
                                                                       penalty='l2',
                                                                       random_state=42,
                                                                       solver='lbfgs',
                                                                       tol=0.0001,
                                                                       verbose=0,
                                                                       warm_start=False),
                                    n_jobs=1, passthrough=False,
                                    stack_method='auto', verbose=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D0726F8EE0>)
2025-10-15 18:01:11,805:INFO:Checking exceptions
2025-10-15 18:01:11,805:INFO:Preloading libraries
2025-10-15 18:01:11,815:INFO:Set up data.
2025-10-15 18:01:11,927:INFO:Set up index.
2025-10-15 18:01:12,963:INFO:Initializing save_model()
2025-10-15 18:01:12,964:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 StackingClassifier(cv=5,
                                    estimators=[('Light Gradient Boosting '
                                                 'Machine',
                                                 LGBMClassifier(boosting_type='gbdt',
                                                                class_weight=None,
                                                                colsample_bytree=1.0,
                                                                importan...
                                                                            verbose=0,
                                                                            warm_start=False))],
                                    final_estimator=LogisticRegression(C=1.0,
                                                                       class_weight=None,
                                                                       dual=False,
                                                                       fit_intercept=True,
                                                                       intercept_scaling=1,
                                                                       l1_ratio=None,
                                                                       max_iter=1000,
                                                                       multi_class='auto',
                                                                       n_jobs=None,
                                                                       penalty='l2',
                                                                       random_state=42,
                                                                       solver='lbfgs',
                                                                       tol=0.0001,
                                                                       verbose=0,
                                                                       warm_start=False),
                                    n_jobs=1, passthrough=False,
                                    stack_method='auto', verbose=0))],
         verbose=False), model_name=best_pycaret_automl_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Khaled\AppData\Local\Temp\joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-10-15 18:01:12,964:INFO:Adding model into prep_pipe
2025-10-15 18:01:12,964:WARNING:Only Model saved as it was a pipeline.
2025-10-15 18:01:13,024:INFO:best_pycaret_automl_model.pkl saved in current working directory
2025-10-15 18:01:13,088:INFO:Pipeline(memory=Memory(location=None),
         steps=[('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 StackingClassifier(cv=5,
                                    estimators=[('Light Gradient Boosting '
                                                 'Machine',
                                                 LGBMClassifier(boosting_type='gbdt',
                                                                class_weight=None,
                                                                colsample_bytree=1.0,
                                                                importan...
                                                                            verbose=0,
                                                                            warm_start=False))],
                                    final_estimator=LogisticRegression(C=1.0,
                                                                       class_weight=None,
                                                                       dual=False,
                                                                       fit_intercept=True,
                                                                       intercept_scaling=1,
                                                                       l1_ratio=None,
                                                                       max_iter=1000,
                                                                       multi_class='auto',
                                                                       n_jobs=None,
                                                                       penalty='l2',
                                                                       random_state=42,
                                                                       solver='lbfgs',
                                                                       tol=0.0001,
                                                                       verbose=0,
                                                                       warm_start=False),
                                    n_jobs=1, passthrough=False,
                                    stack_method='auto', verbose=0))],
         verbose=False)
2025-10-15 18:01:13,088:INFO:save_model() successfully completed......................................
